{"docstore/metadata": {"d4d7bc7c-7e32-453e-8af6-51f0177a7fec": {"doc_hash": "a049a728350702181cc52028aad564ceac1fb5501e5d84e8b25b4c59fef38802"}, "a7f759f7-53ba-405f-95aa-e857207648a9": {"doc_hash": "82943a9dbb216594f79caab6e6c81309f9c34a7635bc66984ed96d25dca02836"}, "843edcee-ff4d-4ea1-a259-ca5a30230a95": {"doc_hash": "91dfb769ea2f17a73676d1e5a6b5a7cf20eefd95df04f458af54db8ecfcd8680"}, "15025bec-e1d7-44d2-bf61-e5c8889d7989": {"doc_hash": "9ef2ffd061562d6d99ccc87feafc87a1818e52d15cd6a3850f19f86e2abddde0"}, "d128bc4c-f689-413d-bc9c-211e33e45f6d": {"doc_hash": "ef02cb01e20daa9e84a00a1df1c2cea76ede8b3933bf9216faf8e48224969962"}, "c15b00da-3e3b-4f33-9f9a-a7968d7510d6": {"doc_hash": "64156be1f6c91e3c79d525d5a6ca56fb5d8aa58fe41bb6a9de6cc5a792f621a7"}, "604d5b76-c572-4673-b2ec-3e8adea2b617": {"doc_hash": "e7d035790735f27d059f4cb98161750a82d4d68b3add016f5b8c280cb8e8a604"}, "cfc5774c-dc55-4dbc-84c2-de2425f6b1b3": {"doc_hash": "8707f8c69e485f9f7613119c2122e62dfe5dfbe69def35bf423c72055b9442cf"}, "4cb244ef-d23a-4606-9cad-18afdc0ad3f9": {"doc_hash": "1c28a568f893e1c148a16f953e9e188eb69e5f5167c665dcf7a42c986cdeec3c"}, "27943491-696e-4730-8d93-3628598abe87": {"doc_hash": "2e5e69872f879d1dd42e9a933b75214f80a224e466929127fc4653bf5a4bd0f0"}, "25aa5ef8-56c2-479d-bbb5-daba49730b80": {"doc_hash": "b271db453447c5aab2109d5020d3a0681c87500dbb412e00850999e366c1762b"}, "4062379e-10b9-4136-b572-f189250c3e7d": {"doc_hash": "fc22f2abd6a3d82e45cd2f8fc1b81809759dd961722498994d944df2b5a8464f"}, "a5f20a51-bedd-4a9c-9085-139446353f1e": {"doc_hash": "bb7d8bbe4e42749850d84aabf1a611826484557ca582c0c01e28e6d1349b116c"}, "de5353d8-49ce-45cd-b973-34c7eb4d78b1": {"doc_hash": "72477860669eaa817cb6a9e6344f895d48b98225d4e9fcfa24ae1b8a43304e7e"}, "5fa2eff2-1d87-4e2d-8988-f8fe17f40185": {"doc_hash": "01f15223ef86df1583045a9b0537b553b732ef361f5a32e44e9656fe922085bb"}, "263f4cb5-bead-4a6b-8984-20e99553c3ca": {"doc_hash": "ec567b3f82639e98aac192c7eb6ce14c8ac27b40a88e560cf3f4f265dafdfab9"}, "d8d897c2-a40f-46c2-9f4f-40c7ca3f2c6e": {"doc_hash": "dd4bddc4614f108936d02d480dfc7541114a760c2d0f7ac12f43ae74e869ca4e"}, "0caa366f-8138-418c-b552-104a339c11cd": {"doc_hash": "055fb1f32306d5ada23a6479c4fc0d86a54257c9ad79f4e759e63d65d94d0e29"}, "a8ca7892-bfd8-4117-aa5e-3d15152072f0": {"doc_hash": "e9eefc0c923bf2c251c2803c6701078ccaa1b6cbcd4ae64a6d4f0bdd2a803d7b"}, "93b400e2-5ea7-4af3-8ab1-e188d9a1c9fd": {"doc_hash": "1226ab2920e06915e6cfe4d712f5cdf63d04d462414bdbdc1387434289c55154"}, "4d47e6f7-5bc0-4bb9-809e-b21c7eb79c0a": {"doc_hash": "b64e1f9165a73b0b52051461cf54ba3338d743b898cda8e53cd8b1bbd2c8404b"}, "9e06595d-c402-4bf7-be8f-20b852150113": {"doc_hash": "27064c2dc4fe428725b1bda16dd94bfdf168c456f2f391464d8fac2f4422909b"}, "b7cc01e2-f0e6-457d-9575-374ec5406f04": {"doc_hash": "2a86b275070ccbcaeb89b862dbd424f2bf4279d8f9aaa37c4e64eaa6753078be"}, "81e1c260-96e9-44ed-934c-fee55d39ca24": {"doc_hash": "8afa6cc7a05e0dac55967aeba082cdc6e3edafdb650aae1bacedd3ab7b646d07"}, "515c186e-752d-434c-a38a-9078e7733eb3": {"doc_hash": "c850e9d1ebd3a2963d2b6e6e309b33540c652284b3d6fd05602f39e528ff0e7d"}, "0ced88fc-9fd3-428d-837a-5e3c241aabdc": {"doc_hash": "2df7d645b2de9235ff7382dae300d76cf35249a0f1d74ff60a0f7fde8e7d15bc"}, "0670389a-f799-43e0-9a56-827672784b53": {"doc_hash": "d5dd544ff1647089b3c78662f262e9b31d73ec89421f53572ae49f5856c10eca"}, "e3afcbf0-afa3-4b1f-ba0e-b2f3afddb625": {"doc_hash": "2359559052a355183640708316c1e555efa7360a4216446944bdfdd1c8b5e3d3"}, "aa15153c-21e2-4bc4-981a-4427eb5389be": {"doc_hash": "768ad6f8516ece2ddaa645996fe835ae88765d38d20d7c7e8f3dde2c462f0150"}, "b20afe2f-20ec-4c27-87c5-b7557a65be3a": {"doc_hash": "a5a50ec813968f18de270940c68d0282071cd036667d9e5e0411c2030b8c431c"}, "271abb5d-413f-451e-8ae8-0b745abdc3a0": {"doc_hash": "789aa1893228435f2514c2fe69cb3e64655f0dec6a182e5700bfbe23b9edfe19"}, "eab98aab-d194-4483-8763-c6adb9876aa4": {"doc_hash": "648d53b00e61433b2a546ab5e88c9b5e92f157f38fbbeeaa80e825af9783cae4"}, "3be8cd1b-645e-4c2c-b429-8d910b985aa7": {"doc_hash": "30a9909e0961c6633fa2db7dc8b46771d50c3e210e9c4387c43b6226ba38eb76"}, "5b37a0d6-dbc7-4b1a-85f9-0ff44ee3cbea": {"doc_hash": "5e99e8a10989909af3684baef52ec7162911075fb6962dac28b93cccb053f0b9"}, "88a81797-7850-4cdb-bcc5-c52855615dd9": {"doc_hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da"}, "c8236ec3-79c5-466c-af80-25d0effa6b1c": {"doc_hash": "629613f2fa5d5c47c35b7d4a5bc04cdad86fac119372dd30ebf7ad8fc0be2bf4"}, "b8cb43a8-4726-41c7-ba46-c19dfaec4c3e": {"doc_hash": "6b9983cf2a5e7b83d17d2ee329c8481e4dab17339701b5081fdad291fcba558f"}, "081ddf92-852f-40bb-b588-538c9fd45e34": {"doc_hash": "8e356e06cc1ceb8e1c3c7e14064eaf2427bf3566614312bdea307b97cd61dc89"}, "3dfd3637-fe04-425a-832e-319e6865f996": {"doc_hash": "9b0a0200b68659bde32ffc1de1c4120519fc2f8207acd74252def55fb66ed754"}, "1045d45d-e50c-4c65-950c-87e76a697c6e": {"doc_hash": "6cff8c0be5d33c55e98732a6c39777489a71f3857226b109072e502b04d631dc"}, "982fa401-3dfb-4937-8004-738030d53def": {"doc_hash": "035388793dcb29f8f034a41beb68c714c0cb72fdc47e3dd6fdd5ac8c1ab53e98"}, "8d4f18be-6679-4f6e-bc83-e33fef9e8653": {"doc_hash": "f2631000182eb3ba675a475fec97fe0720b040103528fe2bd092693143c2c82b"}, "3ac9b8bd-feba-4a5f-a387-71180d079a1e": {"doc_hash": "d0c5687a47407b54c0bf92444e141eb0f762c67300cad343c015549f5cc585c2"}, "8370cd5e-ef89-4abf-ba32-ecf770c2b4f4": {"doc_hash": "2e7f581b32deadbf80156a4fa41337808c666b068c0352f9ec922d226531e14c"}, "6640a5ed-a358-4e2b-91e6-536a4936d4e5": {"doc_hash": "3ef67d5c478ff670bac04f3ead6abf0bfeb8d00d7317ce53d10c5f5a27e9c7ff"}, "0a07be52-f662-4822-b001-331d0ac88dff": {"doc_hash": "ed8f29d43e88935b580f69ed755c17b511424500f350ddec9be0d7dc236377e1"}, "cff25309-ccf5-4af2-872d-4776bec5d113": {"doc_hash": "e09dbca05f5cd23c083ab2004ef3d9ddb172ec2db59b44ffe2a3b999dabb0b27"}, "a032f2ea-36a8-4b14-998f-689e1ce45c2c": {"doc_hash": "1defdfa88203a7412e76ebc00d07a17889007e73f4020a58cc5853a81f546e9b"}, "d744111e-1d36-4033-a5ab-b694d7f347f6": {"doc_hash": "d398d1c6ae4869799d0c095ea620bd83b823484bb6a05a1544cde304f70f6e27"}, "680171bd-ab73-451b-ae9e-bf188dd8f396": {"doc_hash": "9b0c591a2bd8c253f7b2acc2ee83aa32cda9cf89ca46a2a4377134cd444db3a2"}, "7a19d4f7-7aae-4520-8d99-4bea36d8fcd1": {"doc_hash": "33228439e49c7f195dda4c8a78c982ca3a0a7a0968546f07d1d5b680d424326d"}, "9fc7c8d9-9572-4de2-b7a0-8396e1731c65": {"doc_hash": "ae2b7dcdd31ab96f48c0a2b17dccf9a1e70762c6d346d43f650f6c12313aa36e"}, "7cf52c57-9fec-41ac-a9b3-b72dac5529e6": {"doc_hash": "4f7d7e5d83994bcb066f67cdd73ad6a166098e46b5f927b63f0191d492bdd7bf"}, "d6650d8e-5e58-42c2-a326-ff2918e668cf": {"doc_hash": "8b2c29d6e36225933e8a51db9911b0f9c5f8bab3533101d010bc5cef4ce6c70b"}, "cd98c782-c829-46ac-a280-c64b09157e70": {"doc_hash": "ea02e6a6600e2790f5c69159bb73f0e54a7a881978ba76a00cca2211619c30e8"}, "adbc09b4-b1f0-42e4-8d80-0b27ea6e6554": {"doc_hash": "26279fa929e6976cae326faf000a095de1edc0328c0a3e1959d49da2380c7dc9"}, "d9d9245e-a063-4851-9bc5-dfcda9d16772": {"doc_hash": "5ebbac9b1ea1905475fb2adcf3a694d4359306a63f33d0c9ef3f1440042a216a"}, "66174a56-09d6-4bbc-9668-24ecf27a5b35": {"doc_hash": "cf4bcbcbbb1fac98ea410dd2b677a0baf6bc386a78ee6a96193a335ec16a30bf"}, "e26e0394-58f9-4610-bbe3-59562f2e907e": {"doc_hash": "a0b204749881938fab53e00ce0307a5490e92c576d3b5c87f020e4e27b64ebca"}, "d277a37b-cfb5-4ba3-90c3-acb2518d9d61": {"doc_hash": "82a39de91934eedd6c71e1c3cfac3811c4519c162dc43c6a49e8f46c917928bb"}, "aa0c5184-7568-40af-9ee6-45dc83180ac4": {"doc_hash": "2285b68919d5f1c0f29e65b1fac8b4fe69162bf8896dceae5a23f1c7174b8096"}, "1fe55689-be5f-4c9a-9e6d-f5a05376119a": {"doc_hash": "2bcf60ccb528c59e0d064a8524ecc1bd9317c1e481ab039ed9dc601f0b2e320d"}, "b0bd4140-19fe-4feb-a329-26d4cad626b9": {"doc_hash": "52c0174106a6c6035903c2a75c49f622c0155bcfb5016025919a4ab50ec9a61c"}, "bea429f6-6da7-4d9f-8f3d-e396df0fcbe6": {"doc_hash": "c9791e6d099d7d60285e8ec2e2041488930ae506f15a7bded2b2c4404534c873"}, "4664bd02-ec62-4a83-ac5b-505e8d3a4dab": {"doc_hash": "911a1c63f4cfc25da1f093e7fd004378c1babaed880eb16880a46a8b77d34b3d"}, "d7b8e5d0-292a-49db-849e-983eb8354dbc": {"doc_hash": "f1f9f1c9653e9ce238612a9d3da0eabefd4ec1e5ae16ce650915407d5ec00346"}, "e32c141a-8ed3-4645-8cd2-a1bf91813a56": {"doc_hash": "b20df348b10227a870b0214e5a569110e8fb16f4d1c71b54b1f20f5020a3770e"}, "dc35c2fe-c9d0-45ad-9e27-00c16449e401": {"doc_hash": "4a3e60a7b72060edb9067ebaff47b3f9c977777b6fa71c54fc4fccaefdee1a66"}, "fba910c9-2447-4cae-a7a5-10478968f8ba": {"doc_hash": "2675200431a97e11d55b3224598bc522565863b6f555c2097ce8c26d4b29033e"}, "64a39386-e028-413e-83ea-5dbf4249dd51": {"doc_hash": "1bcabf8a9793c48be92faa8adac24f1b046c179bf21b472dee29f5fe5e403576"}, "013e5318-ca62-4631-b99e-b8548829c417": {"doc_hash": "15963c7fedb27973ebc887d6a26d5074f17cb8fee494fd99dbe427cba9d52bcc"}, "0f91f725-1b13-42a4-a393-1710258fb210": {"doc_hash": "b1409efcd670df1a9c2dbb08d8e40487ca08fa38c334aa005e0881de4822539a"}, "13cd80da-57a3-4441-a645-ff3ae27711fe": {"doc_hash": "661c13ef50ba753612e3025ad6069e6aa5bcb4605e3e43f80c93703ceb47b752"}, "6bdefd75-a243-4222-b725-de3966d7e61a": {"doc_hash": "b059b80780191b1ea2aa6b99274cdd256da239ce143a8ebc1627abd0e1c83bb5"}, "542f6490-7535-41aa-ab5a-29ff279ec7bd": {"doc_hash": "6b2990bfd44d6b6acbb560db7b43813967de22d0aa79a021543d1ead1f87718f"}, "376c995c-9fb1-42a1-8e8f-ff50d17f3aa4": {"doc_hash": "5f14d62ae5a1e23500c002797dc714bce83a12a65b03ab521484a7707fd61632"}, "d101e4db-7f79-4bc4-b9ab-c82118d9b3d2": {"doc_hash": "5e7894061202dfb7a97b662b5adb4098423c4f6532ea874ea7cf4d8d317ad6db"}, "c5a18516-2801-4419-a264-a0b664c0aa2c": {"doc_hash": "2257c41255d37565b778234edd0abc15d91f3f56527e088c0c6b25dea3a75c76"}, "4817c0d7-352a-470c-bdee-e82540661cba": {"doc_hash": "1df0879ba20247a486a3e5a6d67960119b67f4055b67e3b7cf601ebc16a62a6d"}, "fc85c902-b5d3-4e57-a74f-616278e0c9ba": {"doc_hash": "fe5d2d91143e803c51c2e04313593555a162fba3f8529a94f2ef2a7ffbb64900"}, "d83cf4d5-a13c-4274-9ac0-1b8bfdac4589": {"doc_hash": "080b0a77c7fff6f05020bb983e876fc2c04bb88a9a94c3f09b17a3f4afda221c"}, "0869e2b9-a31d-4352-9feb-86ca72cb2324": {"doc_hash": "67db632a67ff00eef630b7cd95c3ec29831c46569b28f08076fc882ccb49f0c1"}, "f86b3111-01c1-4e53-83df-f92ff9be0aee": {"doc_hash": "1d9193745887eae11d9a6f3f6bfc16f9f82ccc361c33545e3bb583821ad2195f"}, "d4373eb7-929c-45bf-b748-acbd4054a3b9": {"doc_hash": "81b8dc30e2c5ed8d1e504ea6f2e76b3133ebec91984771475f5edce3d7f2eeb0"}, "3654828c-6c7d-4bf9-b2cd-ce8435291660": {"doc_hash": "944b43fdc7027133669614046e49ad941e23480313f9cf75cf83c2b501785daa"}, "50034a92-37b6-4d7f-a9f0-09cf98806c36": {"doc_hash": "09220da7d3b36b6c271bd68ec6d6e37e51c69a976357f4802461f3fecf032fc9"}, "84d83c1b-13c9-4df4-883a-da2192351114": {"doc_hash": "eaec82de6bb9935128731ce6fc961fd477bb21a815669d6de1ee7abc432ea3fd"}, "6ce61545-6112-4b61-b2f1-3d3cc2b1eccc": {"doc_hash": "5cd7070b17ebae3e7ab241b7f62a16f1e1f870aac8cf822b733d56310e93adc4"}, "37eb8154-56d4-418a-811c-ee1267b5c996": {"doc_hash": "70e6198a4e75898a3861ac9f500b395cc3ca8fb960343ee4e3cc6a2627202ea0"}, "9535911d-33e2-49c3-b623-c79315e1fe79": {"doc_hash": "102946d3c2f1babd4f1d3d686e8e2435520f68ce10ba5c249a2309602493377d"}, "2990df88-ca4a-4cbe-a8a1-749be92c2ee7": {"doc_hash": "f166739740f2e0b5df17253adf81df5f41a507ef129d538662cd50f570926677"}, "e09f8ec4-7ea1-4f55-ae7d-97f528e03bcd": {"doc_hash": "f7b8976c5dac53b525f67f32a7512041a397c316dcd1f604f5a771a587ab3967"}, "972dc4ab-fc85-4816-bafe-f236034ae90b": {"doc_hash": "3665f184f99d335c44b8262870c7916611fe72178bc8aea09723200bbedea29c"}, "e4f359e7-990a-48b6-b23b-e7116d2f7f41": {"doc_hash": "3a6e2b893984ae9ff2b1a5bf931ed22f5caa6f7cc0896394a1cbac7710734ccf"}, "329538b3-b96c-42ad-80ca-bab4f96305e1": {"doc_hash": "1576260d4857f7f2fa2be4f64e0dbcfd0544528eb16cf23888dd4e695a1ad609"}, "77809ebb-d8a8-4c58-a5ad-b6a11b4637e7": {"doc_hash": "42d92892947d21aedae728822de3ae0044c96cbd171185ea521fcbdc1cdef907"}, "976c795b-f5d5-4f1c-946c-c0e788e4be41": {"doc_hash": "2fb19826024461f05c34c1e561ec9905ffe157cb5b41a3878fef9a6a0fb15d26"}, "2f3716f3-7ea7-4055-b8e4-950bc62a3b47": {"doc_hash": "c42c70316dcba5418011a7d78653199a93d32f5750f9d8f414ff3a9750f3cf70"}, "262425e9-1a30-405e-a513-891a87598fbf": {"doc_hash": "9a24e45c02551e84ebe044981caf549ea9fc4965f8b9a53d239deb8bede54b70"}, "e9c57312-ca85-4dbc-b7b3-36df08853db9": {"doc_hash": "0b76caa9abc8448fb5ce1e016bcd0babcebaf2756bbee7968d74cafd2fb6f56a"}, "918d6eab-0844-4917-809d-68b6818d454e": {"doc_hash": "f53b373874733329bc2f7d2a0cb80be244100a9013d53c8de4807cf8357c5fa3"}, "221d27b2-441c-4dd8-a014-c2d7407961a1": {"doc_hash": "24c1a5ecb9ac0887e452be6dec0f1a451ec26030b6c8e3e508989cb1d7621435"}, "0b620ab8-48d8-4e0d-a64f-cccb33254bdb": {"doc_hash": "1ec25a8e1190f641db27a0b34cf7dd596a80e8724e7dd81426224596270db54e"}, "a0bea8eb-a6d9-4d70-88e1-960d0f9c2624": {"doc_hash": "c60697a10f4b4eec6901bdaf00228fa90c5b508b4de7f6916c7f10ee66200a62", "ref_doc_id": "d4d7bc7c-7e32-453e-8af6-51f0177a7fec"}, "5b7cb5fd-5092-4d2a-9cda-c1cc7bedf724": {"doc_hash": "0930403bb70699e6d775962a8e877cd78ffc24bd5dff347d59c28dabe95571fe", "ref_doc_id": "d4d7bc7c-7e32-453e-8af6-51f0177a7fec"}, "7f51159f-bedb-454b-8660-c708b6f4cfd3": {"doc_hash": "bc5e11462f219308e7ade3145814e526cd98a8b1bfd29ab2a466ea8cad5fa0cc", "ref_doc_id": "a7f759f7-53ba-405f-95aa-e857207648a9"}, "8b404941-c86e-441a-8386-322f01604985": {"doc_hash": "b4d5173b28c3ed699a48a8a90ddc944e4eadc5ba27f710135a693c2fd5917a88", "ref_doc_id": "a7f759f7-53ba-405f-95aa-e857207648a9"}, "52b70eec-4bbf-4808-9f3d-846741182718": {"doc_hash": "5deabf76fb03f095a6fd82f84edfa1f60ab7749353ff9b2a1372cf73dd1d6424", "ref_doc_id": "843edcee-ff4d-4ea1-a259-ca5a30230a95"}, "5b5077b9-38da-4c25-ade2-27760f6ac782": {"doc_hash": "a1ef99d16fcec9b2b65bb491ccb870b7883d40c06584327b7ea1f82aee4827d5", "ref_doc_id": "843edcee-ff4d-4ea1-a259-ca5a30230a95"}, "bf16bae2-7474-4276-af73-3b05272afb9a": {"doc_hash": "f1e85b3779b7cf2c145b70cd7d38982266b01ca3ed6667ca7250e01cb0deb42a", "ref_doc_id": "15025bec-e1d7-44d2-bf61-e5c8889d7989"}, "373b31a5-6106-4f6b-bc14-29d11081ed1a": {"doc_hash": "b94c3718f914b788a17060a4d7f7cf1135cdfb4ba4f02cb781a6643d55376fc1", "ref_doc_id": "15025bec-e1d7-44d2-bf61-e5c8889d7989"}, "b68fae12-9a8e-408f-a503-d7bf7e9d4b00": {"doc_hash": "584be43fe2a015d13e8638415ab5a89f261c793f95017204e288894b3391385a", "ref_doc_id": "d128bc4c-f689-413d-bc9c-211e33e45f6d"}, "734cd577-5821-4faf-b9f0-a6e729f369aa": {"doc_hash": "928b2b7bf4cfe94f0788f2b1b473afec3823f38e20f33a22b9e814d06864bd6f", "ref_doc_id": "d128bc4c-f689-413d-bc9c-211e33e45f6d"}, "6cb33439-2d56-4640-9022-86fe9e6637be": {"doc_hash": "5b412644ec7bc89df786315d0b5f04e41763807bf4a27371535635977f187f42", "ref_doc_id": "c15b00da-3e3b-4f33-9f9a-a7968d7510d6"}, "2ca6880e-0b18-41cd-aef3-617f3214d411": {"doc_hash": "c2109644e7fc8049c0a3fd475b73436dca8043c6749a72d4d85e9b0ecd08e203", "ref_doc_id": "c15b00da-3e3b-4f33-9f9a-a7968d7510d6"}, "c27d9cfa-3b4a-4853-ae17-554eb3e4f3e2": {"doc_hash": "8abbdc3dbebd500a72ef6473975463d341d72b3183fa992211ad44d350a4cb58", "ref_doc_id": "604d5b76-c572-4673-b2ec-3e8adea2b617"}, "962b04be-8f2a-4d63-9432-8b9a5520d3a2": {"doc_hash": "2f74723115fc01f8efaf013c4029a1ea84f2bd9f48de86274826053476f3950f", "ref_doc_id": "604d5b76-c572-4673-b2ec-3e8adea2b617"}, "93cedf8a-c8a6-40f0-b8df-c8e5128a6dbf": {"doc_hash": "6cfc4a4967ee66b561a029cad090057e0b677b4c397ba6d507203e13b209b084", "ref_doc_id": "604d5b76-c572-4673-b2ec-3e8adea2b617"}, "16d20fd5-f436-4401-bd65-5f9811920361": {"doc_hash": "1d35585482951442028101a4e3005c644e383ed98564c9fb9f890e3aa5ee2ca0", "ref_doc_id": "604d5b76-c572-4673-b2ec-3e8adea2b617"}, "2a1166b5-5963-4208-9081-740b8c1d1e77": {"doc_hash": "1b0dc37bffd89e5ffb2bc8b61feaa090ff64d58bd4dc1fc15b5214b75a29a326", "ref_doc_id": "604d5b76-c572-4673-b2ec-3e8adea2b617"}, "2547fd93-0bc3-4d4d-9be4-c89cbba0b856": {"doc_hash": "8707f8c69e485f9f7613119c2122e62dfe5dfbe69def35bf423c72055b9442cf", "ref_doc_id": "cfc5774c-dc55-4dbc-84c2-de2425f6b1b3"}, "f941853b-1b1e-4a48-abc3-9dbfd2911beb": {"doc_hash": "24cf3d8274ddf5e51ccd17d7adc30f18b993cc1418b1472fe971e4caa5e6c585", "ref_doc_id": "4cb244ef-d23a-4606-9cad-18afdc0ad3f9"}, "248ecc26-f16e-4113-9488-3f432d6c5aac": {"doc_hash": "6ed2186769c6b277e73792e274facba8138b67dc73a095d9405fdeafefcd2509", "ref_doc_id": "4cb244ef-d23a-4606-9cad-18afdc0ad3f9"}, "8fcc9c46-6e03-435c-97e7-97a3638694a8": {"doc_hash": "7fbc9c4688aff4a7c76c02c4fa98706380f2195ad9f3b1f6aa3151f74c65cd23", "ref_doc_id": "4cb244ef-d23a-4606-9cad-18afdc0ad3f9"}, "591c6e7e-fb52-49ea-9859-8b25f6932b1b": {"doc_hash": "0ede02bb86da4e8583add65a5f9405ef1497ce6da70ba9498e52e354d7eb0129", "ref_doc_id": "4cb244ef-d23a-4606-9cad-18afdc0ad3f9"}, "3673bf07-6eb5-4f21-a899-825c209f56dd": {"doc_hash": "2e5e69872f879d1dd42e9a933b75214f80a224e466929127fc4653bf5a4bd0f0", "ref_doc_id": "27943491-696e-4730-8d93-3628598abe87"}, "0b6f9597-8a81-457a-b1ab-26e8b37dac9a": {"doc_hash": "e53992db8bbc2ff04a3a525a74b5aeb67435a0eac3adf4c0a0074af4773550cd", "ref_doc_id": "25aa5ef8-56c2-479d-bbb5-daba49730b80"}, "174bc864-365a-4e3d-b898-528fc170542e": {"doc_hash": "dfafa17ed482d9d7ee1cec973846ed0c2990aa32f6ad0ddc689544dffd0502d4", "ref_doc_id": "4062379e-10b9-4136-b572-f189250c3e7d"}, "b0e7ec7b-ac2b-4944-ab73-9e95e66a6b31": {"doc_hash": "22233268752e807127e335a0693509bcf0a601b642124f9ee7000a582e88c9c1", "ref_doc_id": "a5f20a51-bedd-4a9c-9085-139446353f1e"}, "063cb970-a394-4c2e-9db9-8a5e99b557d1": {"doc_hash": "7a86ff481d12c430298272f52f20cfe86de7af65c4571c75cd752a78f24cb078", "ref_doc_id": "de5353d8-49ce-45cd-b973-34c7eb4d78b1"}, "51cd4906-09a7-48c8-a66d-9a42d60b5764": {"doc_hash": "8b0102c618d9ca35ae33fd4e8776e012b6acb335055fc6e1d678ae6e651c228c", "ref_doc_id": "5fa2eff2-1d87-4e2d-8988-f8fe17f40185"}, "b0e2a428-1265-44d9-b5b0-4f2ebf5cb572": {"doc_hash": "2fdac92f6c09da8df24973c73da69c99e93d684af3b681d78af19dbdfb68aab0", "ref_doc_id": "263f4cb5-bead-4a6b-8984-20e99553c3ca"}, "61909d8b-fe51-4401-bb85-eb3c6e189724": {"doc_hash": "46bb524046e57632c6610555ee894b1561edcac4b92e53c609a0a2b877c370d5", "ref_doc_id": "d8d897c2-a40f-46c2-9f4f-40c7ca3f2c6e"}, "03d5f84c-4969-4564-b2e9-705d3bb1ec99": {"doc_hash": "bfffadb8ccf7f3d3d697816f3f07bc72574a03034caa208729f6c7828465b94b", "ref_doc_id": "d8d897c2-a40f-46c2-9f4f-40c7ca3f2c6e"}, "3be2bb7d-2174-4e69-ae06-820b8bd9592a": {"doc_hash": "a755e0a7f8398cb64bd571832c8374e56dec62c99a7b23a63ff5c95266b0b133", "ref_doc_id": "0caa366f-8138-418c-b552-104a339c11cd"}, "d0eb1202-335f-4d83-802d-5ddc851fb7d9": {"doc_hash": "f288d8d5aa4361c4649603d3f99355659b31a487626a84f048699b6ba2a1d0b9", "ref_doc_id": "a8ca7892-bfd8-4117-aa5e-3d15152072f0"}, "f524492e-3799-470d-9137-4db6a4d82997": {"doc_hash": "8736547f7faa95940687fc739c19de10653bc7e4def97fd8362d3c80f9333cf8", "ref_doc_id": "93b400e2-5ea7-4af3-8ab1-e188d9a1c9fd"}, "0d1aec07-9348-4529-975d-7d8b4d6d9ffa": {"doc_hash": "531fc0bd047e46f28ca02742d5646b472cdaa9daade26b2435e1c9aa298791b0", "ref_doc_id": "4d47e6f7-5bc0-4bb9-809e-b21c7eb79c0a"}, "195c5082-2566-45ec-b115-cd9f6d01aa1f": {"doc_hash": "0bf0f9ca9c95d3190320a3c3b593e7e9c9959fcb0748dad447ee6f40ec993b9c", "ref_doc_id": "9e06595d-c402-4bf7-be8f-20b852150113"}, "eebba14d-6257-4a18-943d-11c3f1f245f1": {"doc_hash": "514ea7927c2b0c89649179266c43a7d3847961bb37d01bbc60f2eb889b0c727e", "ref_doc_id": "b7cc01e2-f0e6-457d-9575-374ec5406f04"}, "2d1040fd-0b44-408d-aa70-cb01de009e5f": {"doc_hash": "3a92da4902addfa6ead9fdd656ed7cf32d7c7fa2758445ece56b05aefc41a1f6", "ref_doc_id": "81e1c260-96e9-44ed-934c-fee55d39ca24"}, "9672404b-d5a4-4cd5-bb4f-1c139ac10205": {"doc_hash": "eade989d574424dd7025b1d3ca60b93a779e6aba3736334961dcc0606e76c6ea", "ref_doc_id": "515c186e-752d-434c-a38a-9078e7733eb3"}, "9e72d9a4-1cee-4795-bc24-2aeef0e8b5ad": {"doc_hash": "367fe11e53a28cbc10c6e78c9799cbb8d6009d285d83472e0d1bf503ca72dffc", "ref_doc_id": "0ced88fc-9fd3-428d-837a-5e3c241aabdc"}, "0583d04f-0507-4834-9af7-cf3f338d82e3": {"doc_hash": "172df611c96f6efd6b43bd88e5f14713d9cec3840c8e888d9476a8296e6f9a1b", "ref_doc_id": "0670389a-f799-43e0-9a56-827672784b53"}, "898b37bf-cead-4d38-bc79-862ff358c7eb": {"doc_hash": "9c2707090f73fa4c7a27c74cbac2d004c1e49823c6b6b80d8b37395ad923abd7", "ref_doc_id": "e3afcbf0-afa3-4b1f-ba0e-b2f3afddb625"}, "7ea8d8a6-05c7-4c65-b391-494e8a807c0b": {"doc_hash": "ed49bf8bd04444e5da4848e95cb765e162b4dedfd3753883ee337b73ec9c5eda", "ref_doc_id": "aa15153c-21e2-4bc4-981a-4427eb5389be"}, "0ee870fb-8e5c-438b-853b-19450f45b881": {"doc_hash": "9750d41089ab2ea01ae31671d688b29a8b170860feba25d32477b37a84309988", "ref_doc_id": "b20afe2f-20ec-4c27-87c5-b7557a65be3a"}, "288fe6f5-c570-4f45-a2f6-1fe0827cd32c": {"doc_hash": "0afdd088ecbd0bad5522a43e0221376b2426ae2be83a44421ca39f1b8976ab59", "ref_doc_id": "271abb5d-413f-451e-8ae8-0b745abdc3a0"}, "457473bb-f17c-4a26-a4f7-473ee6f5813d": {"doc_hash": "89fcdb71862eab84247ae584238dae0fa2ffd3169a3c2a8ecdcd0a93a3eec3cd", "ref_doc_id": "eab98aab-d194-4483-8763-c6adb9876aa4"}, "bafd021b-e57b-4be0-b250-6d72223a8c81": {"doc_hash": "06dfe7d6d6e1d88e8bfebeee1af964450cff52393155504d2848e9189a247034", "ref_doc_id": "3be8cd1b-645e-4c2c-b429-8d910b985aa7"}, "e1a85400-fcd8-4b6c-a72e-c24f572c110b": {"doc_hash": "5e99e8a10989909af3684baef52ec7162911075fb6962dac28b93cccb053f0b9", "ref_doc_id": "5b37a0d6-dbc7-4b1a-85f9-0ff44ee3cbea"}, "657b08ba-ab79-450f-ae8e-e234aa283a7b": {"doc_hash": "6b17d5868287452c8502b186020e5710e885a737af21b4871205b8cd57f5f92a", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "7c70da1d-5015-4ac4-9430-ac0d26fca148": {"doc_hash": "d83792e372c38dbaab4f1433e7d48561e110e31644604ae8621597fd23c4d04b", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "f62b83b7-c650-4dc4-b699-8e29fe4a3ffd": {"doc_hash": "f50849e2cc0c4c85b2fa1db09977220c8a834a2eb4a6e23d3dee5ff872ad4349", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "af11eeed-7f6f-48f7-9cad-5d7b91750f40": {"doc_hash": "5ef82bb3a8b981b6d1ae405baad487cfb1ccc55b5911ddf4d56713868f9502de", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "a1b490d9-b503-484c-a83d-c90dc324ec9a": {"doc_hash": "fb0b72420fded38c30ef706bbf8a1f7d9f273ddab1e71774ba908dd926e94549", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "ecb12fa0-dbab-4376-8c85-ac0e7a80f3f7": {"doc_hash": "eb38d4903c7827699d685b7770fb49db16e180957608a13bb4985768c5f1b1eb", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "3f356fa0-6086-40e7-908d-36ade5c79691": {"doc_hash": "fca3a6e6159798ee52b3af5beb29cc45b337b71146e6c54841a485ff22636832", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "ab5c7922-dedc-4671-b320-e7b76491f2b8": {"doc_hash": "579fc9fa796c5fae4c8bbd4fc7d59a1c56950e74a739c13be5df9d82402b8f56", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "95e80773-b27e-41fb-af86-6d8474f7d9d0": {"doc_hash": "320f2af86ce47ddf82c0651d65816d688996b97b1ab41248aa7ca0849039c4e3", "ref_doc_id": "88a81797-7850-4cdb-bcc5-c52855615dd9"}, "e8773c7d-5006-44dc-a9e9-d08a61ca5693": {"doc_hash": "629613f2fa5d5c47c35b7d4a5bc04cdad86fac119372dd30ebf7ad8fc0be2bf4", "ref_doc_id": "c8236ec3-79c5-466c-af80-25d0effa6b1c"}, "49d151ed-8df9-473f-a589-586a0191b2ba": {"doc_hash": "6b9983cf2a5e7b83d17d2ee329c8481e4dab17339701b5081fdad291fcba558f", "ref_doc_id": "b8cb43a8-4726-41c7-ba46-c19dfaec4c3e"}, "73cd50da-1aa5-417d-8563-a5ecdc657fb2": {"doc_hash": "8e356e06cc1ceb8e1c3c7e14064eaf2427bf3566614312bdea307b97cd61dc89", "ref_doc_id": "081ddf92-852f-40bb-b588-538c9fd45e34"}, "26ee755e-a30b-4074-9e1f-52c00759ef12": {"doc_hash": "9b0a0200b68659bde32ffc1de1c4120519fc2f8207acd74252def55fb66ed754", "ref_doc_id": "3dfd3637-fe04-425a-832e-319e6865f996"}, "e1dae1df-ac3c-4f8b-98dc-ff8753ac0fee": {"doc_hash": "6cff8c0be5d33c55e98732a6c39777489a71f3857226b109072e502b04d631dc", "ref_doc_id": "1045d45d-e50c-4c65-950c-87e76a697c6e"}, "4ae355d4-ce1f-4f1a-996e-a969ba3de09e": {"doc_hash": "035388793dcb29f8f034a41beb68c714c0cb72fdc47e3dd6fdd5ac8c1ab53e98", "ref_doc_id": "982fa401-3dfb-4937-8004-738030d53def"}, "e80c9e12-0e3a-4c30-b442-a2cca3ccc153": {"doc_hash": "f2631000182eb3ba675a475fec97fe0720b040103528fe2bd092693143c2c82b", "ref_doc_id": "8d4f18be-6679-4f6e-bc83-e33fef9e8653"}, "08616f41-959d-402c-9460-8ae5181025e3": {"doc_hash": "d0c5687a47407b54c0bf92444e141eb0f762c67300cad343c015549f5cc585c2", "ref_doc_id": "3ac9b8bd-feba-4a5f-a387-71180d079a1e"}, "59125d5c-dc15-4241-bb7e-fc40e86fbe73": {"doc_hash": "2e7f581b32deadbf80156a4fa41337808c666b068c0352f9ec922d226531e14c", "ref_doc_id": "8370cd5e-ef89-4abf-ba32-ecf770c2b4f4"}, "7b21c50e-be6d-4f0f-9f69-38c6ee3d1426": {"doc_hash": "3c78754b8b4da237a612b444dea91d90d4a7406c15e75055f1a7bc0fe6039dae", "ref_doc_id": "6640a5ed-a358-4e2b-91e6-536a4936d4e5"}, "a6f19505-fbb4-4b67-b9cb-ecad0ddcc2bd": {"doc_hash": "4cbcfd67ef9a5c50bbca9d6634b5a3a6d4e520733e507a683497b8bcce521e25", "ref_doc_id": "6640a5ed-a358-4e2b-91e6-536a4936d4e5"}, "d6151167-3060-4503-8afd-5f375e9dbeff": {"doc_hash": "ed8f29d43e88935b580f69ed755c17b511424500f350ddec9be0d7dc236377e1", "ref_doc_id": "0a07be52-f662-4822-b001-331d0ac88dff"}, "7c98b49f-46eb-4a77-a842-4e1be44e99db": {"doc_hash": "e09dbca05f5cd23c083ab2004ef3d9ddb172ec2db59b44ffe2a3b999dabb0b27", "ref_doc_id": "cff25309-ccf5-4af2-872d-4776bec5d113"}, "99e35303-726e-42fc-b575-4f7d4489ab6c": {"doc_hash": "1defdfa88203a7412e76ebc00d07a17889007e73f4020a58cc5853a81f546e9b", "ref_doc_id": "a032f2ea-36a8-4b14-998f-689e1ce45c2c"}, "a597c390-afb4-4a8f-ad95-d8bb8ce29e76": {"doc_hash": "d398d1c6ae4869799d0c095ea620bd83b823484bb6a05a1544cde304f70f6e27", "ref_doc_id": "d744111e-1d36-4033-a5ab-b694d7f347f6"}, "b9af6c60-d611-4c18-a0da-ed76da139238": {"doc_hash": "9b0c591a2bd8c253f7b2acc2ee83aa32cda9cf89ca46a2a4377134cd444db3a2", "ref_doc_id": "680171bd-ab73-451b-ae9e-bf188dd8f396"}, "770f1749-36fc-47f6-8d68-65b60e0364bd": {"doc_hash": "33228439e49c7f195dda4c8a78c982ca3a0a7a0968546f07d1d5b680d424326d", "ref_doc_id": "7a19d4f7-7aae-4520-8d99-4bea36d8fcd1"}, "064668e8-b755-4fc3-8c18-462bcad5567c": {"doc_hash": "ae2b7dcdd31ab96f48c0a2b17dccf9a1e70762c6d346d43f650f6c12313aa36e", "ref_doc_id": "9fc7c8d9-9572-4de2-b7a0-8396e1731c65"}, "1519e695-a2d5-4303-a1ee-1b54f85bca95": {"doc_hash": "4f7d7e5d83994bcb066f67cdd73ad6a166098e46b5f927b63f0191d492bdd7bf", "ref_doc_id": "7cf52c57-9fec-41ac-a9b3-b72dac5529e6"}, "4b0e7fc0-dbe4-459a-8455-af398e48babf": {"doc_hash": "8b2c29d6e36225933e8a51db9911b0f9c5f8bab3533101d010bc5cef4ce6c70b", "ref_doc_id": "d6650d8e-5e58-42c2-a326-ff2918e668cf"}, "cce22b88-2af7-4b61-8f17-473d792612a9": {"doc_hash": "ea02e6a6600e2790f5c69159bb73f0e54a7a881978ba76a00cca2211619c30e8", "ref_doc_id": "cd98c782-c829-46ac-a280-c64b09157e70"}, "67b0d70d-40f8-4d09-ad7c-af1225335918": {"doc_hash": "26279fa929e6976cae326faf000a095de1edc0328c0a3e1959d49da2380c7dc9", "ref_doc_id": "adbc09b4-b1f0-42e4-8d80-0b27ea6e6554"}, "7d6699c8-0462-403b-b699-d22375c15454": {"doc_hash": "5ebbac9b1ea1905475fb2adcf3a694d4359306a63f33d0c9ef3f1440042a216a", "ref_doc_id": "d9d9245e-a063-4851-9bc5-dfcda9d16772"}, "530042e6-5533-4b18-803e-ebcfc661ac5e": {"doc_hash": "cf4bcbcbbb1fac98ea410dd2b677a0baf6bc386a78ee6a96193a335ec16a30bf", "ref_doc_id": "66174a56-09d6-4bbc-9668-24ecf27a5b35"}, "e014c2c5-b445-409c-9ce2-89de09007ea6": {"doc_hash": "a0b204749881938fab53e00ce0307a5490e92c576d3b5c87f020e4e27b64ebca", "ref_doc_id": "e26e0394-58f9-4610-bbe3-59562f2e907e"}, "fd79c5f1-57e1-4d2f-9021-5c4ca6d1f4b0": {"doc_hash": "82a39de91934eedd6c71e1c3cfac3811c4519c162dc43c6a49e8f46c917928bb", "ref_doc_id": "d277a37b-cfb5-4ba3-90c3-acb2518d9d61"}, "62050fa0-7614-4fc2-bab3-0495e8debafe": {"doc_hash": "2285b68919d5f1c0f29e65b1fac8b4fe69162bf8896dceae5a23f1c7174b8096", "ref_doc_id": "aa0c5184-7568-40af-9ee6-45dc83180ac4"}, "51be24d0-344b-4780-b040-07b86e38944d": {"doc_hash": "2bcf60ccb528c59e0d064a8524ecc1bd9317c1e481ab039ed9dc601f0b2e320d", "ref_doc_id": "1fe55689-be5f-4c9a-9e6d-f5a05376119a"}, "2ea49615-0a27-4115-8948-70cd6ff1f821": {"doc_hash": "52c0174106a6c6035903c2a75c49f622c0155bcfb5016025919a4ab50ec9a61c", "ref_doc_id": "b0bd4140-19fe-4feb-a329-26d4cad626b9"}, "6dcef79c-a195-4be6-a641-6a284dd0f9d2": {"doc_hash": "c9791e6d099d7d60285e8ec2e2041488930ae506f15a7bded2b2c4404534c873", "ref_doc_id": "bea429f6-6da7-4d9f-8f3d-e396df0fcbe6"}, "f1f1a985-33e9-4553-b3ad-81c4bde250f5": {"doc_hash": "911a1c63f4cfc25da1f093e7fd004378c1babaed880eb16880a46a8b77d34b3d", "ref_doc_id": "4664bd02-ec62-4a83-ac5b-505e8d3a4dab"}, "20b4de67-52e0-409f-9f9d-6ce0f3b1d5ff": {"doc_hash": "f1f9f1c9653e9ce238612a9d3da0eabefd4ec1e5ae16ce650915407d5ec00346", "ref_doc_id": "d7b8e5d0-292a-49db-849e-983eb8354dbc"}, "0b649889-e07a-46ed-bb02-a64accae7a00": {"doc_hash": "b20df348b10227a870b0214e5a569110e8fb16f4d1c71b54b1f20f5020a3770e", "ref_doc_id": "e32c141a-8ed3-4645-8cd2-a1bf91813a56"}, "a17a7e6c-9476-4fea-9e33-e6083bd481d4": {"doc_hash": "4a3e60a7b72060edb9067ebaff47b3f9c977777b6fa71c54fc4fccaefdee1a66", "ref_doc_id": "dc35c2fe-c9d0-45ad-9e27-00c16449e401"}, "7451ace7-13c0-4188-9939-c90839303fc9": {"doc_hash": "2675200431a97e11d55b3224598bc522565863b6f555c2097ce8c26d4b29033e", "ref_doc_id": "fba910c9-2447-4cae-a7a5-10478968f8ba"}, "6c63e7f6-0512-42ef-af6a-8b6a643d0734": {"doc_hash": "1bcabf8a9793c48be92faa8adac24f1b046c179bf21b472dee29f5fe5e403576", "ref_doc_id": "64a39386-e028-413e-83ea-5dbf4249dd51"}, "6532479a-2ae2-4da8-895a-6aaac805c853": {"doc_hash": "15963c7fedb27973ebc887d6a26d5074f17cb8fee494fd99dbe427cba9d52bcc", "ref_doc_id": "013e5318-ca62-4631-b99e-b8548829c417"}, "61e35dda-fc65-4473-af29-60b1f020f95b": {"doc_hash": "b1409efcd670df1a9c2dbb08d8e40487ca08fa38c334aa005e0881de4822539a", "ref_doc_id": "0f91f725-1b13-42a4-a393-1710258fb210"}, "5b93da12-5b91-4b42-8f3a-d2ee4b477bd7": {"doc_hash": "661c13ef50ba753612e3025ad6069e6aa5bcb4605e3e43f80c93703ceb47b752", "ref_doc_id": "13cd80da-57a3-4441-a645-ff3ae27711fe"}, "b1d6fcd2-ab70-466c-9839-8436a04de818": {"doc_hash": "b059b80780191b1ea2aa6b99274cdd256da239ce143a8ebc1627abd0e1c83bb5", "ref_doc_id": "6bdefd75-a243-4222-b725-de3966d7e61a"}, "f6a3ee55-c401-42ee-a896-7dbcb950a25b": {"doc_hash": "6b2990bfd44d6b6acbb560db7b43813967de22d0aa79a021543d1ead1f87718f", "ref_doc_id": "542f6490-7535-41aa-ab5a-29ff279ec7bd"}, "8ca54719-b2bc-4289-9d2f-593101e317c6": {"doc_hash": "5f14d62ae5a1e23500c002797dc714bce83a12a65b03ab521484a7707fd61632", "ref_doc_id": "376c995c-9fb1-42a1-8e8f-ff50d17f3aa4"}, "7bb5f7e0-432e-4b02-89b6-a4e20cb8c45d": {"doc_hash": "5e7894061202dfb7a97b662b5adb4098423c4f6532ea874ea7cf4d8d317ad6db", "ref_doc_id": "d101e4db-7f79-4bc4-b9ab-c82118d9b3d2"}, "7017e94d-b4c2-4496-8165-e0c9f894ea42": {"doc_hash": "2257c41255d37565b778234edd0abc15d91f3f56527e088c0c6b25dea3a75c76", "ref_doc_id": "c5a18516-2801-4419-a264-a0b664c0aa2c"}, "73b912b6-e215-4b8b-ab02-9d9723d42fd2": {"doc_hash": "1df0879ba20247a486a3e5a6d67960119b67f4055b67e3b7cf601ebc16a62a6d", "ref_doc_id": "4817c0d7-352a-470c-bdee-e82540661cba"}, "cf457bff-5399-414b-95a8-751f6b9731b3": {"doc_hash": "fe5d2d91143e803c51c2e04313593555a162fba3f8529a94f2ef2a7ffbb64900", "ref_doc_id": "fc85c902-b5d3-4e57-a74f-616278e0c9ba"}, "f3104168-6eea-4667-9de5-a108f7d04034": {"doc_hash": "080b0a77c7fff6f05020bb983e876fc2c04bb88a9a94c3f09b17a3f4afda221c", "ref_doc_id": "d83cf4d5-a13c-4274-9ac0-1b8bfdac4589"}, "85915591-dcea-402b-b0f9-85ddcc65d954": {"doc_hash": "67db632a67ff00eef630b7cd95c3ec29831c46569b28f08076fc882ccb49f0c1", "ref_doc_id": "0869e2b9-a31d-4352-9feb-86ca72cb2324"}, "d1483a82-fc60-469a-ac55-5a0ed0ca0ee6": {"doc_hash": "1d9193745887eae11d9a6f3f6bfc16f9f82ccc361c33545e3bb583821ad2195f", "ref_doc_id": "f86b3111-01c1-4e53-83df-f92ff9be0aee"}, "0f5252b4-c88a-4758-8b80-838436ed2149": {"doc_hash": "81b8dc30e2c5ed8d1e504ea6f2e76b3133ebec91984771475f5edce3d7f2eeb0", "ref_doc_id": "d4373eb7-929c-45bf-b748-acbd4054a3b9"}, "660ce218-39ef-48af-aa84-ea9dce37d998": {"doc_hash": "944b43fdc7027133669614046e49ad941e23480313f9cf75cf83c2b501785daa", "ref_doc_id": "3654828c-6c7d-4bf9-b2cd-ce8435291660"}, "5430a335-490f-4e1a-bbde-f0a39eec7665": {"doc_hash": "09220da7d3b36b6c271bd68ec6d6e37e51c69a976357f4802461f3fecf032fc9", "ref_doc_id": "50034a92-37b6-4d7f-a9f0-09cf98806c36"}, "903659d8-a415-4264-98ed-675fb565c677": {"doc_hash": "eaec82de6bb9935128731ce6fc961fd477bb21a815669d6de1ee7abc432ea3fd", "ref_doc_id": "84d83c1b-13c9-4df4-883a-da2192351114"}, "0457fdea-0c13-4688-a54e-fd71dfe377a4": {"doc_hash": "5cd7070b17ebae3e7ab241b7f62a16f1e1f870aac8cf822b733d56310e93adc4", "ref_doc_id": "6ce61545-6112-4b61-b2f1-3d3cc2b1eccc"}, "4b257a6e-94a5-4788-b70a-0504a93078f6": {"doc_hash": "70e6198a4e75898a3861ac9f500b395cc3ca8fb960343ee4e3cc6a2627202ea0", "ref_doc_id": "37eb8154-56d4-418a-811c-ee1267b5c996"}, "c443db44-6e60-4414-b692-c67badf89cf0": {"doc_hash": "102946d3c2f1babd4f1d3d686e8e2435520f68ce10ba5c249a2309602493377d", "ref_doc_id": "9535911d-33e2-49c3-b623-c79315e1fe79"}, "b7df068a-d095-444e-b683-d349abdae08b": {"doc_hash": "f166739740f2e0b5df17253adf81df5f41a507ef129d538662cd50f570926677", "ref_doc_id": "2990df88-ca4a-4cbe-a8a1-749be92c2ee7"}, "e47d43f3-91b4-44d6-9e5f-dd85e0cf4fba": {"doc_hash": "f7b8976c5dac53b525f67f32a7512041a397c316dcd1f604f5a771a587ab3967", "ref_doc_id": "e09f8ec4-7ea1-4f55-ae7d-97f528e03bcd"}, "82597407-bbd3-4e54-8b17-b7f2856a7e9d": {"doc_hash": "3665f184f99d335c44b8262870c7916611fe72178bc8aea09723200bbedea29c", "ref_doc_id": "972dc4ab-fc85-4816-bafe-f236034ae90b"}, "2d445638-89e9-4f1e-8af9-f8f445ca439e": {"doc_hash": "3a6e2b893984ae9ff2b1a5bf931ed22f5caa6f7cc0896394a1cbac7710734ccf", "ref_doc_id": "e4f359e7-990a-48b6-b23b-e7116d2f7f41"}, "b5669d62-ae64-496d-9be1-b0a0aec6dd86": {"doc_hash": "1576260d4857f7f2fa2be4f64e0dbcfd0544528eb16cf23888dd4e695a1ad609", "ref_doc_id": "329538b3-b96c-42ad-80ca-bab4f96305e1"}, "0ad6fcc2-192b-4771-b997-0d99481044c4": {"doc_hash": "42d92892947d21aedae728822de3ae0044c96cbd171185ea521fcbdc1cdef907", "ref_doc_id": "77809ebb-d8a8-4c58-a5ad-b6a11b4637e7"}, "6c20d800-f06b-4ae4-8ad6-538bc5da1d70": {"doc_hash": "2fb19826024461f05c34c1e561ec9905ffe157cb5b41a3878fef9a6a0fb15d26", "ref_doc_id": "976c795b-f5d5-4f1c-946c-c0e788e4be41"}, "b4a2397c-cdf8-4537-9ffd-07f8df360085": {"doc_hash": "c42c70316dcba5418011a7d78653199a93d32f5750f9d8f414ff3a9750f3cf70", "ref_doc_id": "2f3716f3-7ea7-4055-b8e4-950bc62a3b47"}, "9cef2c25-8b41-485b-b165-04ca52887e30": {"doc_hash": "9a24e45c02551e84ebe044981caf549ea9fc4965f8b9a53d239deb8bede54b70", "ref_doc_id": "262425e9-1a30-405e-a513-891a87598fbf"}, "a2f1ac0f-7856-42ed-a918-c4b7471b203d": {"doc_hash": "0b76caa9abc8448fb5ce1e016bcd0babcebaf2756bbee7968d74cafd2fb6f56a", "ref_doc_id": "e9c57312-ca85-4dbc-b7b3-36df08853db9"}, "c29910c3-9eb0-4e5f-be54-c692fe0b1f6c": {"doc_hash": "f53b373874733329bc2f7d2a0cb80be244100a9013d53c8de4807cf8357c5fa3", "ref_doc_id": "918d6eab-0844-4917-809d-68b6818d454e"}, "1e0eb29d-d183-4209-a012-902e092e4601": {"doc_hash": "24c1a5ecb9ac0887e452be6dec0f1a451ec26030b6c8e3e508989cb1d7621435", "ref_doc_id": "221d27b2-441c-4dd8-a014-c2d7407961a1"}, "c8a37f28-9e56-4d87-bc25-4ad9b39bdba3": {"doc_hash": "1ec25a8e1190f641db27a0b34cf7dd596a80e8724e7dd81426224596270db54e", "ref_doc_id": "0b620ab8-48d8-4e0d-a64f-cccb33254bdb"}}, "docstore/data": {"a0bea8eb-a6d9-4d70-88e1-960d0f9c2624": {"__data__": {"id_": "a0bea8eb-a6d9-4d70-88e1-960d0f9c2624", "embedding": null, "metadata": {"page_label": "1", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4d7bc7c-7e32-453e-8af6-51f0177a7fec", "node_type": "4", "metadata": {"page_label": "1", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "a049a728350702181cc52028aad564ceac1fb5501e5d84e8b25b4c59fef38802", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b7cb5fd-5092-4d2a-9cda-c1cc7bedf724", "node_type": "1", "metadata": {}, "hash": "19df63c2a0a46a85f3347cd2f458add2117e0e7e38135c5bb03dfaf06261fe49", "class_name": "RelatedNodeInfo"}}, "text": "You Only Look Once:\nUni\ufb01ed, Real-Time Object Detection\nJoseph Redmon\u2217, Santosh Divvala\u2217\u2020, Ross Girshick\u00b6, Ali Farhadi\u2217\u2020\nUniversity of Washington\u2217, Allen Institute for AI\u2020, Facebook AI Research\u00b6\nhttp://pjreddie.com/yolo/\nAbstract\nWe present YOLO, a new approach to object detection.\nPrior work on object detection repurposes classi\ufb01ers to per-\nform detection. Instead, we frame object detection as a re-\ngression problem to spatially separated bounding boxes and\nassociated class probabilities. A single neural network pre-\ndicts bounding boxes and class probabilities directly from\nfull images in one evaluation. Since the whole detection\npipeline is a single network, it can be optimized end-to-end\ndirectly on detection performance.\nOur uni\ufb01ed architecture is extremely fast. Our base\nYOLO model processes images in real-time at 45 frames\nper second. A smaller version of the network, Fast YOLO,\nprocesses an astounding 155 frames per second while\nstill achieving double the mAP of other real-time detec-\ntors. Compared to state-of-the-art detection systems, YOLO\nmakes more localization errors but is less likely to predict\nfalse positives on background. Finally, YOLO learns very\ngeneral representations of objects. It outperforms other de-\ntection methods, including DPM and R-CNN, when gener-\nalizing from natural images to other domains like artwork.\n1. Introduction\nHumans glance at an image and instantly know what ob-\njects are in the image, where they are, and how they inter-\nact. The human visual system is fast and accurate, allow-\ning us to perform complex tasks like driving with little con-\nscious thought. Fast, accurate algorithms for object detec-\ntion would allow computers to drive cars without special-\nized sensors, enable assistive devices to convey real-time\nscene information to human users, and unlock the potential\nfor general purpose, responsive robotic systems.\nCurrent detection systems repurpose classi\ufb01ers to per-\nform detection. To detect an object, these systems take a\nclassi\ufb01er for that object and evaluate it at various locations\nand scales in a test image. Systems like deformable parts\nmodels (DPM) use a sliding window approach where the\nclassi\ufb01er is run at evenly spaced locations over the entire\nimage [10].\nMore recent approaches like R-CNN use region proposal\n1. Resize image.\n2. Run convolutional network.3. Non-max suppression.\nDog: 0.30Person: 0.64Horse: 0.28Figure 1: The YOLO Detection System. Processing images\nwith YOLO is simple and straightforward. Our system (1) resizes\nthe input image to 448\u00d7448, (2) runs a single convolutional net-\nwork on the image, and (3) thresholds the resulting detections by\nthe model\u2019s con\ufb01dence.\nmethods to \ufb01rst generate potential bounding boxes in an im-\nage and then run a classi\ufb01er on these proposed boxes. After\nclassi\ufb01cation, post-processing is used to re\ufb01ne the bound-\ning boxes, eliminate duplicate detections, and rescore the\nboxes based on other objects in the scene [13]. These com-\nplex pipelines are slow and hard to optimize because each\nindividual component must be trained separately.\nWe reframe object detection as a single regression prob-\nlem, straight from image pixels to bounding box coordi-\nnates and class probabilities. Using our system, you only\nlook once (YOLO) at an image to predict what objects are\npresent and where they are.\nYOLO is refreshingly simple: see Figure 1. A sin-\ngle convolutional network simultaneously predicts multi-\nple bounding boxes and class probabilities for those boxes.\nYOLO trains on full images and directly optimizes detec-\ntion performance. This uni\ufb01ed model has several bene\ufb01ts\nover traditional methods of object detection.\nFirst, YOLO is extremely fast. Since we frame detection\nas a regression problem we don\u2019t need a complex pipeline.\nWe simply run our neural network on a new image at test\ntime to predict detections. Our base network runs at 45\nframes per second with no batch processing on a Titan X\nGPU and a fast version runs at more than 150 fps.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3998, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b7cb5fd-5092-4d2a-9cda-c1cc7bedf724": {"__data__": {"id_": "5b7cb5fd-5092-4d2a-9cda-c1cc7bedf724", "embedding": null, "metadata": {"page_label": "1", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4d7bc7c-7e32-453e-8af6-51f0177a7fec", "node_type": "4", "metadata": {"page_label": "1", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "a049a728350702181cc52028aad564ceac1fb5501e5d84e8b25b4c59fef38802", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a0bea8eb-a6d9-4d70-88e1-960d0f9c2624", "node_type": "1", "metadata": {"page_label": "1", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "c60697a10f4b4eec6901bdaf00228fa90c5b508b4de7f6916c7f10ee66200a62", "class_name": "RelatedNodeInfo"}}, "text": "Systems like deformable parts\nmodels (DPM) use a sliding window approach where the\nclassi\ufb01er is run at evenly spaced locations over the entire\nimage [10].\nMore recent approaches like R-CNN use region proposal\n1. Resize image.\n2. Run convolutional network.3. Non-max suppression.\nDog: 0.30Person: 0.64Horse: 0.28Figure 1: The YOLO Detection System. Processing images\nwith YOLO is simple and straightforward. Our system (1) resizes\nthe input image to 448\u00d7448, (2) runs a single convolutional net-\nwork on the image, and (3) thresholds the resulting detections by\nthe model\u2019s con\ufb01dence.\nmethods to \ufb01rst generate potential bounding boxes in an im-\nage and then run a classi\ufb01er on these proposed boxes. After\nclassi\ufb01cation, post-processing is used to re\ufb01ne the bound-\ning boxes, eliminate duplicate detections, and rescore the\nboxes based on other objects in the scene [13]. These com-\nplex pipelines are slow and hard to optimize because each\nindividual component must be trained separately.\nWe reframe object detection as a single regression prob-\nlem, straight from image pixels to bounding box coordi-\nnates and class probabilities. Using our system, you only\nlook once (YOLO) at an image to predict what objects are\npresent and where they are.\nYOLO is refreshingly simple: see Figure 1. A sin-\ngle convolutional network simultaneously predicts multi-\nple bounding boxes and class probabilities for those boxes.\nYOLO trains on full images and directly optimizes detec-\ntion performance. This uni\ufb01ed model has several bene\ufb01ts\nover traditional methods of object detection.\nFirst, YOLO is extremely fast. Since we frame detection\nas a regression problem we don\u2019t need a complex pipeline.\nWe simply run our neural network on a new image at test\ntime to predict detections. Our base network runs at 45\nframes per second with no batch processing on a Titan X\nGPU and a fast version runs at more than 150 fps. This\nmeans we can process streaming video in real-time with\nless than 25 milliseconds of latency. Furthermore, YOLO\nachieves more than twice the mean average precision of\nother real-time systems. For a demo of our system running\nin real-time on a webcam please see our project webpage:\nhttp://pjreddie.com/yolo/ .\nSecond, YOLO reasons globally about the image when\n1arXiv:1506.02640v5  [cs.CV]  9 May 2016", "mimetype": "text/plain", "start_char_idx": 2097, "end_char_idx": 4404, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7f51159f-bedb-454b-8660-c708b6f4cfd3": {"__data__": {"id_": "7f51159f-bedb-454b-8660-c708b6f4cfd3", "embedding": null, "metadata": {"page_label": "2", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a7f759f7-53ba-405f-95aa-e857207648a9", "node_type": "4", "metadata": {"page_label": "2", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "82943a9dbb216594f79caab6e6c81309f9c34a7635bc66984ed96d25dca02836", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8b404941-c86e-441a-8386-322f01604985", "node_type": "1", "metadata": {}, "hash": "4d5024d23de8c0a713733e8141af22ce71ad4a4d139db4ee27ba80e0e36563a9", "class_name": "RelatedNodeInfo"}}, "text": "making predictions. Unlike sliding window and region\nproposal-based techniques, YOLO sees the entire image\nduring training and test time so it implicitly encodes contex-\ntual information about classes as well as their appearance.\nFast R-CNN, a top detection method [14], mistakes back-\nground patches in an image for objects because it can\u2019t see\nthe larger context. YOLO makes less than half the number\nof background errors compared to Fast R-CNN.\nThird, YOLO learns generalizable representations of ob-\njects. When trained on natural images and tested on art-\nwork, YOLO outperforms top detection methods like DPM\nand R-CNN by a wide margin. Since YOLO is highly gen-\neralizable it is less likely to break down when applied to\nnew domains or unexpected inputs.\nYOLO still lags behind state-of-the-art detection systems\nin accuracy. While it can quickly identify objects in im-\nages it struggles to precisely localize some objects, espe-\ncially small ones. We examine these tradeoffs further in our\nexperiments.\nAll of our training and testing code is open source. A\nvariety of pretrained models are also available to download.\n2. Uni\ufb01ed Detection\nWe unify the separate components of object detection\ninto a single neural network. Our network uses features\nfrom the entire image to predict each bounding box. It also\npredicts all bounding boxes across all classes for an im-\nage simultaneously. This means our network reasons glob-\nally about the full image and all the objects in the image.\nThe YOLO design enables end-to-end training and real-\ntime speeds while maintaining high average precision.\nOur system divides the input image into an S\u00d7Sgrid.\nIf the center of an object falls into a grid cell, that grid cell\nis responsible for detecting that object.\nEach grid cell predicts Bbounding boxes and con\ufb01dence\nscores for those boxes. These con\ufb01dence scores re\ufb02ect how\ncon\ufb01dent the model is that the box contains an object and\nalso how accurate it thinks the box is that it predicts. For-\nmally we de\ufb01ne con\ufb01dence as Pr(Object )\u2217IOUtruth\npred. If no\nobject exists in that cell, the con\ufb01dence scores should be\nzero. Otherwise we want the con\ufb01dence score to equal the\nintersection over union (IOU) between the predicted box\nand the ground truth.\nEach bounding box consists of 5 predictions: x,y,w,h,\nand con\ufb01dence. The (x,y)coordinates represent the center\nof the box relative to the bounds of the grid cell. The width\nand height are predicted relative to the whole image. Finally\nthe con\ufb01dence prediction represents the IOU between the\npredicted box and any ground truth box.\nEach grid cell also predicts Cconditional class proba-\nbilities, Pr(Classi|Object ). These probabilities are condi-\ntioned on the grid cell containing an object. We only predictone set of class probabilities per grid cell, regardless of the\nnumber of boxes B.\nAt test time we multiply the conditional class probabili-\nties and the individual box con\ufb01dence predictions,\nPr(Classi|Object )\u2217Pr(Object )\u2217IOUtruth\npred= Pr( Classi)\u2217IOUtruth\npred(1)\nwhich gives us class-speci\ufb01c con\ufb01dence scores for each\nbox. These scores encode both the probability of that class\nappearing in the box and how well the predicted box \ufb01ts the\nobject.\nS \u00d7 S grid on inputBounding boxes + confidence\nClass probability mapFinal detections\nFigure 2: The Model. Our system models detection as a regres-\nsion problem. It divides the image into an S\u00d7Sgrid and for each\ngrid cell predicts Bbounding boxes, con\ufb01dence for those boxes,\nandCclass probabilities. These predictions are encoded as an\nS\u00d7S\u00d7(B\u22175 +C)tensor.\nFor evaluating YOLO on P ASCAL VOC, we use S= 7,\nB= 2. PASCAL VOC has 20 labelled classes so C= 20 .\nOur \ufb01nal prediction is a 7\u00d77\u00d730tensor.\n2.1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3704, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8b404941-c86e-441a-8386-322f01604985": {"__data__": {"id_": "8b404941-c86e-441a-8386-322f01604985", "embedding": null, "metadata": {"page_label": "2", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a7f759f7-53ba-405f-95aa-e857207648a9", "node_type": "4", "metadata": {"page_label": "2", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "82943a9dbb216594f79caab6e6c81309f9c34a7635bc66984ed96d25dca02836", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7f51159f-bedb-454b-8660-c708b6f4cfd3", "node_type": "1", "metadata": {"page_label": "2", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "bc5e11462f219308e7ade3145814e526cd98a8b1bfd29ab2a466ea8cad5fa0cc", "class_name": "RelatedNodeInfo"}}, "text": "For-\nmally we de\ufb01ne con\ufb01dence as Pr(Object )\u2217IOUtruth\npred. If no\nobject exists in that cell, the con\ufb01dence scores should be\nzero. Otherwise we want the con\ufb01dence score to equal the\nintersection over union (IOU) between the predicted box\nand the ground truth.\nEach bounding box consists of 5 predictions: x,y,w,h,\nand con\ufb01dence. The (x,y)coordinates represent the center\nof the box relative to the bounds of the grid cell. The width\nand height are predicted relative to the whole image. Finally\nthe con\ufb01dence prediction represents the IOU between the\npredicted box and any ground truth box.\nEach grid cell also predicts Cconditional class proba-\nbilities, Pr(Classi|Object ). These probabilities are condi-\ntioned on the grid cell containing an object. We only predictone set of class probabilities per grid cell, regardless of the\nnumber of boxes B.\nAt test time we multiply the conditional class probabili-\nties and the individual box con\ufb01dence predictions,\nPr(Classi|Object )\u2217Pr(Object )\u2217IOUtruth\npred= Pr( Classi)\u2217IOUtruth\npred(1)\nwhich gives us class-speci\ufb01c con\ufb01dence scores for each\nbox. These scores encode both the probability of that class\nappearing in the box and how well the predicted box \ufb01ts the\nobject.\nS \u00d7 S grid on inputBounding boxes + confidence\nClass probability mapFinal detections\nFigure 2: The Model. Our system models detection as a regres-\nsion problem. It divides the image into an S\u00d7Sgrid and for each\ngrid cell predicts Bbounding boxes, con\ufb01dence for those boxes,\nandCclass probabilities. These predictions are encoded as an\nS\u00d7S\u00d7(B\u22175 +C)tensor.\nFor evaluating YOLO on P ASCAL VOC, we use S= 7,\nB= 2. PASCAL VOC has 20 labelled classes so C= 20 .\nOur \ufb01nal prediction is a 7\u00d77\u00d730tensor.\n2.1. Network Design\nWe implement this model as a convolutional neural net-\nwork and evaluate it on the P ASCAL VOC detection dataset\n[9]. The initial convolutional layers of the network extract\nfeatures from the image while the fully connected layers\npredict the output probabilities and coordinates.\nOur network architecture is inspired by the GoogLeNet\nmodel for image classi\ufb01cation [34]. Our network has 24\nconvolutional layers followed by 2 fully connected layers.\nInstead of the inception modules used by GoogLeNet, we\nsimply use 1\u00d71reduction layers followed by 3\u00d73convo-\nlutional layers, similar to Lin et al [22]. The full network is\nshown in Figure 3.\nWe also train a fast version of YOLO designed to push\nthe boundaries of fast object detection. Fast YOLO uses a\nneural network with fewer convolutional layers (9 instead\nof 24) and fewer \ufb01lters in those layers. Other than the size\nof the network, all training and testing parameters are the\nsame between YOLO and Fast YOLO.", "mimetype": "text/plain", "start_char_idx": 1987, "end_char_idx": 4683, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "52b70eec-4bbf-4808-9f3d-846741182718": {"__data__": {"id_": "52b70eec-4bbf-4808-9f3d-846741182718", "embedding": null, "metadata": {"page_label": "3", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "843edcee-ff4d-4ea1-a259-ca5a30230a95", "node_type": "4", "metadata": {"page_label": "3", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "91dfb769ea2f17a73676d1e5a6b5a7cf20eefd95df04f458af54db8ecfcd8680", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5b5077b9-38da-4c25-ade2-27760f6ac782", "node_type": "1", "metadata": {}, "hash": "e1bea0ad5363a8b285a62650c5621a256ef320463d2cdcdf4b25f49a13b6416c", "class_name": "RelatedNodeInfo"}}, "text": "448\n448\n3\n7\n7\nConv. Layer\n7x7x64-s-2\nMaxpool Layer\n2x2-s-2\n3\n3112\n112\n192\n3\n356\n56\n256\nConn. Layer4096\nConn. Layer Conv. Layer\n3x3x192\nMaxpool Layer\n2x2-s-2Conv. Layers\n1x1x128\n3x3x256\n1x1x256\n3x3x512\nMaxpool Layer\n2x2-s-2\n3\n328\n28\n512\nConv. Layers\n1x1x256\n3x3x5121x1x512\n3x3x1024\nMaxpool Layer\n2x2-s-2\n3\n314\n14\n1024\nConv. Layers\n1x1x512\n3x3x10243x3x1024\n3x3x1024-s-2\n3\n37\n7\n10247\n7\n10247\n7\n30\n} \u00d74 } \u00d72Conv. Layers\n3x3x1024\n3x3x1024Figure 3: The Architecture. Our detection network has 24 convolutional layers followed by 2 fully connected layers. Alternating 1\u00d71\nconvolutional layers reduce the features space from preceding layers. We pretrain the convolutional layers on the ImageNet classi\ufb01cation\ntask at half the resolution ( 224\u00d7224input image) and then double the resolution for detection.\nThe \ufb01nal output of our network is the 7\u00d77\u00d730tensor\nof predictions.\n2.2. Training\nWe pretrain our convolutional layers on the ImageNet\n1000-class competition dataset [30]. For pretraining we use\nthe \ufb01rst 20 convolutional layers from Figure 3 followed by a\naverage-pooling layer and a fully connected layer. We train\nthis network for approximately a week and achieve a single\ncrop top-5 accuracy of 88% on the ImageNet 2012 valida-\ntion set, comparable to the GoogLeNet models in Caffe\u2019s\nModel Zoo [24]. We use the Darknet framework for all\ntraining and inference [26].\nWe then convert the model to perform detection. Ren et\nal. show that adding both convolutional and connected lay-\ners to pretrained networks can improve performance [29].\nFollowing their example, we add four convolutional lay-\ners and two fully connected layers with randomly initialized\nweights. Detection often requires \ufb01ne-grained visual infor-\nmation so we increase the input resolution of the network\nfrom 224\u00d7224to448\u00d7448.\nOur \ufb01nal layer predicts both class probabilities and\nbounding box coordinates. We normalize the bounding box\nwidth and height by the image width and height so that they\nfall between 0 and 1. We parametrize the bounding box x\nandycoordinates to be offsets of a particular grid cell loca-\ntion so they are also bounded between 0 and 1.\nWe use a linear activation function for the \ufb01nal layer and\nall other layers use the following leaky recti\ufb01ed linear acti-\nvation:\n\u03c6(x) ={\nx, ifx>0\n0.1x,otherwise(2)\nWe optimize for sum-squared error in the output of ourmodel. We use sum-squared error because it is easy to op-\ntimize, however it does not perfectly align with our goal of\nmaximizing average precision. It weights localization er-\nror equally with classi\ufb01cation error which may not be ideal.\nAlso, in every image many grid cells do not contain any\nobject. This pushes the \u201ccon\ufb01dence\u201d scores of those cells\ntowards zero, often overpowering the gradient from cells\nthat do contain objects. This can lead to model instability,\ncausing training to diverge early on.\nTo remedy this, we increase the loss from bounding box\ncoordinate predictions and decrease the loss from con\ufb01-\ndence predictions for boxes that don\u2019t contain objects. We\nuse two parameters, \u03bbcoordand\u03bbnoobjto accomplish this. We\nset\u03bbcoord= 5and\u03bbnoobj=.5.\nSum-squared error also equally weights errors in large\nboxes and small boxes. Our error metric should re\ufb02ect that\nsmall deviations in large boxes matter less than in small\nboxes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3288, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b5077b9-38da-4c25-ade2-27760f6ac782": {"__data__": {"id_": "5b5077b9-38da-4c25-ade2-27760f6ac782", "embedding": null, "metadata": {"page_label": "3", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "843edcee-ff4d-4ea1-a259-ca5a30230a95", "node_type": "4", "metadata": {"page_label": "3", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "91dfb769ea2f17a73676d1e5a6b5a7cf20eefd95df04f458af54db8ecfcd8680", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "52b70eec-4bbf-4808-9f3d-846741182718", "node_type": "1", "metadata": {"page_label": "3", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "5deabf76fb03f095a6fd82f84edfa1f60ab7749353ff9b2a1372cf73dd1d6424", "class_name": "RelatedNodeInfo"}}, "text": "We use the Darknet framework for all\ntraining and inference [26].\nWe then convert the model to perform detection. Ren et\nal. show that adding both convolutional and connected lay-\ners to pretrained networks can improve performance [29].\nFollowing their example, we add four convolutional lay-\ners and two fully connected layers with randomly initialized\nweights. Detection often requires \ufb01ne-grained visual infor-\nmation so we increase the input resolution of the network\nfrom 224\u00d7224to448\u00d7448.\nOur \ufb01nal layer predicts both class probabilities and\nbounding box coordinates. We normalize the bounding box\nwidth and height by the image width and height so that they\nfall between 0 and 1. We parametrize the bounding box x\nandycoordinates to be offsets of a particular grid cell loca-\ntion so they are also bounded between 0 and 1.\nWe use a linear activation function for the \ufb01nal layer and\nall other layers use the following leaky recti\ufb01ed linear acti-\nvation:\n\u03c6(x) ={\nx, ifx>0\n0.1x,otherwise(2)\nWe optimize for sum-squared error in the output of ourmodel. We use sum-squared error because it is easy to op-\ntimize, however it does not perfectly align with our goal of\nmaximizing average precision. It weights localization er-\nror equally with classi\ufb01cation error which may not be ideal.\nAlso, in every image many grid cells do not contain any\nobject. This pushes the \u201ccon\ufb01dence\u201d scores of those cells\ntowards zero, often overpowering the gradient from cells\nthat do contain objects. This can lead to model instability,\ncausing training to diverge early on.\nTo remedy this, we increase the loss from bounding box\ncoordinate predictions and decrease the loss from con\ufb01-\ndence predictions for boxes that don\u2019t contain objects. We\nuse two parameters, \u03bbcoordand\u03bbnoobjto accomplish this. We\nset\u03bbcoord= 5and\u03bbnoobj=.5.\nSum-squared error also equally weights errors in large\nboxes and small boxes. Our error metric should re\ufb02ect that\nsmall deviations in large boxes matter less than in small\nboxes. To partially address this we predict the square root\nof the bounding box width and height instead of the width\nand height directly.\nYOLO predicts multiple bounding boxes per grid cell.\nAt training time we only want one bounding box predictor\nto be responsible for each object. We assign one predictor\nto be \u201cresponsible\u201d for predicting an object based on which\nprediction has the highest current IOU with the ground\ntruth. This leads to specialization between the bounding box\npredictors. Each predictor gets better at predicting certain\nsizes, aspect ratios, or classes of object, improving overall\nrecall.\nDuring training we optimize the following, multi-part", "mimetype": "text/plain", "start_char_idx": 1300, "end_char_idx": 3950, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bf16bae2-7474-4276-af73-3b05272afb9a": {"__data__": {"id_": "bf16bae2-7474-4276-af73-3b05272afb9a", "embedding": null, "metadata": {"page_label": "4", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "15025bec-e1d7-44d2-bf61-e5c8889d7989", "node_type": "4", "metadata": {"page_label": "4", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "9ef2ffd061562d6d99ccc87feafc87a1818e52d15cd6a3850f19f86e2abddde0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "373b31a5-6106-4f6b-bc14-29d11081ed1a", "node_type": "1", "metadata": {}, "hash": "24ce44c940d1b856e8e337f16dadc7cd7fc4b8a24c28631bf0dc03b81f8e9c71", "class_name": "RelatedNodeInfo"}}, "text": "loss function:\n\u03bbcoordS2\u2211\ni=0B\u2211\nj=01obj\nij[\n(xi\u2212\u02c6xi)2+ (yi\u2212\u02c6yi)2]\n+\u03bbcoordS2\u2211\ni=0B\u2211\nj=01obj\nij[(\u221awi\u2212\u221a\n\u02c6wi)2+(\u221a\nhi\u2212\u221a\n\u02c6hi)2]\n+S2\u2211\ni=0B\u2211\nj=01obj\nij(\nCi\u2212\u02c6Ci)2\n+\u03bbnoobjS2\u2211\ni=0B\u2211\nj=01noobj\nij(\nCi\u2212\u02c6Ci)2\n+S2\u2211\ni=01obj\ni\u2211\nc\u2208classes(pi(c)\u2212\u02c6pi(c))2(3)\nwhere 1obj\nidenotes if object appears in cell iand 1obj\nijde-\nnotes that the jth bounding box predictor in cell iis \u201cre-\nsponsible\u201d for that prediction.\nNote that the loss function only penalizes classi\ufb01cation\nerror if an object is present in that grid cell (hence the con-\nditional class probability discussed earlier). It also only pe-\nnalizes bounding box coordinate error if that predictor is\n\u201cresponsible\u201d for the ground truth box (i.e. has the highest\nIOU of any predictor in that grid cell).\nWe train the network for about 135 epochs on the train-\ning and validation data sets from P ASCAL VOC 2007 and\n2012. When testing on 2012 we also include the VOC 2007\ntest data for training. Throughout training we use a batch\nsize of 64, a momentum of 0.9and a decay of 0.0005 .\nOur learning rate schedule is as follows: For the \ufb01rst\nepochs we slowly raise the learning rate from 10\u22123to10\u22122.\nIf we start at a high learning rate our model often diverges\ndue to unstable gradients. We continue training with 10\u22122\nfor 75 epochs, then 10\u22123for 30 epochs, and \ufb01nally 10\u22124\nfor 30 epochs.\nTo avoid over\ufb01tting we use dropout and extensive data\naugmentation. A dropout layer with rate = .5 after the \ufb01rst\nconnected layer prevents co-adaptation between layers [18].\nFor data augmentation we introduce random scaling and\ntranslations of up to 20% of the original image size. We\nalso randomly adjust the exposure and saturation of the im-\nage by up to a factor of 1.5in the HSV color space.\n2.3. Inference\nJust like in training, predicting detections for a test image\nonly requires one network evaluation. On P ASCAL VOC the\nnetwork predicts 98 bounding boxes per image and class\nprobabilities for each box. YOLO is extremely fast at test\ntime since it only requires a single network evaluation, un-\nlike classi\ufb01er-based methods.\nThe grid design enforces spatial diversity in the bound-\ning box predictions. Often it is clear which grid cell an\nobject falls in to and the network only predicts one box for\neach object. However, some large objects or objects nearthe border of multiple cells can be well localized by multi-\nple cells. Non-maximal suppression can be used to \ufb01x these\nmultiple detections. While not critical to performance as it\nis for R-CNN or DPM, non-maximal suppression adds 2-\n3% in mAP.\n2.4. Limitations of YOLO\nYOLO imposes strong spatial constraints on bounding\nbox predictions since each grid cell only predicts two boxes\nand can only have one class. This spatial constraint lim-\nits the number of nearby objects that our model can pre-\ndict. Our model struggles with small objects that appear in\ngroups, such as \ufb02ocks of birds.\nSince our model learns to predict bounding boxes from\ndata, it struggles to generalize to objects in new or unusual\naspect ratios or con\ufb01gurations. Our model also uses rela-\ntively coarse features for predicting bounding boxes since\nour architecture has multiple downsampling layers from the\ninput image.\nFinally, while we train on a loss function that approxi-\nmates detection performance, our loss function treats errors\nthe same in small bounding boxes versus large bounding\nboxes.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3359, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "373b31a5-6106-4f6b-bc14-29d11081ed1a": {"__data__": {"id_": "373b31a5-6106-4f6b-bc14-29d11081ed1a", "embedding": null, "metadata": {"page_label": "4", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "15025bec-e1d7-44d2-bf61-e5c8889d7989", "node_type": "4", "metadata": {"page_label": "4", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "9ef2ffd061562d6d99ccc87feafc87a1818e52d15cd6a3850f19f86e2abddde0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf16bae2-7474-4276-af73-3b05272afb9a", "node_type": "1", "metadata": {"page_label": "4", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "f1e85b3779b7cf2c145b70cd7d38982266b01ca3ed6667ca7250e01cb0deb42a", "class_name": "RelatedNodeInfo"}}, "text": "To avoid over\ufb01tting we use dropout and extensive data\naugmentation. A dropout layer with rate = .5 after the \ufb01rst\nconnected layer prevents co-adaptation between layers [18].\nFor data augmentation we introduce random scaling and\ntranslations of up to 20% of the original image size. We\nalso randomly adjust the exposure and saturation of the im-\nage by up to a factor of 1.5in the HSV color space.\n2.3. Inference\nJust like in training, predicting detections for a test image\nonly requires one network evaluation. On P ASCAL VOC the\nnetwork predicts 98 bounding boxes per image and class\nprobabilities for each box. YOLO is extremely fast at test\ntime since it only requires a single network evaluation, un-\nlike classi\ufb01er-based methods.\nThe grid design enforces spatial diversity in the bound-\ning box predictions. Often it is clear which grid cell an\nobject falls in to and the network only predicts one box for\neach object. However, some large objects or objects nearthe border of multiple cells can be well localized by multi-\nple cells. Non-maximal suppression can be used to \ufb01x these\nmultiple detections. While not critical to performance as it\nis for R-CNN or DPM, non-maximal suppression adds 2-\n3% in mAP.\n2.4. Limitations of YOLO\nYOLO imposes strong spatial constraints on bounding\nbox predictions since each grid cell only predicts two boxes\nand can only have one class. This spatial constraint lim-\nits the number of nearby objects that our model can pre-\ndict. Our model struggles with small objects that appear in\ngroups, such as \ufb02ocks of birds.\nSince our model learns to predict bounding boxes from\ndata, it struggles to generalize to objects in new or unusual\naspect ratios or con\ufb01gurations. Our model also uses rela-\ntively coarse features for predicting bounding boxes since\nour architecture has multiple downsampling layers from the\ninput image.\nFinally, while we train on a loss function that approxi-\nmates detection performance, our loss function treats errors\nthe same in small bounding boxes versus large bounding\nboxes. A small error in a large box is generally benign but a\nsmall error in a small box has a much greater effect on IOU.\nOur main source of error is incorrect localizations.\n3. Comparison to Other Detection Systems\nObject detection is a core problem in computer vision.\nDetection pipelines generally start by extracting a set of\nrobust features from input images (Haar [25], SIFT [23],\nHOG [4], convolutional features [6]). Then, classi\ufb01ers\n[36, 21, 13, 10] or localizers [1, 32] are used to identify\nobjects in the feature space. These classi\ufb01ers or localizers\nare run either in sliding window fashion over the whole im-\nage or on some subset of regions in the image [35, 15, 39].\nWe compare the YOLO detection system to several top de-\ntection frameworks, highlighting key similarities and differ-\nences.\nDeformable parts models. Deformable parts models\n(DPM) use a sliding window approach to object detection\n[10]. DPM uses a disjoint pipeline to extract static features,\nclassify regions, predict bounding boxes for high scoring\nregions, etc. Our system replaces all of these disparate parts\nwith a single convolutional neural network. The network\nperforms feature extraction, bounding box prediction, non-\nmaximal suppression, and contextual reasoning all concur-\nrently. Instead of static features, the network trains the fea-\ntures in-line and optimizes them for the detection task. Our\nuni\ufb01ed architecture leads to a faster, more accurate model\nthan DPM.\nR-CNN. R-CNN and its variants use region proposals in-\nstead of sliding windows to \ufb01nd objects in images. Selective", "mimetype": "text/plain", "start_char_idx": 1317, "end_char_idx": 4933, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b68fae12-9a8e-408f-a503-d7bf7e9d4b00": {"__data__": {"id_": "b68fae12-9a8e-408f-a503-d7bf7e9d4b00", "embedding": null, "metadata": {"page_label": "5", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d128bc4c-f689-413d-bc9c-211e33e45f6d", "node_type": "4", "metadata": {"page_label": "5", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "ef02cb01e20daa9e84a00a1df1c2cea76ede8b3933bf9216faf8e48224969962", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "734cd577-5821-4faf-b9f0-a6e729f369aa", "node_type": "1", "metadata": {}, "hash": "a3aef630ea36833a49c2324ecc46016a27859ac95cff6dccbd16223a08f6162e", "class_name": "RelatedNodeInfo"}}, "text": "Search [35] generates potential bounding boxes, a convolu-\ntional network extracts features, an SVM scores the boxes, a\nlinear model adjusts the bounding boxes, and non-max sup-\npression eliminates duplicate detections. Each stage of this\ncomplex pipeline must be precisely tuned independently\nand the resulting system is very slow, taking more than 40\nseconds per image at test time [14].\nYOLO shares some similarities with R-CNN. Each grid\ncell proposes potential bounding boxes and scores those\nboxes using convolutional features. However, our system\nputs spatial constraints on the grid cell proposals which\nhelps mitigate multiple detections of the same object. Our\nsystem also proposes far fewer bounding boxes, only 98\nper image compared to about 2000 from Selective Search.\nFinally, our system combines these individual components\ninto a single, jointly optimized model.\nOther Fast Detectors Fast and Faster R-CNN focus on\nspeeding up the R-CNN framework by sharing computa-\ntion and using neural networks to propose regions instead\nof Selective Search [14] [28]. While they offer speed and\naccuracy improvements over R-CNN, both still fall short of\nreal-time performance.\nMany research efforts focus on speeding up the DPM\npipeline [31] [38] [5]. They speed up HOG computation,\nuse cascades, and push computation to GPUs. However,\nonly 30Hz DPM [31] actually runs in real-time.\nInstead of trying to optimize individual components of\na large detection pipeline, YOLO throws out the pipeline\nentirely and is fast by design.\nDetectors for single classes like faces or people can be\nhighly optimized since they have to deal with much less\nvariation [37]. YOLO is a general purpose detector that\nlearns to detect a variety of objects simultaneously.\nDeep MultiBox. Unlike R-CNN, Szegedy et al. train a\nconvolutional neural network to predict regions of interest\n[8] instead of using Selective Search. MultiBox can also\nperform single object detection by replacing the con\ufb01dence\nprediction with a single class prediction. However, Multi-\nBox cannot perform general object detection and is still just\na piece in a larger detection pipeline, requiring further im-\nage patch classi\ufb01cation. Both YOLO and MultiBox use a\nconvolutional network to predict bounding boxes in an im-\nage but YOLO is a complete detection system.\nOverFeat. Sermanet et al. train a convolutional neural\nnetwork to perform localization and adapt that localizer to\nperform detection [32]. OverFeat ef\ufb01ciently performs slid-\ning window detection but it is still a disjoint system. Over-\nFeat optimizes for localization, not detection performance.\nLike DPM, the localizer only sees local information when\nmaking a prediction. OverFeat cannot reason about global\ncontext and thus requires signi\ufb01cant post-processing to pro-\nduce coherent detections.\nMultiGrasp. Our work is similar in design to work ongrasp detection by Redmon et al [27]. Our grid approach to\nbounding box prediction is based on the MultiGrasp system\nfor regression to grasps. However, grasp detection is a much\nsimpler task than object detection. MultiGrasp only needs\nto predict a single graspable region for an image containing\none object. It doesn\u2019t have to estimate the size, location,\nor boundaries of the object or predict it\u2019s class, only \ufb01nd a\nregion suitable for grasping. YOLO predicts both bounding\nboxes and class probabilities for multiple objects of multi-\nple classes in an image.\n4. Experiments\nFirst we compare YOLO with other real-time detection\nsystems on P ASCAL VOC 2007. To understand the differ-\nences between YOLO and R-CNN variants we explore the\nerrors on VOC 2007 made by YOLO and Fast R-CNN, one\nof the highest performing versions of R-CNN [14]. Based\non the different error pro\ufb01les we show that YOLO can be\nused to rescore Fast R-CNN detections and reduce the er-\nrors from background false positives, giving a signi\ufb01cant\nperformance boost. We also present VOC 2012 results and\ncompare mAP to current state-of-the-art methods. Finally,\nwe show that YOLO generalizes to new domains better than\nother detectors on two artwork datasets.\n4.1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4105, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "734cd577-5821-4faf-b9f0-a6e729f369aa": {"__data__": {"id_": "734cd577-5821-4faf-b9f0-a6e729f369aa", "embedding": null, "metadata": {"page_label": "5", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d128bc4c-f689-413d-bc9c-211e33e45f6d", "node_type": "4", "metadata": {"page_label": "5", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "ef02cb01e20daa9e84a00a1df1c2cea76ede8b3933bf9216faf8e48224969962", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b68fae12-9a8e-408f-a503-d7bf7e9d4b00", "node_type": "1", "metadata": {"page_label": "5", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "584be43fe2a015d13e8638415ab5a89f261c793f95017204e288894b3391385a", "class_name": "RelatedNodeInfo"}}, "text": "Both YOLO and MultiBox use a\nconvolutional network to predict bounding boxes in an im-\nage but YOLO is a complete detection system.\nOverFeat. Sermanet et al. train a convolutional neural\nnetwork to perform localization and adapt that localizer to\nperform detection [32]. OverFeat ef\ufb01ciently performs slid-\ning window detection but it is still a disjoint system. Over-\nFeat optimizes for localization, not detection performance.\nLike DPM, the localizer only sees local information when\nmaking a prediction. OverFeat cannot reason about global\ncontext and thus requires signi\ufb01cant post-processing to pro-\nduce coherent detections.\nMultiGrasp. Our work is similar in design to work ongrasp detection by Redmon et al [27]. Our grid approach to\nbounding box prediction is based on the MultiGrasp system\nfor regression to grasps. However, grasp detection is a much\nsimpler task than object detection. MultiGrasp only needs\nto predict a single graspable region for an image containing\none object. It doesn\u2019t have to estimate the size, location,\nor boundaries of the object or predict it\u2019s class, only \ufb01nd a\nregion suitable for grasping. YOLO predicts both bounding\nboxes and class probabilities for multiple objects of multi-\nple classes in an image.\n4. Experiments\nFirst we compare YOLO with other real-time detection\nsystems on P ASCAL VOC 2007. To understand the differ-\nences between YOLO and R-CNN variants we explore the\nerrors on VOC 2007 made by YOLO and Fast R-CNN, one\nof the highest performing versions of R-CNN [14]. Based\non the different error pro\ufb01les we show that YOLO can be\nused to rescore Fast R-CNN detections and reduce the er-\nrors from background false positives, giving a signi\ufb01cant\nperformance boost. We also present VOC 2012 results and\ncompare mAP to current state-of-the-art methods. Finally,\nwe show that YOLO generalizes to new domains better than\nother detectors on two artwork datasets.\n4.1. Comparison to Other Real-Time Systems\nMany research efforts in object detection focus on mak-\ning standard detection pipelines fast. [5] [38] [31] [14] [17]\n[28] However, only Sadeghi et al. actually produce a de-\ntection system that runs in real-time (30 frames per second\nor better) [31]. We compare YOLO to their GPU imple-\nmentation of DPM which runs either at 30Hz or 100Hz.\nWhile the other efforts don\u2019t reach the real-time milestone\nwe also compare their relative mAP and speed to examine\nthe accuracy-performance tradeoffs available in object de-\ntection systems.\nFast YOLO is the fastest object detection method on\nPASCAL ; as far as we know, it is the fastest extant object\ndetector. With 52.7%mAP, it is more than twice as accurate\nas prior work on real-time detection. YOLO pushes mAP to\n63.4%while still maintaining real-time performance.\nWe also train YOLO using VGG-16. This model is more\naccurate but also signi\ufb01cantly slower than YOLO. It is use-\nful for comparison to other detection systems that rely on\nVGG-16 but since it is slower than real-time the rest of the\npaper focuses on our faster models.\nFastest DPM effectively speeds up DPM without sacri-\n\ufb01cing much mAP but it still misses real-time performance\nby a factor of 2 [38]. It also is limited by DPM\u2019s relatively\nlow accuracy on detection compared to neural network ap-\nproaches.\nR-CNN minus R replaces Selective Search with static\nbounding box proposals [20]. While it is much faster than", "mimetype": "text/plain", "start_char_idx": 2190, "end_char_idx": 5574, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6cb33439-2d56-4640-9022-86fe9e6637be": {"__data__": {"id_": "6cb33439-2d56-4640-9022-86fe9e6637be", "embedding": null, "metadata": {"page_label": "6", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c15b00da-3e3b-4f33-9f9a-a7968d7510d6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "64156be1f6c91e3c79d525d5a6ca56fb5d8aa58fe41bb6a9de6cc5a792f621a7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2ca6880e-0b18-41cd-aef3-617f3214d411", "node_type": "1", "metadata": {}, "hash": "6540aaffc00f4f626b549b9aca2c6f9e66d4d45ef2a479639f58708f32372c54", "class_name": "RelatedNodeInfo"}}, "text": "Real-Time Detectors Train mAP FPS\n100Hz DPM [31] 2007 16.0 100\n30Hz DPM [31] 2007 26.1 30\nFast YOLO 2007+2012 52.7 155\nYOLO 2007+2012 63.4 45\nLess Than Real-Time\nFastest DPM [38] 2007 30.4 15\nR-CNN Minus R [20] 2007 53.5 6\nFast R-CNN [14] 2007+2012 70.0 0.5\nFaster R-CNN VGG-16[28] 2007+2012 73.2 7\nFaster R-CNN ZF [28] 2007+2012 62.1 18\nYOLO VGG-16 2007+2012 66.4 21\nTable 1: Real-Time Systems on P ASCAL VOC 2007. Compar-\ning the performance and speed of fast detectors. Fast YOLO is\nthe fastest detector on record for P ASCAL VOC detection and is\nstill twice as accurate as any other real-time detector. YOLO is\n10 mAP more accurate than the fast version while still well above\nreal-time in speed.\nR-CNN, it still falls short of real-time and takes a signi\ufb01cant\naccuracy hit from not having good proposals.\nFast R-CNN speeds up the classi\ufb01cation stage of R-CNN\nbut it still relies on selective search which can take around\n2 seconds per image to generate bounding box proposals.\nThus it has high mAP but at 0.5fps it is still far from real-\ntime.\nThe recent Faster R-CNN replaces selective search with\na neural network to propose bounding boxes, similar to\nSzegedy et al. [8] In our tests, their most accurate model\nachieves 7 fps while a smaller, less accurate one runs at\n18 fps. The VGG-16 version of Faster R-CNN is 10 mAP\nhigher but is also 6 times slower than YOLO. The Zeiler-\nFergus Faster R-CNN is only 2.5 times slower than YOLO\nbut is also less accurate.\n4.2. VOC 2007 Error Analysis\nTo further examine the differences between YOLO and\nstate-of-the-art detectors, we look at a detailed breakdown\nof results on VOC 2007. We compare YOLO to Fast R-\nCNN since Fast R-CNN is one of the highest performing\ndetectors on P ASCAL and it\u2019s detections are publicly avail-\nable.\nWe use the methodology and tools of Hoiem et al. [19]\nFor each category at test time we look at the top N predic-\ntions for that category. Each prediction is either correct or\nit is classi\ufb01ed based on the type of error:\n\u2022Correct: correct class and IOU >.5\n\u2022Localization: correct class, .1<IOU<.5\n\u2022Similar: class is similar, IOU >.1\nCorrect: 71.6% Correct: 65.5%Loc: 8.6%Sim: 4.3%Other: 1.9%Background: 13.6%\nLoc: 19.0%Sim: 6.75%Other: 4.0%Background: 4.75%Fast R-CNN YOLOFigure 4: Error Analysis: Fast R-CNN vs. YOLO These\ncharts show the percentage of localization and background errors\nin the top N detections for various categories (N = # objects in that\ncategory).\n\u2022Other: class is wrong, IOU >.1\n\u2022Background: IOU <.1for any object\nFigure 4 shows the breakdown of each error type aver-\naged across all 20 classes.\nYOLO struggles to localize objects correctly. Localiza-\ntion errors account for more of YOLO\u2019s errors than all other\nsources combined. Fast R-CNN makes much fewer local-\nization errors but far more background errors. 13.6% of\nit\u2019s top detections are false positives that don\u2019t contain any\nobjects. Fast R-CNN is almost 3x more likely to predict\nbackground detections than YOLO.\n4.3.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2982, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2ca6880e-0b18-41cd-aef3-617f3214d411": {"__data__": {"id_": "2ca6880e-0b18-41cd-aef3-617f3214d411", "embedding": null, "metadata": {"page_label": "6", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c15b00da-3e3b-4f33-9f9a-a7968d7510d6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "64156be1f6c91e3c79d525d5a6ca56fb5d8aa58fe41bb6a9de6cc5a792f621a7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "6cb33439-2d56-4640-9022-86fe9e6637be", "node_type": "1", "metadata": {"page_label": "6", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "5b412644ec7bc89df786315d0b5f04e41763807bf4a27371535635977f187f42", "class_name": "RelatedNodeInfo"}}, "text": "The Zeiler-\nFergus Faster R-CNN is only 2.5 times slower than YOLO\nbut is also less accurate.\n4.2. VOC 2007 Error Analysis\nTo further examine the differences between YOLO and\nstate-of-the-art detectors, we look at a detailed breakdown\nof results on VOC 2007. We compare YOLO to Fast R-\nCNN since Fast R-CNN is one of the highest performing\ndetectors on P ASCAL and it\u2019s detections are publicly avail-\nable.\nWe use the methodology and tools of Hoiem et al. [19]\nFor each category at test time we look at the top N predic-\ntions for that category. Each prediction is either correct or\nit is classi\ufb01ed based on the type of error:\n\u2022Correct: correct class and IOU >.5\n\u2022Localization: correct class, .1<IOU<.5\n\u2022Similar: class is similar, IOU >.1\nCorrect: 71.6% Correct: 65.5%Loc: 8.6%Sim: 4.3%Other: 1.9%Background: 13.6%\nLoc: 19.0%Sim: 6.75%Other: 4.0%Background: 4.75%Fast R-CNN YOLOFigure 4: Error Analysis: Fast R-CNN vs. YOLO These\ncharts show the percentage of localization and background errors\nin the top N detections for various categories (N = # objects in that\ncategory).\n\u2022Other: class is wrong, IOU >.1\n\u2022Background: IOU <.1for any object\nFigure 4 shows the breakdown of each error type aver-\naged across all 20 classes.\nYOLO struggles to localize objects correctly. Localiza-\ntion errors account for more of YOLO\u2019s errors than all other\nsources combined. Fast R-CNN makes much fewer local-\nization errors but far more background errors. 13.6% of\nit\u2019s top detections are false positives that don\u2019t contain any\nobjects. Fast R-CNN is almost 3x more likely to predict\nbackground detections than YOLO.\n4.3. Combining Fast R-CNN and YOLO\nYOLO makes far fewer background mistakes than Fast\nR-CNN. By using YOLO to eliminate background detec-\ntions from Fast R-CNN we get a signi\ufb01cant boost in perfor-\nmance. For every bounding box that R-CNN predicts we\ncheck to see if YOLO predicts a similar box. If it does, we\ngive that prediction a boost based on the probability pre-\ndicted by YOLO and the overlap between the two boxes.\nThe best Fast R-CNN model achieves a mAP of 71.8%\non the VOC 2007 test set. When combined with YOLO, its\nmAP Combined Gain\nFast R-CNN 71.8 - -\nFast R-CNN (2007 data) 66.9 72.4 .6\nFast R-CNN (VGG-M) 59.2 72.4 .6\nFast R-CNN (CaffeNet) 57.1 72.1 .3\nYOLO 63.4 75.0 3.2\nTable 2: Model combination experiments on VOC 2007. We\nexamine the effect of combining various models with the best ver-\nsion of Fast R-CNN. Other versions of Fast R-CNN provide only\na small bene\ufb01t while YOLO provides a signi\ufb01cant performance\nboost.", "mimetype": "text/plain", "start_char_idx": 1375, "end_char_idx": 3915, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c27d9cfa-3b4a-4853-ae17-554eb3e4f3e2": {"__data__": {"id_": "c27d9cfa-3b4a-4853-ae17-554eb3e4f3e2", "embedding": null, "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "604d5b76-c572-4673-b2ec-3e8adea2b617", "node_type": "4", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "e7d035790735f27d059f4cb98161750a82d4d68b3add016f5b8c280cb8e8a604", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "962b04be-8f2a-4d63-9432-8b9a5520d3a2", "node_type": "1", "metadata": {}, "hash": "6477e9dbe3305ab62347c464b3af053da39b6ed7b268281ee6893b45d5c9e4f3", "class_name": "RelatedNodeInfo"}}, "text": "VOC 2012 test mAP aero bike bird boat bottle bus car cat chair cow table dog horse mbike personplant sheep sofa train tv\nMR CNN MORE DATA [11] 73.9 85.5 82.9 76.6 57.8 62.7 79.4 77.2 86.6 55.0 79.1 62.2 87.0 83.4 84.7 78.9 45.3 73.4 65.8 80.3 74.0\nHyperNet VGG 71.4 84.2 78.5 73.6 55.6 53.7 78.7 79.8 87.7 49.6 74.9 52.1 86.0 81.7 83.3 81.8 48.6 73.5 59.4 79.9 65.7\nHyperNet SP 71.3 84.1 78.3 73.3 55.5 53.6 78.6 79.6 87.5 49.5 74.9 52.1 85.6 81.6 83.2 81.6 48.4 73.2 59.3 79.7 65.6\nFast R-CNN + YOLO 70.7 83.4 78.5 73.5 55.8 43.4 79.1 73.1 89.4 49.4 75.5 57.0 87.5 80.9 81.0 74.7 41.8 71.5 68.5 82.1 67.2\nMR CNN SCNN [11] 70.7 85.0 79.6 71.5 55.3 57.7 76.0 73.9 84.6 50.5 74.3 61.7 85.5 79.9 81.7 76.4 41.0 69.0 61.2 77.7 72.1\nFaster R-CNN [28] 70.4 84.9 79.8 74.3 53.9 49.8 77.5 75.9 88.5 45.6 77.1 55.3 86.9 81.7 80.9 79.6 40.1 72.6 60.9 81.2 61.5\nDEEP ENS COCO 70.1 84.0 79.4 71.6 51.9 51.1 74.1 72.1 88.6 48.3 73.4 57.8 86.1 80.0 80.7 70.4 46.6 69.6 68.8 75.9 71.4\nNoC [29] 68.8 82.8 79.0 71.6 52.3 53.7 74.1 69.0 84.9 46.9 74.3 53.1 85.0 81.3 79.5 72.2 38.9 72.4 59.5 76.7 68.1\nFast R-CNN [14] 68.4 82.3 78.4 70.8 52.3 38.7 77.8 71.6 89.3 44.2 73.0 55.0 87.5 80.5 80.8 72.0 35.1 68.3 65.7 80.4 64.2\nUMICH FGS STRUCT 66.4 82.9 76.1 64.1 44.6 49.4 70.3 71.2 84.6 42.7 68.6 55.8 82.7 77.1 79.9 68.7 41.4 69.0 60.0 72.0 66.2\nNUS NIN C2000 [7] 63.8 80.2 73.8 61.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1363, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "962b04be-8f2a-4d63-9432-8b9a5520d3a2": {"__data__": {"id_": "962b04be-8f2a-4d63-9432-8b9a5520d3a2", "embedding": null, "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "604d5b76-c572-4673-b2ec-3e8adea2b617", "node_type": "4", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "e7d035790735f27d059f4cb98161750a82d4d68b3add016f5b8c280cb8e8a604", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c27d9cfa-3b4a-4853-ae17-554eb3e4f3e2", "node_type": "1", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "8abbdc3dbebd500a72ef6473975463d341d72b3183fa992211ad44d350a4cb58", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "93cedf8a-c8a6-40f0-b8df-c8e5128a6dbf", "node_type": "1", "metadata": {}, "hash": "f7033104f4f1c829fd517267f8eec13ac9a87a1908386273a52bc7f55b71eaad", "class_name": "RelatedNodeInfo"}}, "text": "0 69.0 61.2 77.7 72.1\nFaster R-CNN [28] 70.4 84.9 79.8 74.3 53.9 49.8 77.5 75.9 88.5 45.6 77.1 55.3 86.9 81.7 80.9 79.6 40.1 72.6 60.9 81.2 61.5\nDEEP ENS COCO 70.1 84.0 79.4 71.6 51.9 51.1 74.1 72.1 88.6 48.3 73.4 57.8 86.1 80.0 80.7 70.4 46.6 69.6 68.8 75.9 71.4\nNoC [29] 68.8 82.8 79.0 71.6 52.3 53.7 74.1 69.0 84.9 46.9 74.3 53.1 85.0 81.3 79.5 72.2 38.9 72.4 59.5 76.7 68.1\nFast R-CNN [14] 68.4 82.3 78.4 70.8 52.3 38.7 77.8 71.6 89.3 44.2 73.0 55.0 87.5 80.5 80.8 72.0 35.1 68.3 65.7 80.4 64.2\nUMICH FGS STRUCT 66.4 82.9 76.1 64.1 44.6 49.4 70.3 71.2 84.6 42.7 68.6 55.8 82.7 77.1 79.9 68.7 41.4 69.0 60.0 72.0 66.2\nNUS NIN C2000 [7] 63.8 80.2 73.8 61.9 43.7 43.0 70.3 67.6 80.7 41.9 69.7 51.7 78.2 75.2 76.9 65.1 38.6 68.3 58.0 68.7 63.3\nBabyLearning [7] 63.2 78.0 74.2 61.3 45.7 42.7 68.2 66.8 80.2 40.6 70.0 49.8 79.0 74.5 77.9 64.0 35.3 67.9 55.7 68.7 62.6\nNUS NIN 62.4 77.9 73.1 62.6 39.5 43.3 69.1 66.4 78.9 39.1 68.1 50.0 77.2 71.3 76.1 64.7 38.4 66.9 56.2 66.9 62.7\nR-CNN VGG BB [13] 62.4 79.6 72.7 61.9 41.2 41.9 65.9 66.4 84.6 38.5 67.2 46.7 82.0 74.8 76.0 65.2 35.6 65.4 54.2 67.4 60.3\nR-CNN VGG [13] 59.2 76.8 70.9 56.6 37.5 36.9 62.9 63.6 81.1 35.7 64.3 43.9 80.4 71.6 74.0 60.0 30.8 63.4 52.0 63.5 58.7\nYOLO 57.9 77.0 67.2 57.7 38.3 22.7 68.3 55.", "mimetype": "text/plain", "start_char_idx": 706, "end_char_idx": 1971, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "93cedf8a-c8a6-40f0-b8df-c8e5128a6dbf": {"__data__": {"id_": "93cedf8a-c8a6-40f0-b8df-c8e5128a6dbf", "embedding": null, "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "604d5b76-c572-4673-b2ec-3e8adea2b617", "node_type": "4", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "e7d035790735f27d059f4cb98161750a82d4d68b3add016f5b8c280cb8e8a604", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "962b04be-8f2a-4d63-9432-8b9a5520d3a2", "node_type": "1", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "2f74723115fc01f8efaf013c4029a1ea84f2bd9f48de86274826053476f3950f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "16d20fd5-f436-4401-bd65-5f9811920361", "node_type": "1", "metadata": {}, "hash": "29eb452e0e3b5b5f5ba3d633dd95f242f23aab79b5e66fa6d919723acb6df889", "class_name": "RelatedNodeInfo"}}, "text": "0 66.2\nNUS NIN C2000 [7] 63.8 80.2 73.8 61.9 43.7 43.0 70.3 67.6 80.7 41.9 69.7 51.7 78.2 75.2 76.9 65.1 38.6 68.3 58.0 68.7 63.3\nBabyLearning [7] 63.2 78.0 74.2 61.3 45.7 42.7 68.2 66.8 80.2 40.6 70.0 49.8 79.0 74.5 77.9 64.0 35.3 67.9 55.7 68.7 62.6\nNUS NIN 62.4 77.9 73.1 62.6 39.5 43.3 69.1 66.4 78.9 39.1 68.1 50.0 77.2 71.3 76.1 64.7 38.4 66.9 56.2 66.9 62.7\nR-CNN VGG BB [13] 62.4 79.6 72.7 61.9 41.2 41.9 65.9 66.4 84.6 38.5 67.2 46.7 82.0 74.8 76.0 65.2 35.6 65.4 54.2 67.4 60.3\nR-CNN VGG [13] 59.2 76.8 70.9 56.6 37.5 36.9 62.9 63.6 81.1 35.7 64.3 43.9 80.4 71.6 74.0 60.0 30.8 63.4 52.0 63.5 58.7\nYOLO 57.9 77.0 67.2 57.7 38.3 22.7 68.3 55.9 81.4 36.2 60.8 48.5 77.2 72.3 71.3 63.5 28.9 52.2 54.8 73.9 50.8\nFeature Edit [33] 56.3 74.6 69.1 54.4 39.1 33.1 65.2 62.7 69.7 30.8 56.0 44.6 70.0 64.4 71.1 60.2 33.3 61.3 46.4 61.7 57.8\nR-CNN BB [13] 53.3 71.8 65.8 52.0 34.1 32.6 59.6 60.0 69.8 27.6 52.0 41.7 69.6 61.3 68.3 57.8 29.6 57.8 40.9 59.3 54.1\nSDS [16] 50.7 69.7 58.4 48.5 28.3 28.8 61.3 57.5 70.8 24.1 50.7 35.9 64.9 59.1 65.8 57.1 26.0 58.8 38.6 58.9 50.7\nR-CNN [13] 49.6 68.1 63.8 46.1 29.4 27.9 56.6 57.0 65.9 26.5 48.7 39.5 66.2 57.3 65.4 53.2 26.2 54.5 38.1 50.6 51.6\nTable 3: PASCAL VOC 2012 Leaderboard. YOLO compared with the full comp4 (outside data allowed) public leaderboard as of\nNovember 6th, 2015.", "mimetype": "text/plain", "start_char_idx": 1320, "end_char_idx": 2649, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "16d20fd5-f436-4401-bd65-5f9811920361": {"__data__": {"id_": "16d20fd5-f436-4401-bd65-5f9811920361", "embedding": null, "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "604d5b76-c572-4673-b2ec-3e8adea2b617", "node_type": "4", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "e7d035790735f27d059f4cb98161750a82d4d68b3add016f5b8c280cb8e8a604", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "93cedf8a-c8a6-40f0-b8df-c8e5128a6dbf", "node_type": "1", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "6cfc4a4967ee66b561a029cad090057e0b677b4c397ba6d507203e13b209b084", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2a1166b5-5963-4208-9081-740b8c1d1e77", "node_type": "1", "metadata": {}, "hash": "025e30e348341f47005de46b263357138021331b32d228c32e261abe9741faaf", "class_name": "RelatedNodeInfo"}}, "text": "5 58.7\nYOLO 57.9 77.0 67.2 57.7 38.3 22.7 68.3 55.9 81.4 36.2 60.8 48.5 77.2 72.3 71.3 63.5 28.9 52.2 54.8 73.9 50.8\nFeature Edit [33] 56.3 74.6 69.1 54.4 39.1 33.1 65.2 62.7 69.7 30.8 56.0 44.6 70.0 64.4 71.1 60.2 33.3 61.3 46.4 61.7 57.8\nR-CNN BB [13] 53.3 71.8 65.8 52.0 34.1 32.6 59.6 60.0 69.8 27.6 52.0 41.7 69.6 61.3 68.3 57.8 29.6 57.8 40.9 59.3 54.1\nSDS [16] 50.7 69.7 58.4 48.5 28.3 28.8 61.3 57.5 70.8 24.1 50.7 35.9 64.9 59.1 65.8 57.1 26.0 58.8 38.6 58.9 50.7\nR-CNN [13] 49.6 68.1 63.8 46.1 29.4 27.9 56.6 57.0 65.9 26.5 48.7 39.5 66.2 57.3 65.4 53.2 26.2 54.5 38.1 50.6 51.6\nTable 3: PASCAL VOC 2012 Leaderboard. YOLO compared with the full comp4 (outside data allowed) public leaderboard as of\nNovember 6th, 2015. Mean average precision and per-class average precision are shown for a variety of detection methods. YOLO is the\nonly real-time detector. Fast R-CNN + YOLO is the forth highest scoring method, with a 2.3% boost over Fast R-CNN.\nmAP increases by 3.2% to 75.0%. We also tried combining\nthe top Fast R-CNN model with several other versions of\nFast R-CNN. Those ensembles produced small increases in\nmAP between .3 and .6%, see Table 2 for details.\nThe boost from YOLO is not simply a byproduct of\nmodel ensembling since there is little bene\ufb01t from combin-\ning different versions of Fast R-CNN. Rather, it is precisely\nbecause YOLO makes different kinds of mistakes at test\ntime that it is so effective at boosting Fast R-CNN\u2019s per-\nformance.\nUnfortunately, this combination doesn\u2019t bene\ufb01t from the\nspeed of YOLO since we run each model seperately and\nthen combine the results. However, since YOLO is so fast\nit doesn\u2019t add any signi\ufb01cant computational time compared\nto Fast R-CNN.\n4.4. VOC 2012 Results\nOn the VOC 2012 test set, YOLO scores 57.9% mAP.\nThis is lower than the current state of the art, closer to\nthe original R-CNN using VGG-16, see Table 3. Our sys-\ntem struggles with small objects compared to its closest\ncompetitors. On categories like bottle ,sheep , and\ntv/monitor YOLO scores 8-10% lower than R-CNN or\nFeature Edit. However, on other categories like cat and\ntrain YOLO achieves higher performance.\nOur combined Fast R-CNN + YOLO model is one of the\nhighest performing detection methods. Fast R-CNN gets\na 2.3% improvement from the combination with YOLO,\nboosting it 5 spots up on the public leaderboard.\n4.5.", "mimetype": "text/plain", "start_char_idx": 1921, "end_char_idx": 4277, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2a1166b5-5963-4208-9081-740b8c1d1e77": {"__data__": {"id_": "2a1166b5-5963-4208-9081-740b8c1d1e77", "embedding": null, "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "604d5b76-c572-4673-b2ec-3e8adea2b617", "node_type": "4", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "e7d035790735f27d059f4cb98161750a82d4d68b3add016f5b8c280cb8e8a604", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "16d20fd5-f436-4401-bd65-5f9811920361", "node_type": "1", "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "1d35585482951442028101a4e3005c644e383ed98564c9fb9f890e3aa5ee2ca0", "class_name": "RelatedNodeInfo"}}, "text": "6 51.6\nTable 3: PASCAL VOC 2012 Leaderboard. YOLO compared with the full comp4 (outside data allowed) public leaderboard as of\nNovember 6th, 2015. Mean average precision and per-class average precision are shown for a variety of detection methods. YOLO is the\nonly real-time detector. Fast R-CNN + YOLO is the forth highest scoring method, with a 2.3% boost over Fast R-CNN.\nmAP increases by 3.2% to 75.0%. We also tried combining\nthe top Fast R-CNN model with several other versions of\nFast R-CNN. Those ensembles produced small increases in\nmAP between .3 and .6%, see Table 2 for details.\nThe boost from YOLO is not simply a byproduct of\nmodel ensembling since there is little bene\ufb01t from combin-\ning different versions of Fast R-CNN. Rather, it is precisely\nbecause YOLO makes different kinds of mistakes at test\ntime that it is so effective at boosting Fast R-CNN\u2019s per-\nformance.\nUnfortunately, this combination doesn\u2019t bene\ufb01t from the\nspeed of YOLO since we run each model seperately and\nthen combine the results. However, since YOLO is so fast\nit doesn\u2019t add any signi\ufb01cant computational time compared\nto Fast R-CNN.\n4.4. VOC 2012 Results\nOn the VOC 2012 test set, YOLO scores 57.9% mAP.\nThis is lower than the current state of the art, closer to\nthe original R-CNN using VGG-16, see Table 3. Our sys-\ntem struggles with small objects compared to its closest\ncompetitors. On categories like bottle ,sheep , and\ntv/monitor YOLO scores 8-10% lower than R-CNN or\nFeature Edit. However, on other categories like cat and\ntrain YOLO achieves higher performance.\nOur combined Fast R-CNN + YOLO model is one of the\nhighest performing detection methods. Fast R-CNN gets\na 2.3% improvement from the combination with YOLO,\nboosting it 5 spots up on the public leaderboard.\n4.5. Generalizability: Person Detection in Artwork\nAcademic datasets for object detection draw the training\nand testing data from the same distribution. In real-world\napplications it is hard to predict all possible use cases andthe test data can diverge from what the system has seen be-\nfore [3]. We compare YOLO to other detection systems on\nthe Picasso Dataset [12] and the People-Art Dataset [3], two\ndatasets for testing person detection on artwork.\nFigure 5 shows comparative performance between\nYOLO and other detection methods. For reference, we give\nVOC 2007 detection AP on person where all models are\ntrained only on VOC 2007 data. On Picasso models are\ntrained on VOC 2012 while on People-Art they are trained\non VOC 2010.\nR-CNN has high AP on VOC 2007. However, R-CNN\ndrops off considerably when applied to artwork. R-CNN\nuses Selective Search for bounding box proposals which is\ntuned for natural images. The classi\ufb01er step in R-CNN only\nsees small regions and needs good proposals.\nDPM maintains its AP well when applied to artwork.\nPrior work theorizes that DPM performs well because it has\nstrong spatial models of the shape and layout of objects.\nThough DPM doesn\u2019t degrade as much as R-CNN, it starts\nfrom a lower AP.\nYOLO has good performance on VOC 2007 and its AP\ndegrades less than other methods when applied to artwork.\nLike DPM, YOLO models the size and shape of objects,\nas well as relationships between objects and where objects\ncommonly appear. Artwork and natural images are very\ndifferent on a pixel level but they are similar in terms of\nthe size and shape of objects, thus YOLO can still predict\ngood bounding boxes and detections.\n5. Real-Time Detection In The Wild\nYOLO is a fast, accurate object detector, making it ideal\nfor computer vision applications. We connect YOLO to a\nwebcam and verify that it maintains real-time performance,", "mimetype": "text/plain", "start_char_idx": 2503, "end_char_idx": 6143, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2547fd93-0bc3-4d4d-9be4-c89cbba0b856": {"__data__": {"id_": "2547fd93-0bc3-4d4d-9be4-c89cbba0b856", "embedding": null, "metadata": {"page_label": "8", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cfc5774c-dc55-4dbc-84c2-de2425f6b1b3", "node_type": "4", "metadata": {"page_label": "8", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "8707f8c69e485f9f7613119c2122e62dfe5dfbe69def35bf423c72055b9442cf", "class_name": "RelatedNodeInfo"}}, "text": "Poselets\nRCNN\nD&THumans\nDPMYOLO\n(a)Picasso Dataset precision-recall curves.VOC 2007 Picasso People-Art\nAP AP BestF1 AP\nYOLO 59.2 53.3 0.590 45\nR-CNN 54.2 10.4 0.226 26\nDPM 43.2 37.8 0.458 32\nPoselets [2] 36.5 17.8 0.271\nD&T [4] - 1.9 0.051\n(b)Quantitative results on the VOC 2007, Picasso, and People-Art Datasets.\nThe Picasso Dataset evaluates on both AP and best F1score.\nFigure 5: Generalization results on Picasso and People-Art datasets.\nFigure 6: Qualitative Results. YOLO running on sample artwork and natural images from the internet. It is mostly accurate although it\ndoes think one person is an airplane.\nincluding the time to fetch images from the camera and dis-\nplay the detections.\nThe resulting system is interactive and engaging. While\nYOLO processes images individually, when attached to a\nwebcam it functions like a tracking system, detecting ob-\njects as they move around and change in appearance. A\ndemo of the system and the source code can be found on\nour project website: http://pjreddie.com/yolo/ .\n6. Conclusion\nWe introduce YOLO, a uni\ufb01ed model for object detec-\ntion. Our model is simple to construct and can be traineddirectly on full images. Unlike classi\ufb01er-based approaches,\nYOLO is trained on a loss function that directly corresponds\nto detection performance and the entire model is trained\njointly.\nFast YOLO is the fastest general-purpose object detec-\ntor in the literature and YOLO pushes the state-of-the-art in\nreal-time object detection. YOLO also generalizes well to\nnew domains making it ideal for applications that rely on\nfast, robust object detection.\nAcknowledgements: This work is partially supported by\nONR N00014-13-1-0720, NSF IIS-1338054, and The Allen\nDistinguished Investigator Award.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1737, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f941853b-1b1e-4a48-abc3-9dbfd2911beb": {"__data__": {"id_": "f941853b-1b1e-4a48-abc3-9dbfd2911beb", "embedding": null, "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4cb244ef-d23a-4606-9cad-18afdc0ad3f9", "node_type": "4", "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "1c28a568f893e1c148a16f953e9e188eb69e5f5167c665dcf7a42c986cdeec3c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "248ecc26-f16e-4113-9488-3f432d6c5aac", "node_type": "1", "metadata": {}, "hash": "729e7b9b04c1719ebdbbf1fc8729ad43a0b9a55b57c0820c46715a019625702e", "class_name": "RelatedNodeInfo"}}, "text": "References\n[1] M. B. Blaschko and C. H. Lampert. Learning to localize ob-\njects with structured output regression. In Computer Vision\u2013\nECCV 2008 , pages 2\u201315. Springer, 2008. 4\n[2] L. Bourdev and J. Malik. Poselets: Body part detectors\ntrained using 3d human pose annotations. In International\nConference on Computer Vision (ICCV) , 2009. 8\n[3] H. Cai, Q. Wu, T. Corradi, and P. Hall. The cross-\ndepiction problem: Computer vision algorithms for recog-\nnising objects in artwork and in photographs. arXiv preprint\narXiv:1505.00110 , 2015. 7\n[4] N. Dalal and B. Triggs. Histograms of oriented gradients for\nhuman detection. In Computer Vision and Pattern Recogni-\ntion, 2005. CVPR 2005. IEEE Computer Society Conference\non, volume 1, pages 886\u2013893. IEEE, 2005. 4, 8\n[5] T. Dean, M. Ruzon, M. Segal, J. Shlens, S. Vijaya-\nnarasimhan, J. Yagnik, et al. Fast, accurate detection of\n100,000 object classes on a single machine. In Computer\nVision and Pattern Recognition (CVPR), 2013 IEEE Confer-\nence on , pages 1814\u20131821. IEEE, 2013. 5\n[6] J. Donahue, Y . Jia, O. Vinyals, J. Hoffman, N. Zhang,\nE. Tzeng, and T. Darrell. Decaf: A deep convolutional acti-\nvation feature for generic visual recognition. arXiv preprint\narXiv:1310.1531 , 2013. 4\n[7] J. Dong, Q. Chen, S. Yan, and A. Yuille. Towards uni\ufb01ed\nobject detection and semantic segmentation. In Computer\nVision\u2013ECCV 2014 , pages 299\u2013314. Springer, 2014. 7\n[8] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable\nobject detection using deep neural networks. In Computer\nVision and Pattern Recognition (CVPR), 2014 IEEE Confer-\nence on , pages 2155\u20132162. IEEE, 2014. 5, 6\n[9] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I.\nWilliams, J. Winn, and A. Zisserman. The pascal visual ob-\nject classes challenge: A retrospective. International Journal\nof Computer Vision , 111(1):98\u2013136, Jan. 2015. 2\n[10] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ra-\nmanan. Object detection with discriminatively trained part\nbased models. IEEE Transactions on Pattern Analysis and\nMachine Intelligence , 32(9):1627\u20131645, 2010. 1, 4\n[11] S. Gidaris and N. Komodakis. Object detection via a multi-\nregion & semantic segmentation-aware CNN model. CoRR ,\nabs/1505.01749, 2015. 7\n[12] S. Ginosar, D. Haas, T. Brown, and J. Malik. Detecting peo-\nple in cubist art. In Computer Vision-ECCV 2014 Workshops ,\npages 101\u2013116. Springer, 2014. 7\n[13] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich fea-\nture hierarchies for accurate object detection and semantic\nsegmentation. In Computer Vision and Pattern Recognition\n(CVPR), 2014 IEEE Conference on , pages 580\u2013587. IEEE,\n2014. 1, 4, 7\n[14] R. B. Girshick. Fast R-CNN.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2675, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "248ecc26-f16e-4113-9488-3f432d6c5aac": {"__data__": {"id_": "248ecc26-f16e-4113-9488-3f432d6c5aac", "embedding": null, "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4cb244ef-d23a-4606-9cad-18afdc0ad3f9", "node_type": "4", "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "1c28a568f893e1c148a16f953e9e188eb69e5f5167c665dcf7a42c986cdeec3c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f941853b-1b1e-4a48-abc3-9dbfd2911beb", "node_type": "1", "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "24cf3d8274ddf5e51ccd17d7adc30f18b993cc1418b1472fe971e4caa5e6c585", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8fcc9c46-6e03-435c-97e7-97a3638694a8", "node_type": "1", "metadata": {}, "hash": "4bb7e4647e51aa122d461cc37b77f31ec99c3a506fe5ca9b358c315c5e007a1d", "class_name": "RelatedNodeInfo"}}, "text": "In Computer\nVision\u2013ECCV 2014 , pages 299\u2013314. Springer, 2014. 7\n[8] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable\nobject detection using deep neural networks. In Computer\nVision and Pattern Recognition (CVPR), 2014 IEEE Confer-\nence on , pages 2155\u20132162. IEEE, 2014. 5, 6\n[9] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I.\nWilliams, J. Winn, and A. Zisserman. The pascal visual ob-\nject classes challenge: A retrospective. International Journal\nof Computer Vision , 111(1):98\u2013136, Jan. 2015. 2\n[10] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ra-\nmanan. Object detection with discriminatively trained part\nbased models. IEEE Transactions on Pattern Analysis and\nMachine Intelligence , 32(9):1627\u20131645, 2010. 1, 4\n[11] S. Gidaris and N. Komodakis. Object detection via a multi-\nregion & semantic segmentation-aware CNN model. CoRR ,\nabs/1505.01749, 2015. 7\n[12] S. Ginosar, D. Haas, T. Brown, and J. Malik. Detecting peo-\nple in cubist art. In Computer Vision-ECCV 2014 Workshops ,\npages 101\u2013116. Springer, 2014. 7\n[13] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich fea-\nture hierarchies for accurate object detection and semantic\nsegmentation. In Computer Vision and Pattern Recognition\n(CVPR), 2014 IEEE Conference on , pages 580\u2013587. IEEE,\n2014. 1, 4, 7\n[14] R. B. Girshick. Fast R-CNN. CoRR , abs/1504.08083, 2015.\n2, 5, 6, 7\n[15] S. Gould, T. Gao, and D. Koller. Region-based segmenta-\ntion and object detection. In Advances in neural information\nprocessing systems , pages 655\u2013663, 2009. 4[16] B. Hariharan, P. Arbel \u00b4aez, R. Girshick, and J. Malik. Simul-\ntaneous detection and segmentation. In Computer Vision\u2013\nECCV 2014 , pages 297\u2013312. Springer, 2014. 7\n[17] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling\nin deep convolutional networks for visual recognition. arXiv\npreprint arXiv:1406.4729 , 2014. 5\n[18] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and\nR. R. Salakhutdinov. Improving neural networks by pre-\nventing co-adaptation of feature detectors. arXiv preprint\narXiv:1207.0580 , 2012. 4\n[19] D. Hoiem, Y . Chodpathumwan, and Q. Dai. Diagnosing error\nin object detectors. In Computer Vision\u2013ECCV 2012 , pages\n340\u2013353. Springer, 2012. 6\n[20] K. Lenc and A. Vedaldi. R-cnn minus r. arXiv preprint\narXiv:1506.06981 , 2015. 5, 6\n[21] R. Lienhart and J. Maydt. An extended set of haar-like fea-\ntures for rapid object detection. In Image Processing. 2002.\nProceedings. 2002 International Conference on , volume 1,\npages I\u2013900. IEEE, 2002. 4\n[22] M. Lin, Q. Chen, and S. Yan.", "mimetype": "text/plain", "start_char_idx": 1343, "end_char_idx": 3900, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8fcc9c46-6e03-435c-97e7-97a3638694a8": {"__data__": {"id_": "8fcc9c46-6e03-435c-97e7-97a3638694a8", "embedding": null, "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4cb244ef-d23a-4606-9cad-18afdc0ad3f9", "node_type": "4", "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "1c28a568f893e1c148a16f953e9e188eb69e5f5167c665dcf7a42c986cdeec3c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "248ecc26-f16e-4113-9488-3f432d6c5aac", "node_type": "1", "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "6ed2186769c6b277e73792e274facba8138b67dc73a095d9405fdeafefcd2509", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "591c6e7e-fb52-49ea-9859-8b25f6932b1b", "node_type": "1", "metadata": {}, "hash": "c8aa4b26e01429b0bb2fa67788720c2fff2d99f5974626a2124ef810eda28a36", "class_name": "RelatedNodeInfo"}}, "text": "Fast R-CNN. CoRR , abs/1504.08083, 2015.\n2, 5, 6, 7\n[15] S. Gould, T. Gao, and D. Koller. Region-based segmenta-\ntion and object detection. In Advances in neural information\nprocessing systems , pages 655\u2013663, 2009. 4[16] B. Hariharan, P. Arbel \u00b4aez, R. Girshick, and J. Malik. Simul-\ntaneous detection and segmentation. In Computer Vision\u2013\nECCV 2014 , pages 297\u2013312. Springer, 2014. 7\n[17] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling\nin deep convolutional networks for visual recognition. arXiv\npreprint arXiv:1406.4729 , 2014. 5\n[18] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and\nR. R. Salakhutdinov. Improving neural networks by pre-\nventing co-adaptation of feature detectors. arXiv preprint\narXiv:1207.0580 , 2012. 4\n[19] D. Hoiem, Y . Chodpathumwan, and Q. Dai. Diagnosing error\nin object detectors. In Computer Vision\u2013ECCV 2012 , pages\n340\u2013353. Springer, 2012. 6\n[20] K. Lenc and A. Vedaldi. R-cnn minus r. arXiv preprint\narXiv:1506.06981 , 2015. 5, 6\n[21] R. Lienhart and J. Maydt. An extended set of haar-like fea-\ntures for rapid object detection. In Image Processing. 2002.\nProceedings. 2002 International Conference on , volume 1,\npages I\u2013900. IEEE, 2002. 4\n[22] M. Lin, Q. Chen, and S. Yan. Network in network. CoRR ,\nabs/1312.4400, 2013. 2\n[23] D. G. Lowe. Object recognition from local scale-invariant\nfeatures. In Computer vision, 1999. The proceedings of the\nseventh IEEE international conference on , volume 2, pages\n1150\u20131157. Ieee, 1999. 4\n[24] D. Mishkin. Models accuracy on imagenet 2012\nval. https://github.com/BVLC/caffe/wiki/\nModels-accuracy-on-ImageNet-2012-val . Ac-\ncessed: 2015-10-2. 3\n[25] C. P. Papageorgiou, M. Oren, and T. Poggio. A general\nframework for object detection. In Computer vision, 1998.\nsixth international conference on , pages 555\u2013562. IEEE,\n1998. 4\n[26] J. Redmon. Darknet: Open source neural networks in c.\nhttp://pjreddie.com/darknet/ , 2013\u20132016. 3\n[27] J. Redmon and A. Angelova. Real-time grasp detection using\nconvolutional neural networks. CoRR , abs/1412.3128, 2014.\n5\n[28] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: To-\nwards real-time object detection with region proposal net-\nworks. arXiv preprint arXiv:1506.01497 , 2015. 5, 6, 7\n[29] S. Ren, K. He, R. B. Girshick, X. Zhang, and J. Sun. Object\ndetection networks on convolutional feature maps. CoRR ,\nabs/1504.06066, 2015.", "mimetype": "text/plain", "start_char_idx": 2664, "end_char_idx": 5042, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "591c6e7e-fb52-49ea-9859-8b25f6932b1b": {"__data__": {"id_": "591c6e7e-fb52-49ea-9859-8b25f6932b1b", "embedding": null, "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4cb244ef-d23a-4606-9cad-18afdc0ad3f9", "node_type": "4", "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "1c28a568f893e1c148a16f953e9e188eb69e5f5167c665dcf7a42c986cdeec3c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8fcc9c46-6e03-435c-97e7-97a3638694a8", "node_type": "1", "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "7fbc9c4688aff4a7c76c02c4fa98706380f2195ad9f3b1f6aa3151f74c65cd23", "class_name": "RelatedNodeInfo"}}, "text": "An extended set of haar-like fea-\ntures for rapid object detection. In Image Processing. 2002.\nProceedings. 2002 International Conference on , volume 1,\npages I\u2013900. IEEE, 2002. 4\n[22] M. Lin, Q. Chen, and S. Yan. Network in network. CoRR ,\nabs/1312.4400, 2013. 2\n[23] D. G. Lowe. Object recognition from local scale-invariant\nfeatures. In Computer vision, 1999. The proceedings of the\nseventh IEEE international conference on , volume 2, pages\n1150\u20131157. Ieee, 1999. 4\n[24] D. Mishkin. Models accuracy on imagenet 2012\nval. https://github.com/BVLC/caffe/wiki/\nModels-accuracy-on-ImageNet-2012-val . Ac-\ncessed: 2015-10-2. 3\n[25] C. P. Papageorgiou, M. Oren, and T. Poggio. A general\nframework for object detection. In Computer vision, 1998.\nsixth international conference on , pages 555\u2013562. IEEE,\n1998. 4\n[26] J. Redmon. Darknet: Open source neural networks in c.\nhttp://pjreddie.com/darknet/ , 2013\u20132016. 3\n[27] J. Redmon and A. Angelova. Real-time grasp detection using\nconvolutional neural networks. CoRR , abs/1412.3128, 2014.\n5\n[28] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: To-\nwards real-time object detection with region proposal net-\nworks. arXiv preprint arXiv:1506.01497 , 2015. 5, 6, 7\n[29] S. Ren, K. He, R. B. Girshick, X. Zhang, and J. Sun. Object\ndetection networks on convolutional feature maps. CoRR ,\nabs/1504.06066, 2015. 3, 7\n[30] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,\nS. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,\nA. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual\nRecognition Challenge. International Journal of Computer\nVision (IJCV) , 2015. 3\n[31] M. A. Sadeghi and D. Forsyth. 30hz object detection with\ndpm v5. In Computer Vision\u2013ECCV 2014 , pages 65\u201379.\nSpringer, 2014. 5, 6\n[32] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus,\nand Y . LeCun. Overfeat: Integrated recognition, localiza-\ntion and detection using convolutional networks. CoRR ,\nabs/1312.6229, 2013. 4, 5", "mimetype": "text/plain", "start_char_idx": 3687, "end_char_idx": 5637, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3673bf07-6eb5-4f21-a899-825c209f56dd": {"__data__": {"id_": "3673bf07-6eb5-4f21-a899-825c209f56dd", "embedding": null, "metadata": {"page_label": "10", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "27943491-696e-4730-8d93-3628598abe87", "node_type": "4", "metadata": {"page_label": "10", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "2e5e69872f879d1dd42e9a933b75214f80a224e466929127fc4653bf5a4bd0f0", "class_name": "RelatedNodeInfo"}}, "text": "[33] Z. Shen and X. Xue. Do more dropouts in pool5 feature maps\nfor better object detection. arXiv preprint arXiv:1409.6911 ,\n2014. 7\n[34] C. Szegedy, W. Liu, Y . Jia, P. Sermanet, S. Reed,\nD. Anguelov, D. Erhan, V . Vanhoucke, and A. Rabinovich.\nGoing deeper with convolutions. CoRR , abs/1409.4842,\n2014. 2\n[35] J. R. Uijlings, K. E. van de Sande, T. Gevers, and A. W.\nSmeulders. Selective search for object recognition. Inter-\nnational journal of computer vision , 104(2):154\u2013171, 2013.\n4\n[36] P. Viola and M. Jones. Robust real-time object detection.\nInternational Journal of Computer Vision , 4:34\u201347, 2001. 4\n[37] P. Viola and M. J. Jones. Robust real-time face detection.\nInternational journal of computer vision , 57(2):137\u2013154,\n2004. 5\n[38] J. Yan, Z. Lei, L. Wen, and S. Z. Li. The fastest deformable\npart model for object detection. In Computer Vision and Pat-\ntern Recognition (CVPR), 2014 IEEE Conference on , pages\n2497\u20132504. IEEE, 2014. 5, 6\n[39] C. L. Zitnick and P. Doll \u00b4ar. Edge boxes: Locating object pro-\nposals from edges. In Computer Vision\u2013ECCV 2014 , pages\n391\u2013405. Springer, 2014. 4", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1108, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b6f9597-8a81-457a-b1ab-26e8b37dac9a": {"__data__": {"id_": "0b6f9597-8a81-457a-b1ab-26e8b37dac9a", "embedding": null, "metadata": {"page_label": "1", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "25aa5ef8-56c2-479d-bbb5-daba49730b80", "node_type": "4", "metadata": {"page_label": "1", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "b271db453447c5aab2109d5020d3a0681c87500dbb412e00850999e366c1762b", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information Systems Communications of the Association for Information Systems \nVolume 14 Paper \nSeptember 2004 \nIntelligent Agents Intelligent Agents \nIra Rudowsky \nBrooklyn College , rudowsky@br ooklyn.cuny .edu \nFollow this and additional works at: https:/ /aisel.aisnet.or g/cais \nRecommended Citation Recommended Citation \nRudowsky , I. (2004). Intelligent Agents. Communications of the Association for Information Systems, 14, \npp-pp. https:/ /doi.or g/10.17705/1CAIS.01414 \nThis material is br ought t o you b y the AIS Journals at AIS Electr onic Libr ary (AISeL). It has been accepted for \ninclusion in Communications of the Association for Information Systems b y an authoriz ed administr ator of AIS \nElectr onic Libr ary (AISeL). F or mor e information, please contact elibr ary@aisnet.or g.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 840, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "174bc864-365a-4e3d-b898-528fc170542e": {"__data__": {"id_": "174bc864-365a-4e3d-b898-528fc170542e", "embedding": null, "metadata": {"page_label": "2", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4062379e-10b9-4136-b572-f189250c3e7d", "node_type": "4", "metadata": {"page_label": "2", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "fc22f2abd6a3d82e45cd2f8fc1b81809759dd961722498994d944df2b5a8464f", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information System s (Volume14, 2004)275-290                          275                                \nIntelligent Agents by I. S. Rudowsky \n \n \nINTELLIGENT AGENTS \n \nIra S. Rudowsky \nBrooklyn College \nrudowsky@brooklyn.cuny.edu   \n \n \nABSTRACT \nA search on Google for the keyw ords \u201cintelligent agents\u201d will return more than 330,000 hits; \n\u201cmulti-agent\u201d returns almost double that  amount. Over 5,000 citations appear on \nwww.citeseer.com. What is agent technology and wh at has led to its enormous popularity in both \nthe academic and commercial worlds? Agent-based sy stem technology offers a new paradigm for \ndesigning and implementing software systems. The objective of this tutorial is to provide an \noverview of agents, intelligent  agents and multi-agent  systems, covering such areas as:  \n1. what an agent is, its origins and what it does,  \n2. how intelligence is defined for and di fferentiates an intelligent agent from an \nagent,  \n3. how multi-agent systems coordinate a gents with competing goals to achieve a \nmeaningful result, and  \n4. how an agent differs from an object of a class or an expert system.  \nExamples are presented of academic and commerci al applications that employ agent technology. \nThe potential pitfalls of agent developm ent and agent usage are discussed.  \nKeywords:  agents, intelligent agents,  multi-agent systems, artificial intelligence \nI. WHAT IS AN AGENT?  \nHISTORICAL CONTEXT \nOver the last thirty years,  Artifi cial Intelligence (AI) and agent syst ems were  closely related. AI is \ninterested in studying the compone nts of intelligence (e.g., the ab ility to learn, plan) while the \nstudy of agents deals with integr ating the same components. This distinction may seem to imply \nthat all the problems within AI must be solved to build an agent. But, as Etzioni points out, this is \nnot the case: \u2018Intelligent agents are ninety-nine percent comput er science and one percent AI\u2019 \n[Etzioni, 1996]. While AI techniques may be drawn u pon to build agents, not all AI capabilities are \nrequired by an agent. Thus not all AI problems need be solved before building an agent. For \nexample, the ability to learn may not  be a desirable trait fo r an agent in some situations while it is \ncertainly a component of AI.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2305, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b0e7ec7b-ac2b-4944-ab73-9e95e66a6b31": {"__data__": {"id_": "b0e7ec7b-ac2b-4944-ab73-9e95e66a6b31", "embedding": null, "metadata": {"page_label": "3", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a5f20a51-bedd-4a9c-9085-139446353f1e", "node_type": "4", "metadata": {"page_label": "3", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "bb7d8bbe4e42749850d84aabf1a611826484557ca582c0c01e28e6d1349b116c", "class_name": "RelatedNodeInfo"}}, "text": "276                          Communications  of the Association for Inform ation Systems (Volume 14, 2004)275-290             \n \nIntelligent Agents by I. Rudowsky Between 1960 and 1990, AI witnessed a great deal  of progress in many sub-areas such as \nknowledge representation and inference, machine l earning, vision, robotics. In addition, various \nadvancements in computer science and computin g (e.g., multitasking, distributed computing, \ncommunicating processes, real-time systems and communication networks) made the design, \nimplementation, and deployment of agent based systems possible, at least in principle. The \npotential applications in distributed databases,  mobile computing, information gathering, and \ncollaborative computing that take advantage of these advances in AI and computer systems pose \na strong argument for the development of  intelligent agents and multi-agent systems. \nBut is all this in touch with the reality? One need look no further than NASA\u2019s Deep Space 1 \n(DS1) project where an artifici al intelligence system was plac ed on board to plan and execute \nspacecraft activities. In contrast to remote control, this sophisticated set of computer programs \nacts as an agent of the operations team on bo ard the spacecraft. Rather than requiring humans \nto do the detailed planning necessary to carry out desired tasks, Remote Agent formulates its \nown plans/ It combines the high level goals provid ed by the operations t eam with its detailed \nknowledge of both the condition of the spacecraft and how to control it. It then executes that plan, \nconstantly monitoring its prog ress. If problems develop, Remote Agent in many cases will be able \nto fix them or work around them. If it is unable to find a fix or a work around, it can request help \nfrom its human counterparts.  \nRemote Agent operated DS1 spacecraft during two experiments that began on May 17, 1999, \nwhen it ran the on-board computer more than 60, 000,000 miles from Earth. The tests were a step \ntoward robotic explorers of the 21st century that are less costly, more capable, and more \nindependent from ground c ontrol. These intelligent agents can have the potential of making space \nexploration of the future mo re productive while staying within NASA\u2019s limited budget. By \ntransferring functions normally performed by peopl e to a remote agent, a spacecraft may be more \nagile in responding to u nexpected situations it en counters. In addition, by  assuming responsibility \nfor on-board tasks that currently require human intervention from Earth, Remote Agent permits \nspacecraft to fulfill their mission while greatly re ducing the time consumin g and labor intensive \ncommunications to and from missi on control. This ability will enabl e NASA to achieve its goal of \nlaunching many more spacecraft into the solar system while staying within budget.  \nSo we have what looks like a wi nning idea. What is it all about? \nDEFINING AN AGENT \nNo definition of the term agent is ac cepted universally. Here are a few: \n\u2022 Russel and Norvig [1995) define an agent  as an entity that can be viewed as \nperceiving its environment through sensors and acting upon its environment through \neffectors.  \n\u2022 Coen [1995] views software agents as programs that engage in dialogs and \nnegotiate and coordinate the transfer of information.  \n\u2022 Wooldridge and Jennings [1995] state that an agent is a hardware and/or software-\nbased computer system displaying the pr operties of autonomy, social adeptness, \nreactivity, and proactivity.  Others [Brust olini, 1991; Franklin and Graeser, 1996; \nMaes, 1995; Hayes-Roth et al, 1995; Gilbert et al, 1995] offer variations on this \ntheme.   \nA consensus among researchers indicates that autonomy, the ability to act without human \nintervention or other systems, is a key feature of an agent. Beyond that, different attributes take \non different importance based on the domain of the agent.  \nFigure 1 is a high-level view of an agent within its environment. An agent receives input from its \nenvironment.  Through a repertoire of actions availa ble to it, the agent reacts to the environment", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 4128, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "063cb970-a394-4c2e-9db9-8a5e99b557d1": {"__data__": {"id_": "063cb970-a394-4c2e-9db9-8a5e99b557d1", "embedding": null, "metadata": {"page_label": "4", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "de5353d8-49ce-45cd-b973-34c7eb4d78b1", "node_type": "4", "metadata": {"page_label": "4", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "72477860669eaa817cb6a9e6344f895d48b98225d4e9fcfa24ae1b8a43304e7e", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information System s (Volume14, 2004)275-290                          277                                \nIntelligent Agents by I. S. Rudowsky  \nsensor y effect\nEnvironmentin order to modify it. Generally , in domains of reasonable comple xity, an agent will not control its \nenvironment completely. Thus, the same action pe rformed twice in seemingly identical situations \nmight appear to result in completely different outco mes. Failure is also a possibility i.e., the action \ntaken by the agent may not produce the desired effect at all.  \n \n \n  \n \n  \n \n \n \n  \nFigure 1. Agent Interacti ng with its Environment \nAGENT ENVIRONMENTS \nThe critical decision an agent faces is determining  which action to perform to best satisfy its \ndesign objectives. Agent environments are classified  based on different properties that can affect \nthe complexity of the agent\u2019s de cision-making process [Russell and Norvig, 1995]. They include: \n\u2022 Accessible vs. inaccessible \nAn accessible environment is one in which the agent can obtain complete, timely and accurate information about the state of the environment. The more accessible an \nenvironment, the less complicated it is to build agents to operate within it. Most \nmoderately complex environments are inaccessible.  \n\u2022 Deterministic vs. non-deterministic \nMost reasonably, comp lex systems are non-det erministic. The state that will result \nfrom an action is not guaranteed even when the system is in a similar state before \nthe action is applied.  This uncertaint y presents a greater challenge to the agent \ndesigner than determi nistic systems. \n\u2022 Episodic vs. non-episodic \nIn an episodic environment, the agent\u2019s actions depend on a number of discrete episodes with no link between the agent\u2019s pe rformance in different scenarios. This \nenvironment is simpler to design due to t he lack of need to reason about interactions \nbetween previous and future episodes; only the current environment needs to be \nconsidered.  \n\u2022 Static vs. dynamic \nStatic environments remain unchanged except  for the results produced by the actions \nof the agent. Other processes operate in a dynamic environment, thereby changing \nthe environment outside the control of t he agent. A dynamic environment obviously \nrequires a more complex agent design.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2322, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "51cd4906-09a7-48c8-a66d-9a42d60b5764": {"__data__": {"id_": "51cd4906-09a7-48c8-a66d-9a42d60b5764", "embedding": null, "metadata": {"page_label": "5", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5fa2eff2-1d87-4e2d-8988-f8fe17f40185", "node_type": "4", "metadata": {"page_label": "5", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "01f15223ef86df1583045a9b0537b553b732ef361f5a32e44e9656fe922085bb", "class_name": "RelatedNodeInfo"}}, "text": "278                          Communications  of the Association for Inform ation Systems (Volume 14, 2004)275-290             \n \nIntelligent Agents by I. Rudowsky \u2022 Discrete vs. continuous \nIf the number of actions and percepts are fixed and finite, then the environment is \ndiscrete. A chess game is a discrete environment while driving a taxi is an example of \na continuous one. \nAGENT EXAMPLES \nA simple example of an agent in a physical env ironment is a thermostat for a heater. The \nthermostat receives input from a sensor, which is embedded in the environment, to detect the \ntemperature. Two states: (1) temperature too co ld and (2) temperature OK are possible. An \naction is associated with each state: (1) too cold \u00a8 turn the heating on and (2) temperature OK \u00a8 \nturn the heating off. The first action raises the room temperature. Howe ver its action does not \nguarantee a higher room temperature.   If cold air continuously comes into the room, say from an \nopen window, the added heat may not cr eate the desired effect of ra ising the room temperature. \nBackground software processes which monitor a software environment and perform actions to \nmodify it can be viewed as agents. A softwar e daemon that continually monitors a user\u2019s \nincoming e-mail and indicates via a GUI icon that some messages are unread can also be viewed \nas a simple agent.  \nAGENTS AND OBJECTS \nDoesn\u2019t object-oriented programming provide th ese agent features? What does an agent offer \nthat Java can\u2019t? After all, objects encapsulate dat a that can represent the state of the object, have \nmethods that enable the objects to perform actions, and can communicate by message passing. \nDespite these similarities, agents differ significantly  from objects. An object may be said to exhibit \nautonomy over its state (by defining its instance variables as private) but it does not exhibit \ncontrol over its behavior. The designers of an  object-oriented system work towards a common \ngoal:  if an object Oi invokes method m of object Oj then that method will be executed because \nthe designers ensured that it is in  the best interest of the system . In many types of multi-agent \nsystems, where agents may be built by and/or for different and com peting organizations, no such \ncommon goal can be assumed. Thus, the agent decides whether to execute the requested \nmethod based on its own design goals. \u201cObjects in voke, agents request\u201d or as Wooldridge [1995] \nindicates he heard it said \u201cObjects do it for free; agents do it for money\u201d. \nA second important distinction is that objects do not i nherently say anything about how to build a \nsystem that integrates flexible , autonomous behavior. Of course, such systems could be built with \nobjects but the standard object-oriented programm ing model is not concerned with these types of \nbehavior.  \nFinally, a multi-agent system is intrinsically mult i-threaded (each agent is assumed to contain at \nleast one thread of control). Object-oriented languages may enable multi-threading but autonomy \nis not a sine qua non.  \nAGENTS AND EXPERT SYSTEMS \nWhat about expert systems? Couldn\u2019t they be cons idered agents? Expert systems typically do not \nexist in an environment, they are disembodied. T hey obtain their information not through sensors \nbut through a user acting as a middle man. MYCIN, [Shortlie and Rhame, 1975] the expert \nsystem whose purpose was to assist physicians in  the treatment of blood infections in humans, \nacted as a consultant. It did not operate directly  on humans or any other environment. Similarly, \nexpert systems do not act on any environment. Inst ead they give feedback or advice to a third \nparty. In addition, expert systems are generally not  required to be capable of cooperating with \nother expert systems. The forego ing does not mean that an expert  system cannot be an agent. In \nfact, some real-time (typically process control)  expert systems, such as the ARCHON system \ndiscussed in Section III [Jennings, 1996a], are agents.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 4010, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b0e2a428-1265-44d9-b5b0-4f2ebf5cb572": {"__data__": {"id_": "b0e2a428-1265-44d9-b5b0-4f2ebf5cb572", "embedding": null, "metadata": {"page_label": "6", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "263f4cb5-bead-4a6b-8984-20e99553c3ca", "node_type": "4", "metadata": {"page_label": "6", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "ec567b3f82639e98aac192c7eb6ce14c8ac27b40a88e560cf3f4f265dafdfab9", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information System s (Volume14, 2004)275-290                          279                                \nIntelligent Agents by I. S. Rudowsky II. INTELLIGENT AGENTS \nThe idea of intelligent software agents captures the popular imagi nation. Tell the agent what you \nwant done, set it free, and wait for it to return  results sounds too good to be true. We\u2019ll come back \nto that later. In the meantime, we address the question of what makes an agent intelligent. \nWooldridge and Jennings [1995] define an intelligent agent as o ne that is capable of flexible \nautonomous action to meet its desi gn objectives. Flexible means: \n\u2022 reactivity :  \nintelligent agents perceive and respond in a ti mely fashion to changes that occur in \ntheir environment in order to satisfy thei r design objectives. The agent\u2019s goals and/or \nassumptions that form the basis for a proc edure that is currently executing may be \naffected by a changed environment and a different set of actions may be need to be \nperformed. \n\u2022 pro-activeness :  \nreacting to an environment by mapping a st imulus into a set of responses is not \nenough. As we want intelligent agents to do things for us, goal-directed behavior is \nneeded. In a changed en vironment, intelligent agents mu st  recognize opportunities \nand take the initiative if they are to pro duce meaningful results. The challenge to the \nagent designer is to integrate effectively goal-directed and reactive behavior . \n\u2022 social ability :  \nintelligent agents are capable of interacting with other agents (and possibly humans), \nthrough negotiation and/or  cooperation, to satisfy their design objectives.  \nOther properties sometimes mentioned in the context of intelligent agents include: \n\u2022 mobility: the ability to move around an electronic environment \n\u2022 veracity: an agent will not knowingly co mmunicate false information  \n\u2022 benevolence: agents\u2019 goals do not conflict and every agent  will therefore always try to \ndo what is asked of it \n\u2022 rationality:  an agent will act to achieve its goal s insofar as its beliefs permit  \n\u2022 learning/adaptation: agents improve performance over time  \n \nWhat drives the interest and need for intelligent agents? Users of the Web are faced with \ninformation overload. The amount of data ava ilable doubles annually.  Individuals can analyze \nonly about 5% of the data and most efforts do not provide real meaning.  Thus, intelligent agents \nare needed to assist in searching, filtering, and deciding what is relevant to the user. Forrester \nResearch [Coolidge, 2001], in t he latest forecast found, esti mated that by 2005, 20 million \nhouseholds will be using the Web fo r investment and financial plann ing advice; quite an important \ntask for a critical life decision with out some means of assistance.  \nTo put these concepts into a reality based framew ork, here is a scenari o of what an intelligent \nagent might be able to do in the future [Wooldridge and Jennings, 1995].  \nYou are editing a file when your PDA r equests your attention: an e-mail message \narrived that contains notification ab out a paper you sent to an important \nconference. The PDA correctly predicted t hat you would want to see it as soon \nas possible. The paper was  accepted. Without prompting, the PDA begins to \nlook into travel arrangements by co nsulting a number of databases and other \nnetworked information sources. A short ti me later, a summary of the cheapest \nand most convenient travel options is presented to you for selection and \napproval.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3547, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "61909d8b-fe51-4401-bb85-eb3c6e189724": {"__data__": {"id_": "61909d8b-fe51-4401-bb85-eb3c6e189724", "embedding": null, "metadata": {"page_label": "7", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d8d897c2-a40f-46c2-9f4f-40c7ca3f2c6e", "node_type": "4", "metadata": {"page_label": "7", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "dd4bddc4614f108936d02d480dfc7541114a760c2d0f7ac12f43ae74e869ca4e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "03d5f84c-4969-4564-b2e9-705d3bb1ec99", "node_type": "1", "metadata": {}, "hash": "aff151c67f9b3d7562605edf21926a27ffb5559ec5909e30b689e8ce11cad6e3", "class_name": "RelatedNodeInfo"}}, "text": "280                          Communications  of the Association for Inform ation Systems (Volume 14, 2004)275-290             \n \nIntelligent Agents by I. Rudowsky KNOW HOW, WITH NO HOW \nOne way to convey to an agent the task it should perform is to simply write a program that the \nagent should execute. The agent will do exactly as told and no more - if an unforeseen \ncircumstance arises, the agent will have no clue as to how it sh ould react. Thus, what we really \nwant is to tell our agent what  to do without really telling it how to do it. Associating a performance \nmeasure or utility with each stat e is one technique for doing so.. A utility is a number representing \nthe \u2018goodness\u2019 of the stat e \u2013 the higher the utility the better the state. The task of the agent is to \nmaximize utility without being told how to do so.  \nAn example of the use of such a utility function is in Tileworld [Pollack , 1990]. Tileworld is a \nsimulated, two-dimensional grid environment, both dynamic and unpredictable, which contains \nagents, tiles, obstacles, and holes. An agent can move in four direct ions \u2013 up, down, left, or right. \nIf it is located next to a tile, it can push it. An  obstacle is a group of immovable grid cells; agents \nare not allowed to travel freely th rough obstacles. An agent scores points by filli ng holes with tiles, \nthe aim being to fill as many hol es as possible. A number of para meters can be set, including the \nrate of appearance and disappearance of holes, obstacles, and tiles. The performance of an \nagent on a run r is defined as the number of holes filled in run r divided by the number of holes \nthat appeared in run r.  \nDespite its seeming simplicity, Tileworld enables the study of a number of important capabilities \nof agents. Chief among them is the ability of an agent  to react to changes in  the environment and \nto exploit opportunities when they  arise. If an agent is pushing a tile to fill a hole and the hole \ndisappears before being filled, the agent should re alize its original goal is no longer in effect and \n\u2018rethink\u2019 its objective by searchin g for a new hole to fill. In a similar vein, if an agent is pushing a \ntile to fill a hole that\u2019s four grid cells in the north direction and an  empty hole suddenly appears \none cell to the east of the agent\u2019s current position,  the agent should capitalize on this change and \nfill the closer hole. All other things being equal, the chances of the hole to the east not \ndisappearing in one move is four times greater than the hole to the north which is four moves \naway.  \nTileworld represents an oversimplification of real-wor ld scenarios but it is a useful environment for \nexperimentation.  \nBUT HOW DO THEY DO IT? \nHow is this know-how incorporated into so ftware? Shoham introduced a new programming \nparadigm based on societal views of computat ion that he called agent-oriented programming \n[Shoham, 1993]. He called the programming language AGENT0. The key idea is programming agents in terms of \u201cmentalistic\u201d notions such as belief, desire, and intention (BDI), which have \nbeen developed by agent theorists to represent the properties of agents. In AGENT0, an agent is \nspecified in terms of a set of ca pabilities (things t he agent can do), a set of initial beliefs, a set of \ninitial commitments (an agreement to perform a par ticular action at a particular time) and a set of \ncommitment rules. Capabilities are used by t he agent to decide whether to adopt commitments; \nan agent will not adopt a commitment to perform an action if the agent c an never be capable of \nperforming that action. \nThe set of commitment rules determines how the agent acts. Each commitment rule contains a \nmessage condition, a mental condition and an action.  To determine whether such a rule fires, the \nmessage condition is matched against the message the agent received and the mental condition \nis matched against the agent\u2019s beliefs. If the rule fires, the agent becomes committed to performing the action. For example, agent A s ends a commitment request in a message to agent \nB. Agent B will accept or reject  the request based on the details  of the request, its behavioral \nrules, and its current mental model.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 4220, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03d5f84c-4969-4564-b2e9-705d3bb1ec99": {"__data__": {"id_": "03d5f84c-4969-4564-b2e9-705d3bb1ec99", "embedding": null, "metadata": {"page_label": "7", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d8d897c2-a40f-46c2-9f4f-40c7ca3f2c6e", "node_type": "4", "metadata": {"page_label": "7", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "dd4bddc4614f108936d02d480dfc7541114a760c2d0f7ac12f43ae74e869ca4e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "61909d8b-fe51-4401-bb85-eb3c6e189724", "node_type": "1", "metadata": {"page_label": "7", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "46bb524046e57632c6610555ee894b1561edcac4b92e53c609a0a2b877c370d5", "class_name": "RelatedNodeInfo"}}, "text": "In a similar vein, if an agent is pushing a \ntile to fill a hole that\u2019s four grid cells in the north direction and an  empty hole suddenly appears \none cell to the east of the agent\u2019s current position,  the agent should capitalize on this change and \nfill the closer hole. All other things being equal, the chances of the hole to the east not \ndisappearing in one move is four times greater than the hole to the north which is four moves \naway.  \nTileworld represents an oversimplification of real-wor ld scenarios but it is a useful environment for \nexperimentation.  \nBUT HOW DO THEY DO IT? \nHow is this know-how incorporated into so ftware? Shoham introduced a new programming \nparadigm based on societal views of computat ion that he called agent-oriented programming \n[Shoham, 1993]. He called the programming language AGENT0. The key idea is programming agents in terms of \u201cmentalistic\u201d notions such as belief, desire, and intention (BDI), which have \nbeen developed by agent theorists to represent the properties of agents. In AGENT0, an agent is \nspecified in terms of a set of ca pabilities (things t he agent can do), a set of initial beliefs, a set of \ninitial commitments (an agreement to perform a par ticular action at a particular time) and a set of \ncommitment rules. Capabilities are used by t he agent to decide whether to adopt commitments; \nan agent will not adopt a commitment to perform an action if the agent c an never be capable of \nperforming that action. \nThe set of commitment rules determines how the agent acts. Each commitment rule contains a \nmessage condition, a mental condition and an action.  To determine whether such a rule fires, the \nmessage condition is matched against the message the agent received and the mental condition \nis matched against the agent\u2019s beliefs. If the rule fires, the agent becomes committed to performing the action. For example, agent A s ends a commitment request in a message to agent \nB. Agent B will accept or reject  the request based on the details  of the request, its behavioral \nrules, and its current mental model. B will then se nd a message to A indicating acceptance or \nrejection of the request. If B accepts the reques t, it agrees to attempt to perform the requested \naction at the requested time if possible. For ex ample, agent B may commit itself to make an \ninquiry into a database on behalf of A. Even if B can  connect and query the database, it may not", "mimetype": "text/plain", "start_char_idx": 2131, "end_char_idx": 4571, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3be2bb7d-2174-4e69-ae06-820b8bd9592a": {"__data__": {"id_": "3be2bb7d-2174-4e69-ae06-820b8bd9592a", "embedding": null, "metadata": {"page_label": "8", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0caa366f-8138-418c-b552-104a339c11cd", "node_type": "4", "metadata": {"page_label": "8", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "055fb1f32306d5ada23a6479c4fc0d86a54257c9ad79f4e759e63d65d94d0e29", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information System s (Volume14, 2004)275-290                          281                                \nIntelligent Agents by I. S. Rudowsky be possible at the specified time  due to a disk cras h during the database access. B will monitor \nthe execution of the query and send a message ba ck to A to report success or failure of the \ncommitment. \nIII. THE NEXT STEP: MULTI-AGENT SYSTEMS \nAs the field of AI matured, it broadened its goal s to the development and implementation of multi-\nagent systems (MASs) as it endeavored to attack more complex, realistic, and large-scale \nproblems which are beyond the capabilities of an individual agent. [Sycara, 1998]. The capacity of \nan intelligent agent is limited by its knowledge, it s computing reso urces, and it s perspective \n[Simon, 1957]. By forming communities of agents or agencies (Figure 2), a solution based on a  \n \nFigure 2. Multi-Agent System \n \nmodular design can be implemented where each me mber of the agency specializes in solving a \nparticular aspect of the problem. Thus, the age nts must be able to interoperate and coordinate \nwith one another in peer-to-peer interactions. The ch aracteristics of MASs are defined as [Sycara, \n1998]: \n\u2022 Each agent\u2019s information or  capabilities for solving the problem is incomplete. Thus, \nthe agent\u2019s viewpoint is limited.  \n\u2022 No global control system \n\u2022 Data are decentralized \n\u2022 Computation is asynchronous \nWhat can MASs do that generate so such interest in them?  \n\u2022 They can be used to solve problems that are too large for a centralized agent to solve \nbecause of resource limitations and/or to avoid a one point bottleneck or failure point.  \n\u2022 To keep pace with changing business nee ds,  legacy systems (which may not be \nable to be rewritten due to a combination of cost, time, and technical know) how, can be made to interoperate with other agents in an agent society by building an agent \nwrapper around them [Genesereth and Ke tchpel, 1994]. In addition, those agencies \nwhich are not self-contained but interact with outside agents e.g., buying and selling, \ncontract negotiation, meeting scheduling [Gar rido and Sycara, 1996], are by nature \nMASs.  interactio interactions\nExternal \nenvironment \nLocal", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2265, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d0eb1202-335f-4d83-802d-5ddc851fb7d9": {"__data__": {"id_": "d0eb1202-335f-4d83-802d-5ddc851fb7d9", "embedding": null, "metadata": {"page_label": "9", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a8ca7892-bfd8-4117-aa5e-3d15152072f0", "node_type": "4", "metadata": {"page_label": "9", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "e9eefc0c923bf2c251c2803c6701078ccaa1b6cbcd4ae64a6d4f0bdd2a803d7b", "class_name": "RelatedNodeInfo"}}, "text": "282                          Communications  of the Association for Inform ation Systems (Volume 14, 2004)275-290             \n \nIntelligent Agents by I. Rudowsky \u2022 MASs enhance performance in the following areas: (1) computational efficiency \nthrough concurrency, (2) reliability via r edundancy, (3) extensibilit y of the agency by \nchanging the number and capab ilities of the agents, (4) ma intainability via modularity \nand (5) reuse of agents in different ag encies to solve different problems. \nMASs sound great, but did anyone implement one that is useful? Here is but a small sample of \napplications: \n\u2022 ARCHON (ARchitecture for Cooperative He terogeneous ON-line systems) [Jennings \net al, 1996a; Parunak, 1999] is one of the largest and probably best known European multi-agent system development project to date. Multi-agent technology was \ndeveloped and deployed in a number of industri al domains.  The most significant is a \npower distribution system currently operationa l in northern Spain for the electricity \nutility Iberdrola. The ARCHON technology  was subsequently de ployed in particle \naccelerator control for CERN [Perriolat et al., 1996].  \n\u2022 In workflow and business process control,  the ADEPT system [Jennings et al, 1996b] \nmodels numerous depart ments at British Telecom involv ed in installing a network to \ndeliver a particular type of telecommunicati ons service. Beginning with the initial \ncustomer contact, followed by customer  vetting, requirements definition, \ndetermination of legality of service, de sign plan, and final quote, departments and \nindividuals within the departments are model ed as agents that negotiate with each \nother to reach a mutually agreeabl e contract for the customer.  \n\u2022 The OASIS system (Optimal Aircraft Sequencing using Intelligent Scheduling) \n[Ljungberg, 1992] is an air-traffic control sy stem whose purpose is to assist an air-\ntraffic controller in managing the flow of  aircraft at an airport. OASIS contains (1) \nglobal agents which perform generic domain functions e.g., arranging the landing sequence of aircraft and (2) an aircraft agent fo r each aircraft in the system airspace. \nIt was trialed at Sydney airport in Australia. \n\u2022 A proliferation in online auctions led to the need to monitor and bid in multiple \nauctions to procure the best deal for the desired item. Both of these actions are \ncomplex and time consuming, particularly when the bidding times for different \nauctions may or may not overlap and when the bidding protocol may differ. Anthony \nand Jennings [2003] describe the developm ent of a heuristic decision making \nframework that an autonomous agent can ex ploit in such situations. An agent-based \narchitecture for bidding on the New York  Stock Exchange also has been proposed \n[Griggs, 2000] as well as a trading simula tion that merges automated clients with \nreal-time, real-world stock mark et data [Kearns and Ortiz, 2003]. \nIV. JACK BE NIMBLE, JACK BE QUICK   \nTo appreciate the proce ss of constructing intelligent agents bette r, the following example, coded \nin the JACK\nTM Agent Language from Agent Oriented Software Group1, is offered. The JACKTM \nAgent Language is an agent-oriented developm ent environment built on top of and fully \nintegrated with the Java programming language. It defines new base classes, interfaces, and \nmethods as well as provides extensions to the Java syntax to s upport new agent-oriented \nclasses, definitions and statements. By enabling an agent to pursue its gi ven goals (desires) and \nadopt the appropriate plans (intentions) according to its current set of data (beliefs) it follows the \nBDI model of artificial intelligence. \n                                                      \n1 http://www.agent-software.com/shared/home  (consulted August 30, 2004)", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 3807, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f524492e-3799-470d-9137-4db6a4d82997": {"__data__": {"id_": "f524492e-3799-470d-9137-4db6a4d82997", "embedding": null, "metadata": {"page_label": "10", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "93b400e2-5ea7-4af3-8ab1-e188d9a1c9fd", "node_type": "4", "metadata": {"page_label": "10", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "1226ab2920e06915e6cfe4d712f5cdf63d04d462414bdbdc1387434289c55154", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information System s (Volume14, 2004)275-290                          283                                \nIntelligent Agents by I. S. Rudowsky The class-level constructs JACKTM employs include Agents, Event s, Plans and BeliefSets. Agent \nclasses are used to define t he behavior of an intelligent softw are agent by specifying: \n\u2022 all internal and external events that it will handle \n\u2022 events the agent can post inter nally to be handled by other plans \n\u2022 events the agent can send externally to other agents \n\u2022 plans the agent can execute \n\u2022 beliefsets the agent can refer to \nWhen an agent is instantiated, it waits until it is given a goal to achieve or experiences an event \nthat it must respond to. The types of events an agent responds to include internal stimuli \nrepresenting events an agent sends to itself or ex ternal stimuli which are messages from other \nagents or percepts that an agent receives from its own environment. JACKTM   provides two \ncategories of events.  \n1. A normal event in which the agent reacts to  transient information in the system e.g., \nthe location of the ball in a soccer game. The agent selects the first applicable plan \ninstance for the event and ex ecutes only that plan.  \n2. BDI or goal directed events commit the agent to a desired outcome rather than a \nspecific method to achieve that outcome. In this case the agent selects from a set of \nplans based on relevancy and applicability. If  the selected plan fails to execute, the \nagent executes an alternative plan until it succeeds or runs out plans from which to \nchoose. \nA plan is analogous to an agent\u2019s functions i.e., the instructions the agent follows to try to achieve \nits goals and handle its designated events. Each pl an handles a single event, but multiple plans \nmay handle the same event. An agent can discri minate further between pl ans by executing a \nplan\u2019s relevant()  method to determine whether it is rele vant for the instance of a given event. \nFrom those selected as relevant, the agent can further decide which plans are  applicable by \nexecuting the each plans  context() method. \nAn agent\u2019s beliefs about the world are stored in a beliefset using a tuple-based relational model. \nIn a Closed World relation the tuples stored are believed to be true, those not stored are assumed \nfalse. In an Open World relation both true and fals e tuples are stored; any thing not stored is \n\u201cunknown\u201d. Events can be posted when changes are made to the beliefset and thus initiate action \nwithin the agent based on a change of beliefs.  \nTHIS IS HOW IT HAPPENS \nWith this overview of how agent ori ented programming is supported by JACKTM , we can move on \nto the problem at hand. A relational database cont ains a field SubjectType within a table named \nExperiment. Whenever the value of  SubjectType is either \u2018monke y\u2019 or \u2018mouse\u2019 the system will \ndetect this state and invoke an agent to change t he value to \u2018animal\u2019. The system contains two \nagents, Monitor and Updater, two events, Up date and UpdateRequest and three plans, \nSendUpdateCommand, UpdateMonkey and UpdateMouse. Appendix I presents the source code \nof the system components. \nFigure 3 illustrates the flow of action steps. When the driver class, Progra m, finds a record that \ncontains \u2018monkey\u2019 or \u2018mouse\u2019 in the fiel d SubjectType (box(1)), it invokes the \nsubmitUpdateRequest() method of the Updater a gent (box(2)). This method, in turn, posts a \nsynchronous UpdateRequest event and invokes the request() method of the UpdateRequest \nevent (box(3)). The UpdateRequest event is a dded to the event queue of the Updater agent and \nawaits processing.  The Updater  agent includes the statement #uses plan \nSendUpdateCommand; which informs the agent what plan it should execute to handle any events \nit receives. Thus, the system progresses to box(4) where the SendUpdateCommand plan handles", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3911, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0d1aec07-9348-4529-975d-7d8b4d6d9ffa": {"__data__": {"id_": "0d1aec07-9348-4529-975d-7d8b4d6d9ffa", "embedding": null, "metadata": {"page_label": "11", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4d47e6f7-5bc0-4bb9-809e-b21c7eb79c0a", "node_type": "4", "metadata": {"page_label": "11", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "b64e1f9165a73b0b52051461cf54ba3338d743b898cda8e53cd8b1bbd2c8404b", "class_name": "RelatedNodeInfo"}}, "text": "284                          Communications  of the Association for Inform ation Systems (Volume 14, 2004)275-290             \n \nIntelligent Agents by I. Rudowsky the UpdateRequest event. First the plan instan tiates an Update event and invokes the update \nmethod of Update (box(5)). Then  the SendUpdatePlan \u201csends\u201d an update event to the Monitor \nagent and waits for a reply before continuing. The Monitor agent evaluates the relevant() and \ncontext() methods of UpdateMouse and UpdateMonk ey in order to choose between two plans of \naction (box (6)). The selected plan executes an d updates the value of SelectType to \u2018animal\u2019 for \nthe given record (box(7)). Upon completion of t he plan, an @reply with a Finished event is issued \nwhich invokes the finished method of the Fini shed event (box(8)). The @wait_for command in \nSendUpdateCommand receives this message and interprets the response (box(9)). \nSendUpdateCommand now terminates and control retu rns to Program (box(1)). Thus through a \nseries of events and messages age nts, the system monitors t he database table and when under \nthe proper conditions will trigger a sequence of steps to update the record. \n \nFigure 3. Sequence of Ev ents within the System \nIV. THE DOWNSIDE  \nDespite the significant advances made in th e science of agent syst ems, the pragmatic \nengineering of such systems is not as well under stood (Wooldridge and Jennings, 1998]. Some of \nthe common pitfalls include: \n\u2022 Agents do not make the impossible possible \u2013 they are not a magical problem solving \nparadigm (1)Program.class \nWhen a record with \nSubjectType mouse or monkey is found  it invokes the method \nsubmitUpdateRequest() \nof the  Updater agent  \nof the Updater agent (2) Updater.agent \nsubmitUpdateRequest  invokes  \nthe request()  method of  the \nUpdateRequest  event \n UpdateRequest.event \n the request method is  invoked \n  \n(5)Update.event \n the update method is executed \n  (6) SendUpdateCommand.plan \n@send  method sends Update \n event to the Monitor  agent. \nSelects relevant plan to execute \n (UpdateMonkey  or UpdateMouse ) \n \n(7) UpdateMonkey.plan \nHandles the  Update  event, \nupdates record in table \n@reply  messages  \nthe Finished  event \n  (9)SendUpdateCommand.plan \n the @wait for method receives the reply \nfrom UpdateMonkey  and returns control \nto Program (4) SendUpdateCommand.plan \n invokes update()  method of Update  \n \n(8)Finished.event \nthe finished()  method is \nexecuted", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 2450, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "195c5082-2566-45ec-b115-cd9f6d01aa1f": {"__data__": {"id_": "195c5082-2566-45ec-b115-cd9f6d01aa1f", "embedding": null, "metadata": {"page_label": "12", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e06595d-c402-4bf7-be8f-20b852150113", "node_type": "4", "metadata": {"page_label": "12", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "27064c2dc4fe428725b1bda16dd94bfdf168c456f2f391464d8fac2f4422909b", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information System s (Volume14, 2004)275-290                          285                                \nIntelligent Agents by I. S. Rudowsky \u2022 Agents are not a universal solution; in some situations a conventional software \ndevelopment paradigm (e.g., object oriented ) may be far more appropriate \n\u2022 Projects that employ agents because of the hype about agents but with no clear \npicture of what benefit s agents will bring to the projec t are likely doomed to failure.  \n\u2022 Building a successful protot ype with agents does not guarantee it will prove scalable \nand reliable in solving the full blown, real-world problem. \n\u2022 The design does not leverage concurrency  \n\u2022 The design contains too few or too many agents  \n\u2022 A multi agent system can not be develope d successfully by throwing together a \nnumber of agents and letting the system ru n \u2013 anarchy may result. Instead, a great \ndeal of a priori system-level  engineering is required, especially for large-scale \nsystems. \nEven with a well-designed and implemented MAS, ot her issues can prevent the acceptance of \nthe system by the user community: \n\u2022 Cost justification: is  it worth the price? \n\u2022 Security: will data be secure , particularly in a distributed environment? Will an agent \nrespect restrictions from other servers and go only where allowed? \n\u2022 Legal/Ethical issues: will agents\u2019 goals and plans be designed so as not to do \nanything illegal or unethical? Are there guide lines as to what determines a well- \nbehaved agent? With whom does liability rest for the decisi ons, actions and/or \nrecommendations of these systems? [Mykytyn et al, 1990].  \n\u2022 Accuracy: can the correctness  of the results be guaranteed? \n\u2022 Acceptance by society: An impedim ent to the widespread adoption of agent \ntechnology is social \u2013 for individuals to be comfortable with delegating tasks they \nmust first have trust in agents. [Bradshaw, 1997]  \nV.CONCLUSION \nAgent-based systems technol ogy is a vibrant and rapidly expanding field of academic research \nand business applications. By providing a new pa radigm for designing and implementing systems \nfor a complex, dynamic, and distributed environm ent where the common curr ency is negotiation, \nunplanned for events can be managed in a way that  is beneficial to the overall system \nperformance. Agent technology is greatly hyped as a panacea for the current ills of system design \nand development, but the developer is cautioned to  be aware of the pitfalls inherent in any new \nand untested technology. The potential is there but the full benefit is yet to be realized. Agent \ntechnology will achieve its true potential only if users understand its business value [Radjou, \n2003]. Much work is yet to be done. \nEditor\u2019s Note:  This article was received on August  8, 2004 and was published on September 8, \n2004 \nREFERENCES \nAnthony, P. and Jennings, N.R. (2 003) Developing a Bidding Agent for Multiple Heterogeneous \nAuctions, ACM Transactions on Internet Technology , (3)3, pp. 185-217. \nBradshaw, J. (1997) Software Agents , Menlo Park, CA: AAAI Press.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3104, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eebba14d-6257-4a18-943d-11c3f1f245f1": {"__data__": {"id_": "eebba14d-6257-4a18-943d-11c3f1f245f1", "embedding": null, "metadata": {"page_label": "13", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b7cc01e2-f0e6-457d-9575-374ec5406f04", "node_type": "4", "metadata": {"page_label": "13", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "2a86b275070ccbcaeb89b862dbd424f2bf4279d8f9aaa37c4e64eaa6753078be", "class_name": "RelatedNodeInfo"}}, "text": "286                          Communications  of the Association for Inform ation Systems (Volume 14, 2004)275-290             \n \nIntelligent Agents by I. Rudowsky Brustolini, J.C. (1991) Autonomous Agents: Characterization and Requirements, Report  CMU-\nCS-91-204, Pittsburgh, PA: School of Comput er Science, Carnegie-Mellon University,. \nCoen, M.H.(1991) SodaBot: A Software Agent Construction System , Cambridge, MA: MIT AI \nLaboratory,  \nCoolidge, C. (2001) Financial Planning, Forbes \u2013 Best of the Web, Spring  (167)5, p. 84. \nEtzioni, O. (1996) Moving Up the Information Food Chain: Deploying Softbot s on the World Wide \nWeb, Proceedings of the 13th national Conference on Artifi cial Intelligence (AAAI-96) , \nPortland, OR, pp.4-8. \nFranklin S.P. and Graesser A.G. (1996) Is It an Agent, or Just a Program?: A Taxonomy for \nAutonomous Agents, In M.J. Wooldridge & N.R. Jennings (eds.), Intelligent Agents III , \nHeidelberg: Springer-Verlag. \nGilbert, D., et al. (1995) IBM Intelligent Agent Strategy , White Paper, IBM Corporation. \nGriggs, K. (2000) An Agent Oriented Busi ness Model for E-Commerce Based on the NYSE \nSpecialist System, ACM SIGCPR 2000 , Evanston, IL, pp.136-143. \nHayes-Roth, B., et al.  (1995) A Domain Specif ic Software Architecture for Adaptive Intelligent \nAgents, IEEE Transactions on Software Engineering , (21)4, pp. 288-301, April. \nHonavar, V. (1999), Intelligent Agents and Multi Agent Systems, IEEE Conference on \nEvolutionary Computation, Washington, DC, \nJennings, N. R., et al. (1996a) Using ARCH ON to Develop Real-Word DAI Applications, IEEE \nExpert , (11)6, pp. 64-70.  \nJennings, N. R.,et al. (1996b) Agen t-Based Business Process Management,  International Journal \nof Cooperative Information Systems , (5)2&3, pp. 105-130.  \nKearns, M. and Ortiz, L (2003) The Penn-Lehman Automated Trading Project, IEEE Intelligent \nSystems , (1)6, Nov/Dec, pp. 22-31. \nKendall, E.A.et al. (2000), An  Application Framework for Intelligent and Mobile Agents, ACM \nComputing Surveys , (32)1 March. \nLjungberg, M., Lucas, A. (1992) The O ASIS Air Traffic Management System, Proceedings of the \nSecond Pacific Rim International C onference on Artificial Intelligence , PRICAI \u201992, Seoul, \nKorea. \nMaes, P.  (1995) Artificial Life Meets Entertainment: Lifelike Autonomous Agents, CACM , (38)11, \npp. 108-114, November.. \nMykytyn, K., Mykytyn, P., Slin kman, C. (1990) Expe rt Systems: A Question of Liability?, MIS \nQuarterly ,(14)1 March, pp. 27-42. \nParunak, H.V.D. (1999) Industrial an d Practical Applicat ions of DAI, in Multi-Agent Systems, (ed. \nG. Weis), pp. 377-421, Cambridge, MA:MIT Press,  \nPerriolat, F., et al.(1996) Using Archon, Pa rt 3: Particle Accelerator Control, IEEE Expert,  (11)6, \npp. 80-86.  \nPollack, M.E. and Ringuette, M. (1990) Introduci ng the Tileworld: Experimentally Evaluating \nAgent Architecture, Proceedings of the 8th National Conference on Artificial Intelligence  \n(AAAI-90), pp. 183-189, Boston, MA.", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 2969, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2d1040fd-0b44-408d-aa70-cb01de009e5f": {"__data__": {"id_": "2d1040fd-0b44-408d-aa70-cb01de009e5f", "embedding": null, "metadata": {"page_label": "14", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "81e1c260-96e9-44ed-934c-fee55d39ca24", "node_type": "4", "metadata": {"page_label": "14", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "8afa6cc7a05e0dac55967aeba082cdc6e3edafdb650aae1bacedd3ab7b646d07", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information System s (Volume14, 2004)275-290                          287                                \nIntelligent Agents by I. S. Rudowsky Radjou, N. (2003) Software Agents in Business: Still An Experiment, Forrester Research Brief , \nMarch 27.  \nRussell, S. and Norvig, P. (1995) Artificial Intelligence: A Modern Approach, Englewood Cliffs, NJ: \nPrentice-Hall,. \nShoham, Y. (1993) Agent Oriented Programming, Journal of Artificial Intelligence,  (60)1, pp. 51-\n92, 1993.  \nShortlie, E.H. and Rhame, F.S. et al. (1975) My cin: A Computer Program Providing Antimicrobial \nTherapy Recommendations , Clinical Medicine,  (34), 1975. \nSimon, H., (1957) Models of Man: Social and Rati onal; Mathematical Essays on Rational Human \nBehavior in a Social Setting, New York, Wiley. \nSycara, K.P. (1998)  Multiagent Systems, Artificial Intelligence , (10)2,  pp. 79-93. \nTurban, E. and Aronson, J.E. (2001) Decision Support Systems and Intelligent Systems 6/e , \nUpper Saddle River, NJ: Prentice Hall, \nWooldridge, M. (2002) An Introduction to MultiAgent Systems,  Chichester, UK: Wiley.  \nWooldridge, M. and Jennings, N.R. (1995) Intelligent Agents: Theory and Practice, The \nKnowledge Engineering Review,  (10)2, pp.115-152. \nWooldridge, M. and Jennings, N.R. (1998) Pitfalls of Agent-Oriented Development, Proceedings \nof the 2nd International Conference on Autonomous Agents  (Agents 98), Minneapolis/St. Paul, \nMN, pp, 385-391. \nAPPENDIX I. SOURCE CODE FO R AGENTS, EVENTS AND PLANS \n \npublic class Program  \n{ \n public static void main(String args[])throws SQLException, ClassNotFoundException,      NullPointerException  \n   {   Monitor monitor = new Monitor(\"ResearchMonitor\"); \n  Updater updt = new Updater(\"ResearchUpdater\"); \n  \n       //SQL CODE TO CONNECT TO DATABASE         // AND SEARCH TABLE FOR RECORDS WITH SUBJECTTYPE EQUAL TO mouse \nOR monkey \n \n       ResultSet r = s.executeQuery(\"SELECT ExpID,SubjectID,SubjectType \nFROM        EXPERIMENT WHERE SUBJECTTYPE = 'monkey' OR SUBJECTTYPE = \n'mouse'\" );  \n       while (r.next())     {    String eid = r.getString(\"ExpId\");       String stype = r.getString(\"SubjectType\"); \n     System.out.println(\"ID #:\"+ eid + \" Subject ID:\" + \n               r.getString(\"SubjectID\") + \" Subject Type:\" + stype); \n     updt.submitUpdateRequest (\"ResearchMonitor\", eid, stype);        \n    }; \n  }", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2382, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9672404b-d5a4-4cd5-bb4f-1c139ac10205": {"__data__": {"id_": "9672404b-d5a4-4cd5-bb4f-1c139ac10205", "embedding": null, "metadata": {"page_label": "15", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "515c186e-752d-434c-a38a-9078e7733eb3", "node_type": "4", "metadata": {"page_label": "15", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "c850e9d1ebd3a2963d2b6e6e309b33540c652284b3d6fd05602f39e528ff0e7d", "class_name": "RelatedNodeInfo"}}, "text": "288                          Communications  of the Association for Inform ation Systems (Volume 14, 2004)275-290             \n \nIntelligent Agents by I. Rudowsky }  \n \npublic agent Updater extends Agent { \n   #handles external event UpdateRequest;  \n   #sends event Update;  \n   #uses plan SendUpdateCommand;     #posts event UpdateRequest ev;     public Updater(String name) { super(name);} \n   public void submitUpdateRequest (String monitor, String \n       expID, String stype){ \n     postEventAndWait (ev.request(monitor, stype, expID)); \n   } \n} \n \npublic agent Monitor extends Agent { \n    #handles external event Update;  \n    #sends event Finished;  \n    #uses plan UpdateMonkey;  \n    #uses plan UpdateMouse;  \n    #posts event Update ev; \n     public Monitor(String name){ super(name);}     String stype, eid; \n    public void setVars (String s, String e) {stype = s; eid = e; } \n}   \npublic event Update extends BDIMessageEvent   { \n    public String stype, eid; \n    #posted as \n    update (String s, String e) {stype = s; eid = e; } \n} \n \npublic event UpdateRequest extends BDIGoalEvent { \n    public String monitor, stype, eid; \n    #posted as \n    request (String m, String s, String e){ \n      monitor = m; stype = s; eid = e; \n    } \n} \n \npublic event Finished extends BDIMessageEvent { \n    public String stype, eid; \n    #posted as \n    finished (String s, String e) {stype = s; eid = e;} \n} \n  \npublic plan SendUpdateCommand extends Plan { \n    #handles event UpdateRequest preqev; \n    #sends event Update ev; \n         body()     {try      {   Update q = ev.update(preqev.stype, preqev.eid); \n    @send (preqev.monitor,q);", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 1646, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9e72d9a4-1cee-4795-bc24-2aeef0e8b5ad": {"__data__": {"id_": "9e72d9a4-1cee-4795-bc24-2aeef0e8b5ad", "embedding": null, "metadata": {"page_label": "16", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0ced88fc-9fd3-428d-837a-5e3c241aabdc", "node_type": "4", "metadata": {"page_label": "16", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "2df7d645b2de9235ff7382dae300d76cf35249a0f1d74ff60a0f7fde8e7d15bc", "class_name": "RelatedNodeInfo"}}, "text": "Communications of the Association for Information System s (Volume14, 2004)275-290                          289                                \nIntelligent Agents by I. S. Rudowsky     @wait_for (q.replied()); \n    Finished response = (Finished) q.getReply(); \n    System.out.println(agent.name()+\" has been updated in \n             SendUpdateCommand \"+response.eid); \n     }       catch (NullPointerException npe) {         System.out.println(\"preqev.eid \"+preqev.eid);      } \n   } \n}   \npublic plan UpdateMonkey extends Plan { \n    #handles event Update handleUpdateEvent; \n    #sends event Finished fev; \n    #uses interface Monitor self;  \n    static boolean relevant (Update evRef) \n    { return  ((evRef.stype != null) && (evRef.stype.length() > 0)); } \n \n    context(){   handleUpdateEvent.stype.equals(\"monkey\"); } \n \n    body()     { self.setVars(handleUpdateEvent.stype, handleUpdateEvent.eid); \n     \n    // SQL CODE TO CONNECT TO DATABASE AND  \n    // UPDATE SUBJECTTYPE FROM monkey TO animal \n     s.executeUpdate(\"UPDATE EXPERIMENT SET SUBJECTTYPE='animal\u2018 \n       WHERE EXPID='\" + handleUpdateEvent.eid + \"'\" );  \n     } \n     @reply (handleUpdateEvent,fev.finished(self.stype, self.eid)); \n    }  \n}   \npublic plan UpdateMouse extends Plan { \n    #handles event Update handleUpdateEvent; \n    #sends event Finished fev;     #uses interface Monitor self;  \n    static boolean relevant (Update evRef) \n    { return  ((evRef.stype != null) && (evRef.stype.length() > 0)); } \n \n    context(){   handleUpdateEvent.stype.equals(\"mouse\"); } \n \n    body() \n    { self.setVars(handleUpdateEvent.stype, handleUpdateEvent.eid);      \n    // SQL CODE TO CONNECT TO DATABASE AND  \n    // UPDATE SUBJECTTYPE FROM mouse TO animal \n     s.executeUpdate(\"UPDATE EXPERIMENT SET SUBJECTTYPE='animal\u2018 \n       WHERE EXPID='\" + handleUpdateEvent.eid + \"'\" );  \n     } \n     @reply (handleUpdateEvent,fev.finished(self.stype, self.eid)); \n    }  \n}", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1942, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0583d04f-0507-4834-9af7-cf3f338d82e3": {"__data__": {"id_": "0583d04f-0507-4834-9af7-cf3f338d82e3", "embedding": null, "metadata": {"page_label": "17", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0670389a-f799-43e0-9a56-827672784b53", "node_type": "4", "metadata": {"page_label": "17", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "d5dd544ff1647089b3c78662f262e9b31d73ec89421f53572ae49f5856c10eca", "class_name": "RelatedNodeInfo"}}, "text": "290                          Communications  of the Association for Inform ation Systems (Volume 14, 2004)275-290             \n \nIntelligent Agents by I. Rudowsky ABOUT THE AUTHOR \nIra S. Rudowsky is Associate Professor of Co mputer and Information Science at Brooklyn \nCollege of the City University of New York at the undergraduat e and graduate level. He also \nteaches business/technology course s in the Department of Economics. His research interests \ninclude database systems for multimedia data,  intelligent agents, and management information \nsystems. For over twenty-five years he managed and developed application software for financial \nservices industry in companies such as Merr ill Lynch, Bankers Trust, and the New York State \nOffice of the Comptroller. He is a member  of AIS, ACM, and IEEE Computer Society.  \n \nCopyright \u00a9 2004 by the Association for Information System s. Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee prov ided that copies are not \nmade or distributed for profit or commercial advantage and that copies bear this notice and full citation on \nthe first page. Copyright for components of this wo rk owned by others than the Association for Information \nSystems must be honored. Abstracting with credit is permi tted. To copy otherwise, to republish, to post on \nservers, or to redistribute to lists requires prior specif ic permission and/or fee. Request permission to publish \nfrom: AIS Administrative Office, P.O. Box 2712 Atlanta,  GA, 30301-2712 Attn: Reprints or via e-mail from  \nais@aisnet.org", "mimetype": "text/plain", "start_char_idx": 1, "end_char_idx": 1614, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "898b37bf-cead-4d38-bc79-862ff358c7eb": {"__data__": {"id_": "898b37bf-cead-4d38-bc79-862ff358c7eb", "embedding": null, "metadata": {"page_label": "18", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e3afcbf0-afa3-4b1f-ba0e-b2f3afddb625", "node_type": "4", "metadata": {"page_label": "18", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "2359559052a355183640708316c1e555efa7360a4216446944bdfdd1c8b5e3d3", "class_name": "RelatedNodeInfo"}}, "text": "ISSN: 1529-3181 \n                                                  \nEDITOR-IN-CHIEF \nPaul Gray \nClaremont Graduate University \nAIS SENIOR  EDITORIAL BOARD \nDetmar Straub \nVice President Publications  \nGeorgia State University Paul Gray                                 \nEditor, CAIS                                \nClaremont Graduate University Sirkka Jarvenpaa \nEditor, JAIS \nUniversity of Texas at Austin \nEdward A. Stohr \nEditor-at-Large \nStevens Inst. of Technology Blake Ives                                \nEditor, Electronic Publications  \nUniversity of Houston Reagan Ramsower \nEditor, ISWorld Net \nBaylor University \nCAIS ADVISORY BOARD   \nGordon Davis University of Minnesota  Ken Kraemer \nUniv. of Calif. at Irvine M.Lynne Markus  \nBentley College Richard Mason \nSouthern Methodist Univ.   \nJay Nunamaker                    \nUniversity of Arizona Henk Sol \nDelft  University Ralph Sprague \nUniversity of Hawaii Hugh J. Watson \nUniversity of Georgia  \nCAIS SENIOR EDITORS  \nSteve Alter \nU. of San Francisco Chris Holland \nManchester Bus. School Jaak Jurison \nFordham University Jerry Luftman \nStevens Inst.of Technology \nCAIS EDITORIAL BOARD    \nTung Bui University of Hawaii Fred Davis \nU.ofArkansas, Fayetteville Candace Deans \nUniversity of Richmond Donna Dufner \nU.of Nebraska -Omaha \nOmar El Sawy  \nUniv. of Southern Calif. Ali Farhoomand \nUniversity of Hong Kong  Jane Fedorowicz \nBentley College Brent Gallupe \nQueens University \nRobert L.  Glass \nComputing Trends Sy Goodman  \nGa. Inst.  of Technology Joze Gricar \nUniversity of Maribor Ake Gronlund \nUniversity of Umea,  \nRuth Guthrie California State Univ. Alan Hevner \nUniv. of South Florida Juhani Iivari \nUniv. of Oulu Claudia Loebbecke \nUniversity of Cologne \nMunir Mandviwalla  \nTemple University Sal March \nVanderbilt University Don McCubbrey  \nUniversity of Denver Emannuel Monod \nUniversity of Nantes \nJohn Mooney \nPepperdine University  Michael Myers \nUniversity of Auckland Seev Neumann                 \nTel Aviv University Dan Power  \nUniversity of No. Iowa \nRam Ramesh \nSUNY-Buffalo Maung Sein  \nAgder University College,  Carol Saunders \nUniv. of Central Florida Peter Seddon  \nUniversity of Melbourne \nThompson Teo \nNational U. of Singapore Doug Vogel  \nCity Univ. of Hong Kong Rolf Wigand  \nUof Arkansas,LittleRock Upkar Varshney  \nGeorgia State Univ.  \nVance Wilson \nU.Wisconsin,Milwaukee Peter Wolcott \nUniv. of Nebraska-Omaha   \nDEPARTMENTS \nGlobal Diffusion of the Internet.  \nEditors: Peter Wolcott and Sy Goodman Information Technology and Systems.  \nEditors: Alan Hevner and Sal March  \nPapers in French \nEditor: Emmanuel Monod Information Systems and Healthcare  \nEditor: Vance Wilson  \nADMINISTRATIVE PERSONNEL                                                                              \nEph McLean  \nAIS, Executive Director \nGeorgia State University Samantha Spears \nSubscriptions Manager \nGeorgia State University Reagan Ramsower \nPublisher, CAIS \nBaylor University", "mimetype": "text/plain", "start_char_idx": 4, "end_char_idx": 2965, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7ea8d8a6-05c7-4c65-b391-494e8a807c0b": {"__data__": {"id_": "7ea8d8a6-05c7-4c65-b391-494e8a807c0b", "embedding": null, "metadata": {"page_label": "1", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aa15153c-21e2-4bc4-981a-4427eb5389be", "node_type": "4", "metadata": {"page_label": "1", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "768ad6f8516ece2ddaa645996fe835ae88765d38d20d7c7e8f3dde2c462f0150", "class_name": "RelatedNodeInfo"}}, "text": "What is machine learning? \nMachine learning is a branch of artificial intelligence (AI) and computer science which \nfocuses on the use of data and algorithms to imitate the way that humans learn, \ngradually improving its accuracy. \nIBM has a rich history with machine learning. One of its own, Arthur Samuel, is credited \nfor coining the term, \u00aamachine learning\u00ba with his research (link resides outside ibm.com) \naround the game of checkers. Robert Nealey, the self-proclaimed checkers master, \nplayed the game on an IBM 7094 computer in 1962, and he lost to the computer. \nCompared to what can be done today, this feat seems trivial, but it's considered a major \nmilestone in the field of artificial intelligence. \nOver the last couple of decades, the technological advances in storage and processing \npower have enabled some innovative products based on machine learning, such as \nNetflix's recommendation engine and self-driving cars. \nMachine learning is an important component of the growing field of data science. \nThrough the use of statistical methods, algorithms are trained to make classifications or \npredictions, and to uncover key insights in data mining projects. These insights \nsubsequently drive decision making within applications and businesses, ideally \nimpacting key growth metrics. As big data continues to expand and grow, the market \ndemand for new data scientists will increase. They will be required to help identify the \nmost relevant business questions and the data to answer them. \nMachine learning algorithms are typically created using frameworks such as Python that \naccelerate solution development by using platforms like TensorFlow or PyTorch. \nNow available: watsonx.ai \nThe all-new enterprise studio that brings together traditional machine learning along \nwith new generative AI capabilities powered by foundation models. \nTry watsonx.ai \nBegin your journey to AI \nLearn how to scale AI \nExplore the AI Academy \nMachine Learning vs. Deep Learning vs. Neural Networks \nSince deep learning and machine learning tend to be used interchangeably, it's worth \nnoting the nuances between the two. Machine learning, deep learning, and neural \nnetworks are all sub-fields of artificial intelligence. However, neural networks is actually \na sub-field of machine learning, and deep learning is a sub-field of neural networks. \nThe way in which deep learning and machine learning differ is in how each algorithm \nlearns. \"Deep\" machine learning can use labeled datasets, also known as supervised \nlearning, to inform its algorithm, but it doesn't necessarily require a labeled dataset. The \ndeep learning process can ingest unstructured data in its raw form (e.g., text or images), \nand it can automatically determine the set of features which distinguish different \ncategories of data from one another. This eliminates some of the human intervention \nrequired and enables the use of large amounts of data. You can think of deep learning \nas \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides \noutside ibm.com). \nClassical, or \"non-deep,\" machine learning is more dependent on human intervention to \nlearn. Human experts determine the set of features to understand the differences \nbetween data inputs, usually requiring more structured data to learn. \nNeural networks, or artificial neural networks (ANNs), are comprised of node layers, \ncontaining an input layer, one or more hidden layers, and an output layer. Each node, or \nartificial neuron, connects to another and has an associated weight and threshold. If the \noutput of any individual node is above the specified threshold value, that node is \nactivated, sending data to the next layer of the network. Otherwise, no data is passed \nalong to the next layer of the network by that node. The \u00aadeep\u00ba in deep learning is just \nreferring to the number of layers in a neural network. A neural network that consists of \nmore than three layers\u00d0which would be inclusive of the input and the output\u00d0can be \nconsidered a deep learning algorithm or a deep neural network. A neural network that", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4097, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ee870fb-8e5c-438b-853b-19450f45b881": {"__data__": {"id_": "0ee870fb-8e5c-438b-853b-19450f45b881", "embedding": null, "metadata": {"page_label": "2", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b20afe2f-20ec-4c27-87c5-b7557a65be3a", "node_type": "4", "metadata": {"page_label": "2", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "a5a50ec813968f18de270940c68d0282071cd036667d9e5e0411c2030b8c431c", "class_name": "RelatedNodeInfo"}}, "text": "only has three layers is just a basic neural network. \nDeep learning and neural networks are credited with accelerating progress in areas \nsuch as computer vision, natural language processing, and speech recognition. \nSee the blog post \u00aaAI vs. Machine Learning vs. Deep Learning vs. Neural Networks: \nWhat's the Difference?\u00ba for a closer look at how the different concepts relate. \nRelated content \nExplore the watsonx.ai interactive demo \nDownload \u00aaMachine learning for Dummies\u00ba \n- This link downloads a pdf \nExplore Gen AI for developers \nHow does machine learning work? \nUC Berkeley (link resides outside ibm.com) breaks out the learning system of a \nmachine learning algorithm into three main parts. \nA Decision Process: In general, machine learning algorithms are used to make a \nprediction or classification. Based on some input data, which can be labeled or \nunlabeled, your algorithm will produce an estimate about a pattern in the data. \nAn Error Function: An error function evaluates the prediction of the model. If \nthere are known examples, an error function can make a comparison to assess \nthe accuracy of the model. \nA Model Optimization Process: If the model can fit better to the data points in the \ntraining set, then weights are adjusted to reduce the discrepancy between the \nknown example and the model estimate. The algorithm will repeat this iterative \n\u00aaevaluate and optimize\u00ba process, updating weights autonomously until a \nthreshold of accuracy has been met. \nMachine learning methods \nMachine learning models fall into three primary categories. \nSupervised machine learning \nSupervised learning, also known as supervised machine learning, is defined by its use \nof labeled datasets to train algorithms to classify data or predict outcomes accurately. \nAs input data is fed into the model, the model adjusts its weights until it has been fitted \nappropriately. This occurs as part of the cross validation process to ensure that the \nmodel avoids overfitting or underfitting. Supervised learning helps organizations solve a \nvariety of real-world problems at scale, such as classifying spam in a separate folder \nfrom your inbox. Some methods used in supervised learning include neural networks, \nna\u00efve bayes, linear regression, logistic regression, random forest, and support vector \nmachine (SVM). \nUnsupervised machine learning \nUnsupervised learning, also known as unsupervised machine learning, uses machine \nlearning algorithms to analyze and cluster unlabeled datasets (subsets called clusters). \nThese algorithms discover hidden patterns or data groupings without the need for \nhuman intervention. This method\u2019s ability to discover similarities and differences in \ninformation make it ideal for exploratory data analysis, cross-selling strategies, \ncustomer segmentation, and image and pattern recognition. It\u2019s also used to reduce the \nnumber of features in a model through the process of dimensionality reduction. Principal \ncomponent analysis (PCA) and singular value decomposition (SVD) are two common \napproaches for this. Other algorithms used in unsupervised learning include neural \nnetworks, k-means clustering, and probabilistic clustering methods. \nSemi-supervised learning \nSemi-supervised learning offers a happy medium between supervised and \nunsupervised learning. During training, it uses a smaller labeled data set to guide \nclassification and feature extraction from a larger, unlabeled data set. Semi-supervised \nlearning can solve the problem of not having enough labeled data for a supervised \nlearning algorithm. It also helps if it\u2019s too costly to label enough data. \nFor a deep dive into the differences between these approaches, check out \"Supervised \nvs. Unsupervised Learning: What's the Difference?\"", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3759, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "288fe6f5-c570-4f45-a2f6-1fe0827cd32c": {"__data__": {"id_": "288fe6f5-c570-4f45-a2f6-1fe0827cd32c", "embedding": null, "metadata": {"page_label": "3", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "271abb5d-413f-451e-8ae8-0b745abdc3a0", "node_type": "4", "metadata": {"page_label": "3", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "789aa1893228435f2514c2fe69cb3e64655f0dec6a182e5700bfbe23b9edfe19", "class_name": "RelatedNodeInfo"}}, "text": "Reinforcement machine learning \nReinforcement machine learning is a machine learning model that is similar to \nsupervised learning, but the algorithm isn\u2019t trained using sample data. This model learns \nas it goes by using trial and error. A sequence of successful outcomes will be reinforced \nto develop the best recommendation or policy for a given problem. \nThe IBM Watson\u00ae system that won the Jeopardy! challenge in 2011 is a good example. \nThe system used reinforcement learning to learn when to attempt an answer (or \nquestion, as it were), which square to select on the board, and how much to \nwager\u2014especially on daily doubles. \nLearn more about reinforcement learning \nCommon machine learning algorithms \nA number of machine learning algorithms are commonly used. These include: \nNeural networks: Neural networks simulate the way the human brain works, with \na huge number of linked processing nodes. Neural networks are good at \nrecognizing patterns and play an important role in applications including natural \nlanguage translation, image recognition, speech recognition, and image creation. \nLinear regression: This algorithm is used to predict numerical values, based on a \nlinear relationship between different values. For example, the technique could be \nused to predict house prices based on historical data for the area. \nLogistic regression: This supervised learning algorithm makes predictions for \ncategorical response variables, such as \u201cyes/no\u201d answers to questions. It can be \nused for applications such as classifying spam and quality control on a \nproduction line. \nClustering: Using unsupervised learning, clustering algorithms can identify \npatterns in data so that it can be grouped. Computers can help data scientists by \nidentifying differences between data items that humans have overlooked. \nDecision trees: Decision trees can be used for both predicting numerical values \n(regression) and classifying data into categories. Decision trees use a branching \nsequence of linked decisions that can be represented with a tree diagram. One of \nthe advantages of decision trees is that they are easy to validate and audit, \nunlike the black box of the neural network. \nRandom forests: In a random forest, the machine learning algorithm predicts a \nvalue or category by combining the results from a number of decision trees. \nAdvantages and disadvantages of machine learning algorithms \nDepending on your budget, need for speed and precision required, each algorithm \ntype\u2014supervised, unsupervised, semi-supervised, or reinforcement\u2014has its own \nadvantages and disadvantages. For example, decision tree algorithms are used for both \npredicting numerical values (regression problems) and classifying data into categories. \nDecision trees use a branching sequence of linked decisions that may be represented \nwith a tree diagram. A prime advantage of decision trees is that they are easier to \nvalidate and audit than a neural network. The bad news is that they can be more \nunstable than other decision predictors. \nOverall, there are many advantages to machine learning that businesses can leverage \nfor new efficiencies. These include machine learning identifying patterns and trends in \nmassive volumes of data that humans might not spot at all. And this analysis requires \nlittle human intervention: just feed in the dataset of interest and let the machine learning \nsystem assemble and refine its own algorithms\u2014which will continually improve with \nmore data input over time. Customers and users can enjoy a more personalized \nexperience as the model learns more with every experience with that person. \nOn the downside, machine learning requires large training datasets that are accurate \nand unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering \nsufficient data and having a system robust enough to run it might also be a drain on \nresources. Machine learning can also be prone to error, depending on the input. With \ntoo small a sample, the system could produce a perfectly logical algorithm that is \ncompletely wrong or misleading. To avoid wasting budget or displeasing customers,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4135, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "457473bb-f17c-4a26-a4f7-473ee6f5813d": {"__data__": {"id_": "457473bb-f17c-4a26-a4f7-473ee6f5813d", "embedding": null, "metadata": {"page_label": "4", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "eab98aab-d194-4483-8763-c6adb9876aa4", "node_type": "4", "metadata": {"page_label": "4", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "648d53b00e61433b2a546ab5e88c9b5e92f157f38fbbeeaa80e825af9783cae4", "class_name": "RelatedNodeInfo"}}, "text": "organizations should act on the answers only when there is high confidence in the \noutput. \nReal-world machine learning use cases \nHere are just a few examples of machine learning you might encounter every day: \nSpeech recognition: It is also known as automatic speech recognition (ASR), computer \nspeech recognition, or speech-to-text, and it is a capability which uses natural language \nprocessing (NLP) to translate human speech into a written format. Many mobile devices \nincorporate speech recognition into their systems to conduct voice search\u2014e.g. Siri\u2014or \nimprove accessibility for texting. \nCustomer service: Online chatbots are replacing human agents along the customer \njourney, changing the way we think about customer engagement across websites and \nsocial media platforms. Chatbots answer frequently asked questions (FAQs) about \ntopics such as shipping, or provide personalized advice, cross-selling products or \nsuggesting sizes for users. Examples include virtual agents on e-commerce sites; \nmessaging bots, using Slack and Facebook Messenger; and tasks usually done by \nvirtual assistants and voice assistants. \nComputer vision: This AI technology enables computers to derive meaningful \ninformation from digital images, videos, and other visual inputs, and then take the \nappropriate action. Powered by convolutional neural networks, computer vision has \napplications in photo tagging on social media, radiology imaging in healthcare, and \nself-driving cars in the automotive industry. \nRecommendation engines: Using past consumption behavior data, AI algorithms can \nhelp to discover data trends that can be used to develop more effective cross-selling \nstrategies. Recommendation engines are used by online retailers to make relevant \nproduct recommendations to customers during the checkout process. \nRobotic process automation (RPA): Also known as software robotics, RPA uses \nintelligent automation technologies to perform repetitive manual tasks. \nAutomated stock trading: Designed to optimize stock portfolios, AI-driven \nhigh-frequency trading platforms make thousands or even millions of trades per day \nwithout human intervention. \nFraud detection: Banks and other financial institutions can use machine learning to spot \nsuspicious transactions. Supervised learning can train a model using information about \nknown fraudulent transactions. Anomaly detection can identify transactions that look \natypical and deserve further investigation. \nChallenges of machine learning \nAs machine learning technology has developed, it has certainly made our lives easier. \nHowever, implementing machine learning in businesses has also raised a number of \nethical concerns about AI technologies. Some of these include: \nTechnological singularity \nWhile this topic garners a lot of public attention, many researchers are not concerned \nwith the idea of AI surpassing human intelligence in the near future. Technological \nsingularity is also referred to as strong AI or superintelligence. Philosopher Nick \nBostrum defines superintelligence as \u201cany intellect that vastly outperforms the best \nhuman brains in practically every field, including scientific creativity, general wisdom, \nand social skills.\u201d Despite the fact that superintelligence is not imminent in society, the \nidea of it raises some interesting questions as we consider the use of autonomous \nsystems, like self-driving cars. It\u2019s unrealistic to think that a driverless car would never \nhave an accident, but who is responsible and liable under those circumstances? Should \nwe still develop autonomous vehicles, or do we limit this technology to \nsemi-autonomous vehicles which help people drive safely? The jury is still out on this, \nbut these are the types of ethical debates that are occurring as new, innovative AI \ntechnology develops. \nAI impact on jobs \nWhile a lot of public perception of artificial intelligence centers around job losses, this \nconcern should probably be reframed. With every disruptive, new technology, we see", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bafd021b-e57b-4be0-b250-6d72223a8c81": {"__data__": {"id_": "bafd021b-e57b-4be0-b250-6d72223a8c81", "embedding": null, "metadata": {"page_label": "5", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3be8cd1b-645e-4c2c-b429-8d910b985aa7", "node_type": "4", "metadata": {"page_label": "5", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "30a9909e0961c6633fa2db7dc8b46771d50c3e210e9c4387c43b6226ba38eb76", "class_name": "RelatedNodeInfo"}}, "text": "that the market demand for specific job roles shifts. For example, when we look at the \nautomotive industry, many manufacturers, like GM, are shifting to focus on electric \nvehicle production to align with green initiatives. The energy industry isn\u2019t going away, \nbut the source of energy is shifting from a fuel economy to an electric one. \nIn a similar way, artificial intelligence will shift the demand for jobs to other areas. There \nwill need to be individuals to help manage AI systems. There will still need to be people \nto address more complex problems within the industries that are most likely to be \naffected by job demand shifts, such as customer service. The biggest challenge with \nartificial intelligence and its effect on the job market will be helping people to transition \nto new roles that are in demand. \nPrivacy \nPrivacy tends to be discussed in the context of data privacy, data protection, and data \nsecurity. These concerns have allowed policymakers to make more strides in recent \nyears. For example, in 2016, GDPR legislation was created to protect the personal data \nof people in the European Union and European Economic Area, giving individuals more \ncontrol of their data. In the United States, individual states are developing policies, such \nas the California Consumer Privacy Act (CCPA), which was introduced in 2018 and \nrequires businesses to inform consumers about the collection of their data. Legislation \nsuch as this has forced companies to rethink how they store and use personally \nidentifiable information (PII). As a result, investments in security have become an \nincreasing priority for businesses as they seek to eliminate any vulnerabilities and \nopportunities for surveillance, hacking, and cyberattacks. \nBias and discrimination \nInstances of bias and discrimination across a number of machine learning systems have \nraised many ethical questions regarding the use of artificial intelligence. How can we \nsafeguard against bias and discrimination when the training data itself may be \ngenerated by biased human processes? While companies typically have good \nintentions for their automation efforts, Reuters (link resides outside ibm.com) highlights \nsome of the unforeseen consequences of incorporating AI into hiring practices. In their \neffort to automate and simplify a process, Amazon unintentionally discriminated against \njob candidates by gender for technical roles, and the company ultimately had to scrap \nthe project. Harvard Business Review (link resides outside ibm.com) has raised other \npointed questions about the use of AI in hiring practices, such as what data you should \nbe able to use when evaluating a candidate for a role. \nBias and discrimination aren\u2019t limited to the human resources function either; they can \nbe found in a number of applications from facial recognition software to social media \nalgorithms. \nAs businesses become more aware of the risks with AI, they\u2019ve also become more \nactive in this discussion around AI ethics and values. For example, IBM has sunset its \ngeneral purpose facial recognition and analysis products. IBM CEO Arvind Krishna \nwrote: \u201cIBM firmly opposes and will not condone uses of any technology, including facial \nrecognition technology offered by other vendors, for mass surveillance, racial profiling, \nviolations of basic human rights and freedoms, or any purpose which is not consistent \nwith our values and Principles of Trust and Transparency.\u201d \nAccountability \nSince there isn\u2019t significant legislation to regulate AI practices, there is no real \nenforcement mechanism to ensure that ethical AI is practiced. The current incentives for \ncompanies to be ethical are the negative repercussions of an unethical AI system on the \nbottom line. To fill the gap, ethical frameworks have emerged as part of a collaboration \nbetween ethicists and researchers to govern the construction and distribution of AI \nmodels within society. However, at the moment, these only serve to guide. Some \nresearch (link resides outside ibm.com) shows that the combination of distributed \nresponsibility and a lack of foresight into potential consequences aren\u2019t conducive to \npreventing harm to society. \nRead more about IBM's position on AI Ethics", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e1a85400-fcd8-4b6c-a72e-c24f572c110b": {"__data__": {"id_": "e1a85400-fcd8-4b6c-a72e-c24f572c110b", "embedding": null, "metadata": {"page_label": "6", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5b37a0d6-dbc7-4b1a-85f9-0ff44ee3cbea", "node_type": "4", "metadata": {"page_label": "6", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "5e99e8a10989909af3684baef52ec7162911075fb6962dac28b93cccb053f0b9", "class_name": "RelatedNodeInfo"}}, "text": "How to choose the right AI platform for machine learning \nSelecting a platform can be a challenging process, as the wrong system can drive up \ncosts, or limit the use of other valuable tools or technologies. When reviewing multiple \nvendors to select an AI platform, there is often a tendency to think that more features = \na better system. Maybe so, but reviewers should start by thinking through what the AI \nplatform will be doing for their organization. What machine learning capabilities need to \nbe delivered and what features are important to accomplish them? One missing feature \nmight doom the usefulness of an entire system. Here are some features to consider. \nMLOps capabilities. Does the system have: \na unified interface for ease of management? \nautomated machine learning tools for faster model creation with low-code \nand no-code functionality? \ndecision optimization to streamline the selection and deployment of \noptimization models? \nvisual modeling to combine visual data science with open-source libraries \nand notebook-based interfaces on a unified data and AI studio? \nautomated development for beginners to get started quickly and more \nadvanced data scientists to experiment? \nsynthetic data generator as an alternative or supplement to real-world data \nwhen real-world data is not readily available? \nGenerative AI capabilities. Does the system have: \na content generator that can generate text, images and other content \nbased on the data it was trained on? \nautomated classification to read and classify written input, such as \nevaluating and sorting customer complaints or reviewing customer \nfeedback sentiment? \na summary generator that can transform dense text into a high-quality \nsummary, capture key points from financial reports, and generate meeting \ntranscriptions? \na data extraction capability to sort through complex details and quickly pull \nthe necessary information from large documents?", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1931, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "657b08ba-ab79-450f-ae8e-e234aa283a7b": {"__data__": {"id_": "657b08ba-ab79-450f-ae8e-e234aa283a7b", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7c70da1d-5015-4ac4-9430-ac0d26fca148", "node_type": "1", "metadata": {}, "hash": "9fa2c66da0c09d864ac30d7d3c79d401690db6e28d3cad356a5c5f743f1da4b7", "class_name": "RelatedNodeInfo"}}, "text": "What is machine learning?\nMachine learning is a branch of artificial intelligence (AI) and computer science which\nfocuses on the use of data and algorithms to imitate the way that humans learn,\ngradually improving its accuracy.\nIBM has a rich history with machine learning. One of its own, Arthur Samuel, is credited\nfor coining the term, \u201cmachine learning\u201d with his research (link resides outside ibm.com)\naround the game of checkers. Robert Nealey, the self-proclaimed checkers master,\nplayed the game on an IBM 7094 computer in 1962, and he lost to the computer.\nCompared to what can be done today, this feat seems trivial, but it\u2019s considered a major\nmilestone in the field of artificial intelligence.\nOver the last couple of decades, the technological advances in storage and processing\npower have enabled some innovative products based on machine learning, such as\nNetflix\u2019s recommendation engine and self-driving cars.\nMachine learning is an important component of the growing field of data science.\nThrough the use of statistical methods, algorithms are trained to make classifications or\npredictions, and to uncover key insights in data mining projects. These insights\nsubsequently drive decision making within applications and businesses, ideally\nimpacting key growth metrics. As big data continues to expand and grow, the market\ndemand for new data scientists will increase. They will be required to help identify the\nmost relevant business questions and the data to answer them.\nMachine learning algorithms are typically created using frameworks such as Python that\naccelerate solution development by using platforms like TensorFlow or PyTorch.\nNow available: watsonx.ai\nThe all-new enterprise studio that brings together traditional machine learning along\nwith new generative AI capabilities powered by foundation models.\nTry watsonx.ai\nBegin your journey to AI\nLearn how to scale AI\nExplore the AI Academy\nMachine Learning vs. Deep Learning vs. Neural Networks\nSince deep learning and machine learning tend to be used interchangeably, it\u2019s worth\nnoting the nuances between the two. Machine learning, deep learning, and neural\nnetworks are all sub-fields of artificial intelligence. However, neural networks is actually\na sub-field of machine learning, and deep learning is a sub-field of neural networks.\nThe way in which deep learning and machine learning differ is in how each algorithm\nlearns. \"Deep\" machine learning can use labeled datasets, also known as supervised\nlearning, to inform its algorithm, but it doesn\u2019t necessarily require a labeled dataset. The\ndeep learning process can ingest unstructured data in its raw form (e.g., text or images),\nand it can automatically determine the set of features which distinguish different\ncategories of data from one another. This eliminates some of the human intervention\nrequired and enables the use of large amounts of data. You can think of deep learning\nas \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides\noutside ibm.com).\nClassical, or \"non-deep,\" machine learning is more dependent on human intervention to\nlearn. Human experts determine the set of features to understand the differences\nbetween data inputs, usually requiring more structured data to learn.\nNeural networks, or artificial neural networks (ANNs), are comprised of node layers,\ncontaining an input layer, one or more hidden layers, and an output layer. Each node, or\nartificial neuron, connects to another and has an associated weight and threshold. If the\noutput of any individual node is above the specified threshold value, that node is\nactivated, sending data to the next layer of the network. Otherwise, no data is passed\nalong to the next layer of the network by that node. The \u201cdeep\u201d in deep learning is just\nreferring to the number of layers in a neural network. A neural network that consists of\nmore than three layers\u2014which would be inclusive of the input and the output\u2014can be\nconsidered a deep learning algorithm or a deep neural network. A neural network that\nonly has three layers is just a basic neural network.\nDeep learning and neural networks are credited with accelerating progress in areas\nsuch as computer vision, natural language processing, and speech recognition.\nSee the blog post \u201cAI vs. Machine Learning vs. Deep Learning vs. Neural Networks:\nWhat\u2019s the Difference?\u201d for a closer look at how the different concepts relate.\nRelated content\nExplore the watsonx.ai interactive demo\nDownload \u201cMachine learning for Dummies\u201d\n- This link downloads a pdf\nExplore Gen AI for developers\nHow does machine learning work?\nUC Berkeley (link resides outside ibm.com) breaks out the learning system of a\nmachine learning algorithm into three main parts.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4735, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7c70da1d-5015-4ac4-9430-ac0d26fca148": {"__data__": {"id_": "7c70da1d-5015-4ac4-9430-ac0d26fca148", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "657b08ba-ab79-450f-ae8e-e234aa283a7b", "node_type": "1", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "6b17d5868287452c8502b186020e5710e885a737af21b4871205b8cd57f5f92a", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f62b83b7-c650-4dc4-b699-8e29fe4a3ffd", "node_type": "1", "metadata": {}, "hash": "cb1c8cf0f23caea26faadce7f993ffb9ada03f9d8ab6868ab7d5ba9d6517c1c1", "class_name": "RelatedNodeInfo"}}, "text": "\"Deep\" machine learning can use labeled datasets, also known as supervised\nlearning, to inform its algorithm, but it doesn\u2019t necessarily require a labeled dataset. The\ndeep learning process can ingest unstructured data in its raw form (e.g., text or images),\nand it can automatically determine the set of features which distinguish different\ncategories of data from one another. This eliminates some of the human intervention\nrequired and enables the use of large amounts of data. You can think of deep learning\nas \"scalable machine learning\" as Lex Fridman notes in this MIT lecture (link resides\noutside ibm.com).\nClassical, or \"non-deep,\" machine learning is more dependent on human intervention to\nlearn. Human experts determine the set of features to understand the differences\nbetween data inputs, usually requiring more structured data to learn.\nNeural networks, or artificial neural networks (ANNs), are comprised of node layers,\ncontaining an input layer, one or more hidden layers, and an output layer. Each node, or\nartificial neuron, connects to another and has an associated weight and threshold. If the\noutput of any individual node is above the specified threshold value, that node is\nactivated, sending data to the next layer of the network. Otherwise, no data is passed\nalong to the next layer of the network by that node. The \u201cdeep\u201d in deep learning is just\nreferring to the number of layers in a neural network. A neural network that consists of\nmore than three layers\u2014which would be inclusive of the input and the output\u2014can be\nconsidered a deep learning algorithm or a deep neural network. A neural network that\nonly has three layers is just a basic neural network.\nDeep learning and neural networks are credited with accelerating progress in areas\nsuch as computer vision, natural language processing, and speech recognition.\nSee the blog post \u201cAI vs. Machine Learning vs. Deep Learning vs. Neural Networks:\nWhat\u2019s the Difference?\u201d for a closer look at how the different concepts relate.\nRelated content\nExplore the watsonx.ai interactive demo\nDownload \u201cMachine learning for Dummies\u201d\n- This link downloads a pdf\nExplore Gen AI for developers\nHow does machine learning work?\nUC Berkeley (link resides outside ibm.com) breaks out the learning system of a\nmachine learning algorithm into three main parts.\nA Decision Process: In general, machine learning algorithms are used to make a\nprediction or classification. Based on some input data, which can be labeled or\nunlabeled, your algorithm will produce an estimate about a pattern in the data.\nAn Error Function: An error function evaluates the prediction of the model. If\nthere are known examples, an error function can make a comparison to assess\nthe accuracy of the model.\nA Model Optimization Process: If the model can fit better to the data points in the\ntraining set, then weights are adjusted to reduce the discrepancy between the\nknown example and the model estimate. The algorithm will repeat this iterative\n\u201cevaluate and optimize\u201d process, updating weights autonomously until a\nthreshold of accuracy has been met.\nMachine learning methods\nMachine learning models fall into three primary categories.\nSupervised machine learning\nSupervised learning, also known as supervised machine learning, is defined by its use\nof labeled datasets to train algorithms to classify data or predict outcomes accurately.\nAs input data is fed into the model, the model adjusts its weights until it has been fitted\nappropriately. This occurs as part of the cross validation process to ensure that the\nmodel avoids overfitting or underfitting. Supervised learning helps organizations solve a\nvariety of real-world problems at scale, such as classifying spam in a separate folder\nfrom your inbox. Some methods used in supervised learning include neural networks,\nna\u00efve bayes, linear regression, logistic regression, random forest, and support vector\nmachine (SVM).\nUnsupervised machine learning\nUnsupervised learning, also known as unsupervised machine learning, uses machine\nlearning algorithms to analyze and cluster unlabeled datasets (subsets called clusters).\nThese algorithms discover hidden patterns or data groupings without the need for\nhuman intervention. This method\u2019s ability to discover similarities and differences in\ninformation make it ideal for exploratory data analysis, cross-selling strategies,\ncustomer segmentation, and image and pattern recognition. It\u2019s also used to reduce the\nnumber of features in a model through the process of dimensionality reduction. Principal\ncomponent analysis (PCA) and singular value decomposition (SVD) are two common\napproaches for this. Other algorithms used in unsupervised learning include neural\nnetworks, k-means clustering, and probabilistic clustering methods.", "mimetype": "text/plain", "start_char_idx": 2411, "end_char_idx": 7188, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f62b83b7-c650-4dc4-b699-8e29fe4a3ffd": {"__data__": {"id_": "f62b83b7-c650-4dc4-b699-8e29fe4a3ffd", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c70da1d-5015-4ac4-9430-ac0d26fca148", "node_type": "1", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "d83792e372c38dbaab4f1433e7d48561e110e31644604ae8621597fd23c4d04b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "af11eeed-7f6f-48f7-9cad-5d7b91750f40", "node_type": "1", "metadata": {}, "hash": "b15a2f9c27eff2ac69e4364c19d1461f75e2021924198cf332a5bf667ac3d414", "class_name": "RelatedNodeInfo"}}, "text": "A Decision Process: In general, machine learning algorithms are used to make a\nprediction or classification. Based on some input data, which can be labeled or\nunlabeled, your algorithm will produce an estimate about a pattern in the data.\nAn Error Function: An error function evaluates the prediction of the model. If\nthere are known examples, an error function can make a comparison to assess\nthe accuracy of the model.\nA Model Optimization Process: If the model can fit better to the data points in the\ntraining set, then weights are adjusted to reduce the discrepancy between the\nknown example and the model estimate. The algorithm will repeat this iterative\n\u201cevaluate and optimize\u201d process, updating weights autonomously until a\nthreshold of accuracy has been met.\nMachine learning methods\nMachine learning models fall into three primary categories.\nSupervised machine learning\nSupervised learning, also known as supervised machine learning, is defined by its use\nof labeled datasets to train algorithms to classify data or predict outcomes accurately.\nAs input data is fed into the model, the model adjusts its weights until it has been fitted\nappropriately. This occurs as part of the cross validation process to ensure that the\nmodel avoids overfitting or underfitting. Supervised learning helps organizations solve a\nvariety of real-world problems at scale, such as classifying spam in a separate folder\nfrom your inbox. Some methods used in supervised learning include neural networks,\nna\u00efve bayes, linear regression, logistic regression, random forest, and support vector\nmachine (SVM).\nUnsupervised machine learning\nUnsupervised learning, also known as unsupervised machine learning, uses machine\nlearning algorithms to analyze and cluster unlabeled datasets (subsets called clusters).\nThese algorithms discover hidden patterns or data groupings without the need for\nhuman intervention. This method\u2019s ability to discover similarities and differences in\ninformation make it ideal for exploratory data analysis, cross-selling strategies,\ncustomer segmentation, and image and pattern recognition. It\u2019s also used to reduce the\nnumber of features in a model through the process of dimensionality reduction. Principal\ncomponent analysis (PCA) and singular value decomposition (SVD) are two common\napproaches for this. Other algorithms used in unsupervised learning include neural\nnetworks, k-means clustering, and probabilistic clustering methods.\nSemi-supervised learning\nSemi-supervised learning offers a happy medium between supervised and\nunsupervised learning. During training, it uses a smaller labeled data set to guide\nclassification and feature extraction from a larger, unlabeled data set. Semi-supervised\nlearning can solve the problem of not having enough labeled data for a supervised\nlearning algorithm. It also helps if it\u2019s too costly to label enough data.\nFor a deep dive into the differences between these approaches, check out \"Supervised\nvs. Unsupervised Learning: What's the Difference?\"\nReinforcement machine learning\nReinforcement machine learning is a machine learning model that is similar to\nsupervised learning, but the algorithm isn\u2019t trained using sample data. This model learns\nas it goes by using trial and error. A sequence of successful outcomes will be reinforced\nto develop the best recommendation or policy for a given problem.\nThe IBM Watson\u00ae system that won the Jeopardy! challenge in 2011 is a good example.\nThe system used reinforcement learning to learn when to attempt an answer (or\nquestion, as it were), which square to select on the board, and how much to\nwager\u2014especially on daily doubles.\nLearn more about reinforcement learning\nCommon machine learning algorithms\nA number of machine learning algorithms are commonly used. These include:\nNeural networks: Neural networks simulate the way the human brain works, with\na huge number of linked processing nodes. Neural networks are good at\nrecognizing patterns and play an important role in applications including natural\nlanguage translation, image recognition, speech recognition, and image creation.\nLinear regression: This algorithm is used to predict numerical values, based on a\nlinear relationship between different values. For example, the technique could be\nused to predict house prices based on historical data for the area.\nLogistic regression: This supervised learning algorithm makes predictions for\ncategorical response variables, such as \u201cyes/no\u201d answers to questions. It can be\nused for applications such as classifying spam and quality control on a\nproduction line.\nClustering: Using unsupervised learning, clustering algorithms can identify\npatterns in data so that it can be grouped. Computers can help data scientists by\nidentifying differences between data items that humans have overlooked.", "mimetype": "text/plain", "start_char_idx": 4736, "end_char_idx": 9546, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "af11eeed-7f6f-48f7-9cad-5d7b91750f40": {"__data__": {"id_": "af11eeed-7f6f-48f7-9cad-5d7b91750f40", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f62b83b7-c650-4dc4-b699-8e29fe4a3ffd", "node_type": "1", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "f50849e2cc0c4c85b2fa1db09977220c8a834a2eb4a6e23d3dee5ff872ad4349", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a1b490d9-b503-484c-a83d-c90dc324ec9a", "node_type": "1", "metadata": {}, "hash": "dd5565af973ffb7d6eb8b6eae6158247862b1a599b55b2864fe54a5de31c6e34", "class_name": "RelatedNodeInfo"}}, "text": "Other algorithms used in unsupervised learning include neural\nnetworks, k-means clustering, and probabilistic clustering methods.\nSemi-supervised learning\nSemi-supervised learning offers a happy medium between supervised and\nunsupervised learning. During training, it uses a smaller labeled data set to guide\nclassification and feature extraction from a larger, unlabeled data set. Semi-supervised\nlearning can solve the problem of not having enough labeled data for a supervised\nlearning algorithm. It also helps if it\u2019s too costly to label enough data.\nFor a deep dive into the differences between these approaches, check out \"Supervised\nvs. Unsupervised Learning: What's the Difference?\"\nReinforcement machine learning\nReinforcement machine learning is a machine learning model that is similar to\nsupervised learning, but the algorithm isn\u2019t trained using sample data. This model learns\nas it goes by using trial and error. A sequence of successful outcomes will be reinforced\nto develop the best recommendation or policy for a given problem.\nThe IBM Watson\u00ae system that won the Jeopardy! challenge in 2011 is a good example.\nThe system used reinforcement learning to learn when to attempt an answer (or\nquestion, as it were), which square to select on the board, and how much to\nwager\u2014especially on daily doubles.\nLearn more about reinforcement learning\nCommon machine learning algorithms\nA number of machine learning algorithms are commonly used. These include:\nNeural networks: Neural networks simulate the way the human brain works, with\na huge number of linked processing nodes. Neural networks are good at\nrecognizing patterns and play an important role in applications including natural\nlanguage translation, image recognition, speech recognition, and image creation.\nLinear regression: This algorithm is used to predict numerical values, based on a\nlinear relationship between different values. For example, the technique could be\nused to predict house prices based on historical data for the area.\nLogistic regression: This supervised learning algorithm makes predictions for\ncategorical response variables, such as \u201cyes/no\u201d answers to questions. It can be\nused for applications such as classifying spam and quality control on a\nproduction line.\nClustering: Using unsupervised learning, clustering algorithms can identify\npatterns in data so that it can be grouped. Computers can help data scientists by\nidentifying differences between data items that humans have overlooked.\nDecision trees: Decision trees can be used for both predicting numerical values\n(regression) and classifying data into categories. Decision trees use a branching\nsequence of linked decisions that can be represented with a tree diagram. One of\nthe advantages of decision trees is that they are easy to validate and audit,\nunlike the black box of the neural network.\nRandom forests: In a random forest, the machine learning algorithm predicts a\nvalue or category by combining the results from a number of decision trees.\nAdvantages and disadvantages of machine learning algorithms\nDepending on your budget, need for speed and precision required, each algorithm\ntype\u2014supervised, unsupervised, semi-supervised, or reinforcement\u2014has its own\nadvantages and disadvantages. For example, decision tree algorithms are used for both\npredicting numerical values (regression problems) and classifying data into categories.\nDecision trees use a branching sequence of linked decisions that may be represented\nwith a tree diagram. A prime advantage of decision trees is that they are easier to\nvalidate and audit than a neural network. The bad news is that they can be more\nunstable than other decision predictors.\nOverall, there are many advantages to machine learning that businesses can leverage\nfor new efficiencies. These include machine learning identifying patterns and trends in\nmassive volumes of data that humans might not spot at all. And this analysis requires\nlittle human intervention: just feed in the dataset of interest and let the machine learning\nsystem assemble and refine its own algorithms\u2014which will continually improve with\nmore data input over time. Customers and users can enjoy a more personalized\nexperience as the model learns more with every experience with that person.\nOn the downside, machine learning requires large training datasets that are accurate\nand unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering\nsufficient data and having a system robust enough to run it might also be a drain on\nresources. Machine learning can also be prone to error, depending on the input. With\ntoo small a sample, the system could produce a perfectly logical algorithm that is\ncompletely wrong or misleading. To avoid wasting budget or displeasing customers,\norganizations should act on the answers only when there is high confidence in the\noutput.", "mimetype": "text/plain", "start_char_idx": 7059, "end_char_idx": 11921, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a1b490d9-b503-484c-a83d-c90dc324ec9a": {"__data__": {"id_": "a1b490d9-b503-484c-a83d-c90dc324ec9a", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "af11eeed-7f6f-48f7-9cad-5d7b91750f40", "node_type": "1", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "5ef82bb3a8b981b6d1ae405baad487cfb1ccc55b5911ddf4d56713868f9502de", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ecb12fa0-dbab-4376-8c85-ac0e7a80f3f7", "node_type": "1", "metadata": {}, "hash": "d58ad64b7fb5c85a4930fc760df450513f8d7d70dbcd6eace11e036e16aa8bd2", "class_name": "RelatedNodeInfo"}}, "text": "Computers can help data scientists by\nidentifying differences between data items that humans have overlooked.\nDecision trees: Decision trees can be used for both predicting numerical values\n(regression) and classifying data into categories. Decision trees use a branching\nsequence of linked decisions that can be represented with a tree diagram. One of\nthe advantages of decision trees is that they are easy to validate and audit,\nunlike the black box of the neural network.\nRandom forests: In a random forest, the machine learning algorithm predicts a\nvalue or category by combining the results from a number of decision trees.\nAdvantages and disadvantages of machine learning algorithms\nDepending on your budget, need for speed and precision required, each algorithm\ntype\u2014supervised, unsupervised, semi-supervised, or reinforcement\u2014has its own\nadvantages and disadvantages. For example, decision tree algorithms are used for both\npredicting numerical values (regression problems) and classifying data into categories.\nDecision trees use a branching sequence of linked decisions that may be represented\nwith a tree diagram. A prime advantage of decision trees is that they are easier to\nvalidate and audit than a neural network. The bad news is that they can be more\nunstable than other decision predictors.\nOverall, there are many advantages to machine learning that businesses can leverage\nfor new efficiencies. These include machine learning identifying patterns and trends in\nmassive volumes of data that humans might not spot at all. And this analysis requires\nlittle human intervention: just feed in the dataset of interest and let the machine learning\nsystem assemble and refine its own algorithms\u2014which will continually improve with\nmore data input over time. Customers and users can enjoy a more personalized\nexperience as the model learns more with every experience with that person.\nOn the downside, machine learning requires large training datasets that are accurate\nand unbiased. GIGO is the operative factor: garbage in / garbage out. Gathering\nsufficient data and having a system robust enough to run it might also be a drain on\nresources. Machine learning can also be prone to error, depending on the input. With\ntoo small a sample, the system could produce a perfectly logical algorithm that is\ncompletely wrong or misleading. To avoid wasting budget or displeasing customers,\norganizations should act on the answers only when there is high confidence in the\noutput.\nReal-world machine learning use cases\nHere are just a few examples of machine learning you might encounter every day:\nSpeech recognition: It is also known as automatic speech recognition (ASR), computer\nspeech recognition, or speech-to-text, and it is a capability which uses natural language\nprocessing (NLP) to translate human speech into a written format. Many mobile devices\nincorporate speech recognition into their systems to conduct voice search\u2014e.g. Siri\u2014or\nimprove accessibility for texting.\nCustomer service: Online chatbots are replacing human agents along the customer\njourney, changing the way we think about customer engagement across websites and\nsocial media platforms. Chatbots answer frequently asked questions (FAQs) about\ntopics such as shipping, or provide personalized advice, cross-selling products or\nsuggesting sizes for users. Examples include virtual agents on e-commerce sites;\nmessaging bots, using Slack and Facebook Messenger; and tasks usually done by\nvirtual assistants and voice assistants.\nComputer vision: This AI technology enables computers to derive meaningful\ninformation from digital images, videos, and other visual inputs, and then take the\nappropriate action. Powered by convolutional neural networks, computer vision has\napplications in photo tagging on social media, radiology imaging in healthcare, and\nself-driving cars in the automotive industry.\nRecommendation engines: Using past consumption behavior data, AI algorithms can\nhelp to discover data trends that can be used to develop more effective cross-selling\nstrategies. Recommendation engines are used by online retailers to make relevant\nproduct recommendations to customers during the checkout process.\nRobotic process automation (RPA): Also known as software robotics, RPA uses\nintelligent automation technologies to perform repetitive manual tasks.\nAutomated stock trading: Designed to optimize stock portfolios, AI-driven\nhigh-frequency trading platforms make thousands or even millions of trades per day\nwithout human intervention.\nFraud detection: Banks and other financial institutions can use machine learning to spot\nsuspicious transactions. Supervised learning can train a model using information about\nknown fraudulent transactions. Anomaly detection can identify transactions that look\natypical and deserve further investigation.\nChallenges of machine learning\nAs machine learning technology has developed, it has certainly made our lives easier.\nHowever, implementing machine learning in businesses has also raised a number of\nethical concerns about AI technologies.", "mimetype": "text/plain", "start_char_idx": 9437, "end_char_idx": 14506, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ecb12fa0-dbab-4376-8c85-ac0e7a80f3f7": {"__data__": {"id_": "ecb12fa0-dbab-4376-8c85-ac0e7a80f3f7", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a1b490d9-b503-484c-a83d-c90dc324ec9a", "node_type": "1", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "fb0b72420fded38c30ef706bbf8a1f7d9f273ddab1e71774ba908dd926e94549", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3f356fa0-6086-40e7-908d-36ade5c79691", "node_type": "1", "metadata": {}, "hash": "85ebefa2ca8c07a9074b6abe98c9d805137fc0ad7e8195c512846030b0cc3832", "class_name": "RelatedNodeInfo"}}, "text": "Real-world machine learning use cases\nHere are just a few examples of machine learning you might encounter every day:\nSpeech recognition: It is also known as automatic speech recognition (ASR), computer\nspeech recognition, or speech-to-text, and it is a capability which uses natural language\nprocessing (NLP) to translate human speech into a written format. Many mobile devices\nincorporate speech recognition into their systems to conduct voice search\u2014e.g. Siri\u2014or\nimprove accessibility for texting.\nCustomer service: Online chatbots are replacing human agents along the customer\njourney, changing the way we think about customer engagement across websites and\nsocial media platforms. Chatbots answer frequently asked questions (FAQs) about\ntopics such as shipping, or provide personalized advice, cross-selling products or\nsuggesting sizes for users. Examples include virtual agents on e-commerce sites;\nmessaging bots, using Slack and Facebook Messenger; and tasks usually done by\nvirtual assistants and voice assistants.\nComputer vision: This AI technology enables computers to derive meaningful\ninformation from digital images, videos, and other visual inputs, and then take the\nappropriate action. Powered by convolutional neural networks, computer vision has\napplications in photo tagging on social media, radiology imaging in healthcare, and\nself-driving cars in the automotive industry.\nRecommendation engines: Using past consumption behavior data, AI algorithms can\nhelp to discover data trends that can be used to develop more effective cross-selling\nstrategies. Recommendation engines are used by online retailers to make relevant\nproduct recommendations to customers during the checkout process.\nRobotic process automation (RPA): Also known as software robotics, RPA uses\nintelligent automation technologies to perform repetitive manual tasks.\nAutomated stock trading: Designed to optimize stock portfolios, AI-driven\nhigh-frequency trading platforms make thousands or even millions of trades per day\nwithout human intervention.\nFraud detection: Banks and other financial institutions can use machine learning to spot\nsuspicious transactions. Supervised learning can train a model using information about\nknown fraudulent transactions. Anomaly detection can identify transactions that look\natypical and deserve further investigation.\nChallenges of machine learning\nAs machine learning technology has developed, it has certainly made our lives easier.\nHowever, implementing machine learning in businesses has also raised a number of\nethical concerns about AI technologies. Some of these include:\nTechnological singularity\nWhile this topic garners a lot of public attention, many researchers are not concerned\nwith the idea of AI surpassing human intelligence in the near future. Technological\nsingularity is also referred to as strong AI or superintelligence. Philosopher Nick\nBostrum defines superintelligence as \u201cany intellect that vastly outperforms the best\nhuman brains in practically every field, including scientific creativity, general wisdom,\nand social skills.\u201d Despite the fact that superintelligence is not imminent in society, the\nidea of it raises some interesting questions as we consider the use of autonomous\nsystems, like self-driving cars. It\u2019s unrealistic to think that a driverless car would never\nhave an accident, but who is responsible and liable under those circumstances? Should\nwe still develop autonomous vehicles, or do we limit this technology to\nsemi-autonomous vehicles which help people drive safely? The jury is still out on this,\nbut these are the types of ethical debates that are occurring as new, innovative AI\ntechnology develops.\nAI impact on jobs\nWhile a lot of public perception of artificial intelligence centers around job losses, this\nconcern should probably be reframed. With every disruptive, new technology, we see\nthat the market demand for specific job roles shifts. For example, when we look at the\nautomotive industry, many manufacturers, like GM, are shifting to focus on electric\nvehicle production to align with green initiatives. The energy industry isn\u2019t going away,\nbut the source of energy is shifting from a fuel economy to an electric one.\nIn a similar way, artificial intelligence will shift the demand for jobs to other areas. There\nwill need to be individuals to help manage AI systems. There will still need to be people\nto address more complex problems within the industries that are most likely to be\naffected by job demand shifts, such as customer service. The biggest challenge with\nartificial intelligence and its effect on the job market will be helping people to transition\nto new roles that are in demand.\nPrivacy\nPrivacy tends to be discussed in the context of data privacy, data protection, and data\nsecurity. These concerns have allowed policymakers to make more strides in recent\nyears.", "mimetype": "text/plain", "start_char_idx": 11922, "end_char_idx": 16797, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3f356fa0-6086-40e7-908d-36ade5c79691": {"__data__": {"id_": "3f356fa0-6086-40e7-908d-36ade5c79691", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ecb12fa0-dbab-4376-8c85-ac0e7a80f3f7", "node_type": "1", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "eb38d4903c7827699d685b7770fb49db16e180957608a13bb4985768c5f1b1eb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ab5c7922-dedc-4671-b320-e7b76491f2b8", "node_type": "1", "metadata": {}, "hash": "b8467d847c892871c1cef830bc483d345f79aedaeb40a5be0cb3dfa142655110", "class_name": "RelatedNodeInfo"}}, "text": "However, implementing machine learning in businesses has also raised a number of\nethical concerns about AI technologies. Some of these include:\nTechnological singularity\nWhile this topic garners a lot of public attention, many researchers are not concerned\nwith the idea of AI surpassing human intelligence in the near future. Technological\nsingularity is also referred to as strong AI or superintelligence. Philosopher Nick\nBostrum defines superintelligence as \u201cany intellect that vastly outperforms the best\nhuman brains in practically every field, including scientific creativity, general wisdom,\nand social skills.\u201d Despite the fact that superintelligence is not imminent in society, the\nidea of it raises some interesting questions as we consider the use of autonomous\nsystems, like self-driving cars. It\u2019s unrealistic to think that a driverless car would never\nhave an accident, but who is responsible and liable under those circumstances? Should\nwe still develop autonomous vehicles, or do we limit this technology to\nsemi-autonomous vehicles which help people drive safely? The jury is still out on this,\nbut these are the types of ethical debates that are occurring as new, innovative AI\ntechnology develops.\nAI impact on jobs\nWhile a lot of public perception of artificial intelligence centers around job losses, this\nconcern should probably be reframed. With every disruptive, new technology, we see\nthat the market demand for specific job roles shifts. For example, when we look at the\nautomotive industry, many manufacturers, like GM, are shifting to focus on electric\nvehicle production to align with green initiatives. The energy industry isn\u2019t going away,\nbut the source of energy is shifting from a fuel economy to an electric one.\nIn a similar way, artificial intelligence will shift the demand for jobs to other areas. There\nwill need to be individuals to help manage AI systems. There will still need to be people\nto address more complex problems within the industries that are most likely to be\naffected by job demand shifts, such as customer service. The biggest challenge with\nartificial intelligence and its effect on the job market will be helping people to transition\nto new roles that are in demand.\nPrivacy\nPrivacy tends to be discussed in the context of data privacy, data protection, and data\nsecurity. These concerns have allowed policymakers to make more strides in recent\nyears. For example, in 2016, GDPR legislation was created to protect the personal data\nof people in the European Union and European Economic Area, giving individuals more\ncontrol of their data. In the United States, individual states are developing policies, such\nas the California Consumer Privacy Act (CCPA), which was introduced in 2018 and\nrequires businesses to inform consumers about the collection of their data. Legislation\nsuch as this has forced companies to rethink how they store and use personally\nidentifiable information (PII). As a result, investments in security have become an\nincreasing priority for businesses as they seek to eliminate any vulnerabilities and\nopportunities for surveillance, hacking, and cyberattacks.\nBias and discrimination\nInstances of bias and discrimination across a number of machine learning systems have\nraised many ethical questions regarding the use of artificial intelligence. How can we\nsafeguard against bias and discrimination when the training data itself may be\ngenerated by biased human processes? While companies typically have good\nintentions for their automation efforts, Reuters (link resides outside ibm.com) highlights\nsome of the unforeseen consequences of incorporating AI into hiring practices. In their\neffort to automate and simplify a process, Amazon unintentionally discriminated against\njob candidates by gender for technical roles, and the company ultimately had to scrap\nthe project. Harvard Business Review (link resides outside ibm.com) has raised other\npointed questions about the use of AI in hiring practices, such as what data you should\nbe able to use when evaluating a candidate for a role.\nBias and discrimination aren\u2019t limited to the human resources function either; they can\nbe found in a number of applications from facial recognition software to social media\nalgorithms.\nAs businesses become more aware of the risks with AI, they\u2019ve also become more\nactive in this discussion around AI ethics and values. For example, IBM has sunset its\ngeneral purpose facial recognition and analysis products.", "mimetype": "text/plain", "start_char_idx": 14386, "end_char_idx": 18869, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ab5c7922-dedc-4671-b320-e7b76491f2b8": {"__data__": {"id_": "ab5c7922-dedc-4671-b320-e7b76491f2b8", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3f356fa0-6086-40e7-908d-36ade5c79691", "node_type": "1", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "fca3a6e6159798ee52b3af5beb29cc45b337b71146e6c54841a485ff22636832", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "95e80773-b27e-41fb-af86-6d8474f7d9d0", "node_type": "1", "metadata": {}, "hash": "245f82c83f6c9ab4743d5c35b0d85af2c0d153e11ad7aff32569e35fc4e656bd", "class_name": "RelatedNodeInfo"}}, "text": "The biggest challenge with\nartificial intelligence and its effect on the job market will be helping people to transition\nto new roles that are in demand.\nPrivacy\nPrivacy tends to be discussed in the context of data privacy, data protection, and data\nsecurity. These concerns have allowed policymakers to make more strides in recent\nyears. For example, in 2016, GDPR legislation was created to protect the personal data\nof people in the European Union and European Economic Area, giving individuals more\ncontrol of their data. In the United States, individual states are developing policies, such\nas the California Consumer Privacy Act (CCPA), which was introduced in 2018 and\nrequires businesses to inform consumers about the collection of their data. Legislation\nsuch as this has forced companies to rethink how they store and use personally\nidentifiable information (PII). As a result, investments in security have become an\nincreasing priority for businesses as they seek to eliminate any vulnerabilities and\nopportunities for surveillance, hacking, and cyberattacks.\nBias and discrimination\nInstances of bias and discrimination across a number of machine learning systems have\nraised many ethical questions regarding the use of artificial intelligence. How can we\nsafeguard against bias and discrimination when the training data itself may be\ngenerated by biased human processes? While companies typically have good\nintentions for their automation efforts, Reuters (link resides outside ibm.com) highlights\nsome of the unforeseen consequences of incorporating AI into hiring practices. In their\neffort to automate and simplify a process, Amazon unintentionally discriminated against\njob candidates by gender for technical roles, and the company ultimately had to scrap\nthe project. Harvard Business Review (link resides outside ibm.com) has raised other\npointed questions about the use of AI in hiring practices, such as what data you should\nbe able to use when evaluating a candidate for a role.\nBias and discrimination aren\u2019t limited to the human resources function either; they can\nbe found in a number of applications from facial recognition software to social media\nalgorithms.\nAs businesses become more aware of the risks with AI, they\u2019ve also become more\nactive in this discussion around AI ethics and values. For example, IBM has sunset its\ngeneral purpose facial recognition and analysis products. IBM CEO Arvind Krishna\nwrote: \u201cIBM firmly opposes and will not condone uses of any technology, including facial\nrecognition technology offered by other vendors, for mass surveillance, racial profiling,\nviolations of basic human rights and freedoms, or any purpose which is not consistent\nwith our values and Principles of Trust and Transparency.\u201d\nAccountability\nSince there isn\u2019t significant legislation to regulate AI practices, there is no real\nenforcement mechanism to ensure that ethical AI is practiced. The current incentives for\ncompanies to be ethical are the negative repercussions of an unethical AI system on the\nbottom line. To fill the gap, ethical frameworks have emerged as part of a collaboration\nbetween ethicists and researchers to govern the construction and distribution of AI\nmodels within society. However, at the moment, these only serve to guide. Some\nresearch (link resides outside ibm.com) shows that the combination of distributed\nresponsibility and a lack of foresight into potential consequences aren\u2019t conducive to\npreventing harm to society.\nRead more about IBM's position on AI Ethics\nHow to choose the right AI platform for machine learning\nSelecting a platform can be a challenging process, as the wrong system can drive up\ncosts, or limit the use of other valuable tools or technologies. When reviewing multiple\nvendors to select an AI platform, there is often a tendency to think that more features =\na better system. Maybe so, but reviewers should start by thinking through what the AI\nplatform will be doing for their organization. What machine learning capabilities need to\nbe delivered and what features are important to accomplish them? One missing feature\nmight doom the usefulness of an entire system. Here are some features to consider.\nMLOps capabilities. Does the system have:\na unified interface for ease of management?\nautomated machine learning tools for faster model creation with low-code\nand no-code functionality?\ndecision optimization to streamline the selection and deployment of\noptimization models?\nvisual modeling to combine visual data science with open-source libraries\nand notebook-based interfaces on a unified data and AI studio?\nautomated development for beginners to get started quickly and more\nadvanced data scientists to experiment?\nsynthetic data generator as an alternative or supplement to real-world data\nwhen real-world data is not readily available?\nGenerative AI capabilities. Does the system have:\na content generator that can generate text, images and other content\nbased on the data it was trained on?", "mimetype": "text/plain", "start_char_idx": 16459, "end_char_idx": 21449, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "95e80773-b27e-41fb-af86-6d8474f7d9d0": {"__data__": {"id_": "95e80773-b27e-41fb-af86-6d8474f7d9d0", "embedding": null, "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "88a81797-7850-4cdb-bcc5-c52855615dd9", "node_type": "4", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "2d81ca4fa101861a1672ca6daab5ed37fe335148aa00c93908d84adf381be8da", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ab5c7922-dedc-4671-b320-e7b76491f2b8", "node_type": "1", "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}, "hash": "579fc9fa796c5fae4c8bbd4fc7d59a1c56950e74a739c13be5df9d82402b8f56", "class_name": "RelatedNodeInfo"}}, "text": "The current incentives for\ncompanies to be ethical are the negative repercussions of an unethical AI system on the\nbottom line. To fill the gap, ethical frameworks have emerged as part of a collaboration\nbetween ethicists and researchers to govern the construction and distribution of AI\nmodels within society. However, at the moment, these only serve to guide. Some\nresearch (link resides outside ibm.com) shows that the combination of distributed\nresponsibility and a lack of foresight into potential consequences aren\u2019t conducive to\npreventing harm to society.\nRead more about IBM's position on AI Ethics\nHow to choose the right AI platform for machine learning\nSelecting a platform can be a challenging process, as the wrong system can drive up\ncosts, or limit the use of other valuable tools or technologies. When reviewing multiple\nvendors to select an AI platform, there is often a tendency to think that more features =\na better system. Maybe so, but reviewers should start by thinking through what the AI\nplatform will be doing for their organization. What machine learning capabilities need to\nbe delivered and what features are important to accomplish them? One missing feature\nmight doom the usefulness of an entire system. Here are some features to consider.\nMLOps capabilities. Does the system have:\na unified interface for ease of management?\nautomated machine learning tools for faster model creation with low-code\nand no-code functionality?\ndecision optimization to streamline the selection and deployment of\noptimization models?\nvisual modeling to combine visual data science with open-source libraries\nand notebook-based interfaces on a unified data and AI studio?\nautomated development for beginners to get started quickly and more\nadvanced data scientists to experiment?\nsynthetic data generator as an alternative or supplement to real-world data\nwhen real-world data is not readily available?\nGenerative AI capabilities. Does the system have:\na content generator that can generate text, images and other content\nbased on the data it was trained on?\nautomated classification to read and classify written input, such as\nevaluating and sorting customer complaints or reviewing customer\nfeedback sentiment?\na summary generator that can transform dense text into a high-quality\nsummary, capture key points from financial reports, and generate meeting\ntranscriptions?\na data extraction capability to sort through complex details and quickly pull\nthe necessary information from large documents?", "mimetype": "text/plain", "start_char_idx": 19379, "end_char_idx": 21888, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e8773c7d-5006-44dc-a9e9-d08a61ca5693": {"__data__": {"id_": "e8773c7d-5006-44dc-a9e9-d08a61ca5693", "embedding": null, "metadata": {"page_label": "1", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c8236ec3-79c5-466c-af80-25d0effa6b1c", "node_type": "4", "metadata": {"page_label": "1", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "629613f2fa5d5c47c35b7d4a5bc04cdad86fac119372dd30ebf7ad8fc0be2bf4", "class_name": "RelatedNodeInfo"}}, "text": "Attention Is All You Need\nAshish Vaswani\u2217\nGoogle Brain\navaswani@google.comNoam Shazeer\u2217\nGoogle Brain\nnoam@google.comNiki Parmar\u2217\nGoogle Research\nnikip@google.comJakob Uszkoreit\u2217\nGoogle Research\nusz@google.com\nLlion Jones\u2217\nGoogle Research\nllion@google.comAidan N. Gomez\u2217\u2020\nUniversity of Toronto\naidan@cs.toronto.edu\u0141ukasz Kaiser\u2217\nGoogle Brain\nlukaszkaiser@google.com\nIllia Polosukhin\u2217\u2021\nillia.polosukhin@gmail.com\nAbstract\nThe dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks that include an encoder and a decoder. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer,\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to\nbe superior in quality while being more parallelizable and requiring signi\ufb01cantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-German translation task, improving over the existing best results, including\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\nbest models from the literature.\n1 Introduction\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\nin particular, have been \ufb01rmly established as state of the art approaches in sequence modeling and\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\narchitectures [31, 21, 13].\n\u2217Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the \ufb01rst Transformer models and\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\nattention and the parameter-free position representation and became the other person involved in nearly every\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\nef\ufb01cient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\nour research.\n\u2020Work performed while at Google Brain.\n\u2021Work performed while at Google Research.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2903, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "49d151ed-8df9-473f-a589-586a0191b2ba": {"__data__": {"id_": "49d151ed-8df9-473f-a589-586a0191b2ba", "embedding": null, "metadata": {"page_label": "2", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b8cb43a8-4726-41c7-ba46-c19dfaec4c3e", "node_type": "4", "metadata": {"page_label": "2", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "6b9983cf2a5e7b83d17d2ee329c8481e4dab17339701b5081fdad291fcba558f", "class_name": "RelatedNodeInfo"}}, "text": "Recurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstatesht, as a function of the previous hidden state ht\u22121and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\nsigni\ufb01cant improvements in computational ef\ufb01ciency through factorization tricks [ 18] and conditional\ncomputation [ 26], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [ 2,16]. In all but a few cases [ 22], however, such attention mechanisms\nare used in conjunction with a recurrent network.\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for signi\ufb01cantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2 Background\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n[20], ByteNet [ 15] and ConvS2S [ 8], all of which use convolutional neural networks as basic building\nblock, computing hidden representations in parallel for all input and output positions. In these models,\nthe number of operations required to relate signals from two arbitrary input or output positions grows\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\nit more dif\ufb01cult to learn dependencies between distant positions [ 11]. In the Transformer this is\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\ndescribed in section 3.2.\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\naligned recurrence and have been shown to perform well on simple-language question answering and\nlanguage modeling tasks [28].\nTo the best of our knowledge, however, the Transformer is the \ufb01rst transduction model relying\nentirely on self-attention to compute representations of its input and output without using sequence-\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\nself-attention and discuss its advantages over models such as [14, 15] and [8].\n3 Model Architecture\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,29].\nHere, the encoder maps an input sequence of symbol representations (x1,...,x n)to a sequence\nof continuous representations z= (z1,...,z n). Given z, the decoder then generates an output\nsequence (y1,...,y m)of symbols one element at a time. At each step the model is auto-regressive\n[9], consuming the previously generated symbols as additional input when generating the next.\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\nrespectively.\n3.1 Encoder and Decoder Stacks\nEncoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\nsub-layers. The \ufb01rst is a multi-head self-attention mechanism, and the second is a simple, position-\n2", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4249, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73cd50da-1aa5-417d-8563-a5ecdc657fb2": {"__data__": {"id_": "73cd50da-1aa5-417d-8563-a5ecdc657fb2", "embedding": null, "metadata": {"page_label": "3", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "081ddf92-852f-40bb-b588-538c9fd45e34", "node_type": "4", "metadata": {"page_label": "3", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "8e356e06cc1ceb8e1c3c7e14064eaf2427bf3566614312bdea307b97cd61dc89", "class_name": "RelatedNodeInfo"}}, "text": "Figure 1: The Transformer - model architecture.\nwise fully connected feed-forward network. We employ a residual connection [ 10] around each of\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\nLayerNorm( x+ Sublayer( x)), where Sublayer(x)is the function implemented by the sub-layer\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512 .\nDecoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\npredictions for position ican depend only on the known outputs at positions less than i.\n3.2 Attention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\nof the values, where the weight assigned to each value is computed by a compatibility function of the\nquery with the corresponding key.\n3.2.1 Scaled Dot-Product Attention\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\n3", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1755, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "26ee755e-a30b-4074-9e1f-52c00759ef12": {"__data__": {"id_": "26ee755e-a30b-4074-9e1f-52c00759ef12", "embedding": null, "metadata": {"page_label": "4", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3dfd3637-fe04-425a-832e-319e6865f996", "node_type": "4", "metadata": {"page_label": "4", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "9b0a0200b68659bde32ffc1de1c4120519fc2f8207acd74252def55fb66ed754", "class_name": "RelatedNodeInfo"}}, "text": "Scaled Dot-Product Attention\n Multi-Head Attention\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\nattention layers running in parallel.\nquery with all keys, divide each by\u221adk, and apply a softmax function to obtain the weights on the\nvalues.\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\ninto a matrix Q. The keys and values are also packed together into matrices KandV. We compute\nthe matrix of outputs as:\nAttention(Q,K,V ) = softmax(QKT\n\u221adk)V (1)\nThe two most commonly used attention functions are additive attention [ 2], and dot-product (multi-\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\nof1\u221adk. Additive attention computes the compatibility function using a feed-forward network with\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\nmuch faster and more space-ef\ufb01cient in practice, since it can be implemented using highly optimized\nmatrix multiplication code.\nWhile for small values of dkthe two mechanisms perform similarly, additive attention outperforms\ndot product attention without scaling for larger values of dk[3]. We suspect that for large values of\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\nextremely small gradients4. To counteract this effect, we scale the dot products by1\u221adk.\n3.2.2 Multi-Head Attention\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\nwe found it bene\ufb01cial to linearly project the queries, keys and values htimes with different, learned\nlinear projections to dk,dkanddvdimensions, respectively. On each of these projected versions of\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\noutput values. These are concatenated and once again projected, resulting in the \ufb01nal values, as\ndepicted in Figure 2.\nMulti-head attention allows the model to jointly attend to information from different representation\nsubspaces at different positions. With a single attention head, averaging inhibits this.\n4To illustrate why the dot products get large, assume that the components of qandkare independent random\nvariables with mean 0and variance 1. Then their dot product, q\u00b7k=\u2211dk\ni=1qiki, has mean 0and variance dk.\n4", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2419, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e1dae1df-ac3c-4f8b-98dc-ff8753ac0fee": {"__data__": {"id_": "e1dae1df-ac3c-4f8b-98dc-ff8753ac0fee", "embedding": null, "metadata": {"page_label": "5", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1045d45d-e50c-4c65-950c-87e76a697c6e", "node_type": "4", "metadata": {"page_label": "5", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "6cff8c0be5d33c55e98732a6c39777489a71f3857226b109072e502b04d631dc", "class_name": "RelatedNodeInfo"}}, "text": "MultiHead( Q,K,V ) = Concat(head 1,...,head h)WO\nwhere head i= Attention( QWQ\ni,KWK\ni,VWV\ni)\nWhere the projections are parameter matrices WQ\ni\u2208Rdmodel\u00d7dk,WK\ni\u2208Rdmodel\u00d7dk,WV\ni\u2208Rdmodel\u00d7dv\nandWO\u2208Rhdv\u00d7dmodel.\nIn this work we employ h= 8 parallel attention layers, or heads. For each of these we use\ndk=dv=dmodel/h= 64 . Due to the reduced dimension of each head, the total computational cost\nis similar to that of single-head attention with full dimensionality.\n3.2.3 Applications of Attention in our Model\nThe Transformer uses multi-head attention in three different ways:\n\u2022In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\nand the memory keys and values come from the output of the encoder. This allows every\nposition in the decoder to attend over all positions in the input sequence. This mimics the\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n[31, 2, 8].\n\u2022The encoder contains self-attention layers. In a self-attention layer all of the keys, values\nand queries come from the same place, in this case, the output of the previous layer in the\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\nencoder.\n\u2022Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\nall positions in the decoder up to and including that position. We need to prevent leftward\ninformation \ufb02ow in the decoder to preserve the auto-regressive property. We implement this\ninside of scaled dot-product attention by masking out (setting to \u2212\u221e) all values in the input\nof the softmax which correspond to illegal connections. See Figure 2.\n3.3 Position-wise Feed-Forward Networks\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\nconnected feed-forward network, which is applied to each position separately and identically. This\nconsists of two linear transformations with a ReLU activation in between.\nFFN(x) = max(0,xW 1+b1)W2+b2 (2)\nWhile the linear transformations are the same across different positions, they use different parameters\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\nThe dimensionality of input and output is dmodel = 512 , and the inner-layer has dimensionality\ndff= 2048 .\n3.4 Embeddings and Softmax\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\nlinear transformation, similar to [ 24]. In the embedding layers, we multiply those weights by\u221admodel.\n3.5 Positional Encoding\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\norder of the sequence, we must inject some information about the relative or absolute position of the\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\n5", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3174, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4ae355d4-ce1f-4f1a-996e-a969ba3de09e": {"__data__": {"id_": "4ae355d4-ce1f-4f1a-996e-a969ba3de09e", "embedding": null, "metadata": {"page_label": "6", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "982fa401-3dfb-4937-8004-738030d53def", "node_type": "4", "metadata": {"page_label": "6", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "035388793dcb29f8f034a41beb68c714c0cb72fdc47e3dd6fdd5ac8c1ab53e98", "class_name": "RelatedNodeInfo"}}, "text": "Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\nfor different layer types. nis the sequence length, dis the representation dimension, kis the kernel\nsize of convolutions and rthe size of the neighborhood in restricted self-attention.\nLayer Type Complexity per Layer Sequential Maximum Path Length\nOperations\nSelf-Attention O(n2\u00b7d) O(1) O(1)\nRecurrent O(n\u00b7d2) O(n) O(n)\nConvolutional O(k\u00b7n\u00b7d2)O(1) O(logk(n))\nSelf-Attention (restricted) O(r\u00b7n\u00b7d)O(1) O(n/r)\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\nlearned and \ufb01xed [8].\nIn this work, we use sine and cosine functions of different frequencies:\nPE(pos,2i)=sin(pos/100002i/d model)\nPE(pos,2i+1)=cos(pos/100002i/d model)\nwhereposis the position and iis the dimension. That is, each dimension of the positional encoding\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2\u03c0to10000\u00b72\u03c0. We\nchose this function because we hypothesized it would allow the model to easily learn to attend by\nrelative positions, since for any \ufb01xed offset k,PEpos+kcan be represented as a linear function of\nPEpos.\nWe also experimented with using learned positional embeddings [ 8] instead, and found that the two\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\nduring training.\n4 Why Self-Attention\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\ntional layers commonly used for mapping one variable-length sequence of symbol representations\n(x1,...,x n)to another sequence of equal length (z1,...,z n), withxi,zi\u2208Rd, such as a hidden\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\nconsider three desiderata.\nOne is the total computational complexity per layer. Another is the amount of computation that can\nbe parallelized, as measured by the minimum number of sequential operations required.\nThe third is the path length between long-range dependencies in the network. Learning long-range\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\nability to learn such dependencies is the length of the paths forward and backward signals have to\ntraverse in the network. The shorter these paths between any combination of positions in the input\nand output sequences, the easier it is to learn long-range dependencies [ 11]. Hence we also compare\nthe maximum path length between any two input and output positions in networks composed of the\ndifferent layer types.\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\nexecuted operations, whereas a recurrent layer requires O(n)sequential operations. In terms of\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\nlengthnis smaller than the representation dimensionality d, which is most often the case with\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\n[31] and byte-pair [ 25] representations. To improve computational performance for tasks involving\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size rin\n6", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3508, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e80c9e12-0e3a-4c30-b442-a2cca3ccc153": {"__data__": {"id_": "e80c9e12-0e3a-4c30-b442-a2cca3ccc153", "embedding": null, "metadata": {"page_label": "7", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8d4f18be-6679-4f6e-bc83-e33fef9e8653", "node_type": "4", "metadata": {"page_label": "7", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "f2631000182eb3ba675a475fec97fe0720b040103528fe2bd092693143c2c82b", "class_name": "RelatedNodeInfo"}}, "text": "the input sequence centered around the respective output position. This would increase the maximum\npath length to O(n/r). We plan to investigate this approach further in future work.\nA single convolutional layer with kernel width k<n does not connect all pairs of input and output\npositions. Doing so requires a stack of O(n/k)convolutional layers in the case of contiguous kernels,\norO(logk(n))in the case of dilated convolutions [ 15], increasing the length of the longest paths\nbetween any two positions in the network. Convolutional layers are generally more expensive than\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\nconsiderably, to O(k\u00b7n\u00b7d+n\u00b7d2). Even with k=n, however, the complexity of a separable\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\nthe approach we take in our model.\nAs side bene\ufb01t, self-attention could yield more interpretable models. We inspect attention distributions\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\nand semantic structure of the sentences.\n5 Training\nThis section describes the training regime for our models.\n5.1 Training Data and Batching\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\ntarget vocabulary of about 37000 tokens. For English-French, we used the signi\ufb01cantly larger WMT\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\nvocabulary [ 31]. Sentence pairs were batched together by approximate sequence length. Each training\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\ntarget tokens.\n5.2 Hardware and Schedule\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\n(3.5 days).\n5.3 Optimizer\nWe used the Adam optimizer [ 17] with\u03b21= 0.9,\u03b22= 0.98and\u03f5= 10\u22129. We varied the learning\nrate over the course of training, according to the formula:\nlrate =d\u22120.5\nmodel\u00b7min(step_num\u22120.5,step _num\u00b7warmup _steps\u22121.5) (3)\nThis corresponds to increasing the learning rate linearly for the \ufb01rst warmup _steps training steps,\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\nwarmup _steps = 4000 .\n5.4 Regularization\nWe employ three types of regularization during training:\nResidual Dropout We apply dropout [ 27] to the output of each sub-layer, before it is added to the\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\nPdrop= 0.1.\n7", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3209, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08616f41-959d-402c-9460-8ae5181025e3": {"__data__": {"id_": "08616f41-959d-402c-9460-8ae5181025e3", "embedding": null, "metadata": {"page_label": "8", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3ac9b8bd-feba-4a5f-a387-71180d079a1e", "node_type": "4", "metadata": {"page_label": "8", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "d0c5687a47407b54c0bf92444e141eb0f762c67300cad343c015549f5cc585c2", "class_name": "RelatedNodeInfo"}}, "text": "Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\nModelBLEU Training Cost (FLOPs)\nEN-DE EN-FR EN-DE EN-FR\nByteNet [15] 23.75\nDeep-Att + PosUnk [32] 39.2 1.0\u00b71020\nGNMT + RL [31] 24.6 39.92 2.3\u00b710191.4\u00b71020\nConvS2S [8] 25.16 40.46 9.6\u00b710181.5\u00b71020\nMoE [26] 26.03 40.56 2.0\u00b710191.2\u00b71020\nDeep-Att + PosUnk Ensemble [32] 40.4 8.0\u00b71020\nGNMT + RL Ensemble [31] 26.30 41.16 1.8\u00b710201.1\u00b71021\nConvS2S Ensemble [8] 26.36 41.29 7.7\u00b710191.2\u00b71021\nTransformer (base model) 27.3 38.1 3.3\u00b71018\nTransformer (big) 28.4 41.0 2.3\u00b71019\nLabel Smoothing During training, we employed label smoothing of value \u03f5ls= 0.1[30]. This\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\n6 Results\n6.1 Machine Translation\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The con\ufb01guration of this model is\nlisted in the bottom line of Table 3. Training took 3.5days on 8P100 GPUs. Even our base model\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\nthe competitive models.\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\noutperforming all of the previously published single models, at less than 1/4the training cost of the\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\ndropout rate Pdrop= 0.1, instead of 0.3.\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\nused beam search with a beam size of 4and length penalty \u03b1= 0.6[31]. These hyperparameters\nwere chosen after experimentation on the development set. We set the maximum output length during\ninference to input length + 50, but terminate early when possible [31].\nTable 2 summarizes our results and compares our translation quality and training costs to other model\narchitectures from the literature. We estimate the number of \ufb02oating point operations used to train a\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\nsingle-precision \ufb02oating-point capacity of each GPU5.\n6.2 Model Variations\nTo evaluate the importance of different components of the Transformer, we varied our base model\nin different ways, measuring the change in performance on English-to-German translation on the\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\ncheckpoint averaging. We present these results in Table 3.\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\n8", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3283, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "59125d5c-dc15-4241-bb7e-fc40e86fbe73": {"__data__": {"id_": "59125d5c-dc15-4241-bb7e-fc40e86fbe73", "embedding": null, "metadata": {"page_label": "9", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8370cd5e-ef89-4abf-ba32-ecf770c2b4f4", "node_type": "4", "metadata": {"page_label": "9", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "2e7f581b32deadbf80156a4fa41337808c666b068c0352f9ec922d226531e14c", "class_name": "RelatedNodeInfo"}}, "text": "Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\nper-word perplexities.\nN d modeldffh d kdvPdrop\u03f5lstrain PPL BLEU params\nsteps (dev) (dev)\u00d7106\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\n(A)1 512 512 5.29 24.9\n4 128 128 5.00 25.5\n16 32 32 4.91 25.8\n32 16 16 5.01 25.4\n(B)16 5.16 25.1 58\n32 5.01 25.4 60\n(C)2 6.11 23.7 36\n4 5.19 25.3 50\n8 4.88 25.5 80\n256 32 32 5.75 24.5 28\n1024 128 128 4.66 26.0 168\n1024 5.12 25.4 53\n4096 4.75 26.2 90\n(D)0.0 5.77 24.6\n0.2 4.95 25.5\n0.0 4.67 25.3\n0.2 5.47 25.7\n(E) positional embedding instead of sinusoids 4.92 25.7\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\nIn Table 3 rows (B), we observe that reducing the attention key size dkhurts model quality. This\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\nfunction than dot product may be bene\ufb01cial. We further observe in rows (C) and (D) that, as expected,\nbigger models are better, and dropout is very helpful in avoiding over-\ufb01tting. In row (E) we replace our\nsinusoidal positional encoding with learned positional embeddings [ 8], and observe nearly identical\nresults to the base model.\n7 Conclusion\nIn this work, we presented the Transformer, the \ufb01rst sequence transduction model based entirely on\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\nmulti-headed self-attention.\nFor translation tasks, the Transformer can be trained signi\ufb01cantly faster than architectures based\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\nmodel outperforms even all previously reported ensembles.\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\nplan to extend the Transformer to problems involving input and output modalities other than text and\nto investigate local, restricted attention mechanisms to ef\ufb01ciently handle large inputs and outputs\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\nThe code we used to train and evaluate our models is available at https://github.com/\ntensorflow/tensor2tensor .\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\ncomments, corrections and inspiration.\n9", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2609, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7b21c50e-be6d-4f0f-9f69-38c6ee3d1426": {"__data__": {"id_": "7b21c50e-be6d-4f0f-9f69-38c6ee3d1426", "embedding": null, "metadata": {"page_label": "10", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6640a5ed-a358-4e2b-91e6-536a4936d4e5", "node_type": "4", "metadata": {"page_label": "10", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "3ef67d5c478ff670bac04f3ead6abf0bfeb8d00d7317ce53d10c5f5a27e9c7ff", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a6f19505-fbb4-4b67-b9cb-ecad0ddcc2bd", "node_type": "1", "metadata": {}, "hash": "732bc7aae7819af31fc44576f8c06d9a8eb5683ee441ce648099af9d24e2cfbc", "class_name": "RelatedNodeInfo"}}, "text": "References\n[1]Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\narXiv:1607.06450 , 2016.\n[2]Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\nlearning to align and translate. CoRR , abs/1409.0473, 2014.\n[3]Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\nmachine translation architectures. CoRR , abs/1703.03906, 2017.\n[4]Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\nreading. arXiv preprint arXiv:1601.06733 , 2016.\n[5]Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\nmachine translation. CoRR , abs/1406.1078, 2014.\n[6]Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\npreprint arXiv:1610.02357 , 2016.\n[7]Junyoung Chung, \u00c7aglar G\u00fcl\u00e7ehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\nof gated recurrent neural networks on sequence modeling. CoRR , abs/1412.3555, 2014.\n[8]Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2 , 2017.\n[9]Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\narXiv:1308.0850 , 2013.\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition , pages 770\u2013778, 2016.\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and J\u00fcrgen Schmidhuber. Gradient \ufb02ow in\nrecurrent nets: the dif\ufb01culty of learning long-term dependencies, 2001.\n[12] Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation ,\n9(8):1735\u20131780, 1997.\n[13] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\nthe limits of language modeling. arXiv preprint arXiv:1602.02410 , 2016.\n[14] \u0141ukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\non Learning Representations (ICLR) , 2016.\n[15] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2 ,\n2017.\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\nInInternational Conference on Learning Representations , 2017.\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR , 2015.\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\narXiv:1703.10722 , 2017.\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\nZhou, and Yoshua Bengio.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2870, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a6f19505-fbb4-4b67-b9cb-ecad0ddcc2bd": {"__data__": {"id_": "a6f19505-fbb4-4b67-b9cb-ecad0ddcc2bd", "embedding": null, "metadata": {"page_label": "10", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6640a5ed-a358-4e2b-91e6-536a4936d4e5", "node_type": "4", "metadata": {"page_label": "10", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "3ef67d5c478ff670bac04f3ead6abf0bfeb8d00d7317ce53d10c5f5a27e9c7ff", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7b21c50e-be6d-4f0f-9f69-38c6ee3d1426", "node_type": "1", "metadata": {"page_label": "10", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "3c78754b8b4da237a612b444dea91d90d4a7406c15e75055f1a7bc0fe6039dae", "class_name": "RelatedNodeInfo"}}, "text": "[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition , pages 770\u2013778, 2016.\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and J\u00fcrgen Schmidhuber. Gradient \ufb02ow in\nrecurrent nets: the dif\ufb01culty of learning long-term dependencies, 2001.\n[12] Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation ,\n9(8):1735\u20131780, 1997.\n[13] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\nthe limits of language modeling. arXiv preprint arXiv:1602.02410 , 2016.\n[14] \u0141ukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\non Learning Representations (ICLR) , 2016.\n[15] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2 ,\n2017.\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\nInInternational Conference on Learning Representations , 2017.\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR , 2015.\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\narXiv:1703.10722 , 2017.\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\narXiv:1703.03130 , 2017.\n[20] Samy Bengio \u0141ukasz Kaiser. Can active memory replace attention? In Advances in Neural\nInformation Processing Systems, (NIPS) , 2016.\n10", "mimetype": "text/plain", "start_char_idx": 1394, "end_char_idx": 3099, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d6151167-3060-4503-8afd-5f375e9dbeff": {"__data__": {"id_": "d6151167-3060-4503-8afd-5f375e9dbeff", "embedding": null, "metadata": {"page_label": "11", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0a07be52-f662-4822-b001-331d0ac88dff", "node_type": "4", "metadata": {"page_label": "11", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}, "hash": "ed8f29d43e88935b580f69ed755c17b511424500f350ddec9be0d7dc236377e1", "class_name": "RelatedNodeInfo"}}, "text": "[21] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\nbased neural machine translation. arXiv preprint arXiv:1508.04025 , 2015.\n[22] Ankur Parikh, Oscar T\u00e4ckstr\u00f6m, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\nmodel. In Empirical Methods in Natural Language Processing , 2016.\n[23] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\nsummarization. arXiv preprint arXiv:1705.04304 , 2017.\n[24] O\ufb01r Press and Lior Wolf. Using the output embedding to improve language models. arXiv\npreprint arXiv:1608.05859 , 2016.\n[25] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\nwith subword units. arXiv preprint arXiv:1508.07909 , 2015.\n[26] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\nlayer. arXiv preprint arXiv:1701.06538 , 2017.\n[27] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from over\ufb01tting. Journal of Machine\nLearning Research , 15(1):1929\u20131958, 2014.\n[28] Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems 28 , pages 2440\u20132448. Curran Associates,\nInc., 2015.\n[29] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\nnetworks. In Advances in Neural Information Processing Systems , pages 3104\u20133112, 2014.\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\nRethinking the inception architecture for computer vision. CoRR , abs/1512.00567, 2015.\n[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google\u2019s neural machine\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\narXiv:1609.08144 , 2016.\n[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\nfast-forward connections for neural machine translation. CoRR , abs/1606.04199, 2016.\n11", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7c98b49f-46eb-4a77-a842-4e1be44e99db": {"__data__": {"id_": "7c98b49f-46eb-4a77-a842-4e1be44e99db", "embedding": null, "metadata": {"page_label": "1", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cff25309-ccf5-4af2-872d-4776bec5d113", "node_type": "4", "metadata": {"page_label": "1", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "e09dbca05f5cd23c083ab2004ef3d9ddb172ec2db59b44ffe2a3b999dabb0b27", "class_name": "RelatedNodeInfo"}}, "text": "2INTELLIGENT AGENTS\nInwhichwediscusswhatanintelligent agentdoes,howitisrelatedtoitsenvironment,\nhowitisevaluated, andhowwemightgoaboutbuildingone.\n2.1INTRODUCTION\nAnagentisanythingthatcanbeviewedasperceivingitsenvironmentthroughsensorsandacting\nuponthatenvironment througheffectors.Ahumanagenthaseyes,ears,andotherorgansfor\nsensors,andhands,legs,mouth,andotherbodypartsforeffectors.Aroboticagentsubstitutes\ncamerasandinfraredrange\u00aendersforthesensorsandvariousmotorsfortheeffectors. A\nsoftwareagenthasencodedbitstringsasitsperceptsandactions.Agenericagentisdiagrammed\ninFigure2.1.\nOuraiminthisbookistodesignagentsthatdoagoodjobofactingontheirenvironment.\nFirst,wewillbealittlemorepreciseaboutwhatwemeanbyagoodjob.Thenwewilltalkabout\ndifferentdesignsforsuccessful agents\u00d0\u00aelling inthequestionmarkinFigure2.1.Wediscuss\nsomeofthegeneralprinciples usedinthedesignofagentsthroughout thebook,chiefamong\nwhichistheprinciple thatagentsshouldknowthings.Finally,weshowhowtocoupleanagent\ntoanenvironment anddescribeseveralkindsofenvironments.\n2.2HOWAGENTSSHOULDACT\nArationalagentisonethatdoestherightthing.Obviously,thisisbetterthandoingthewrong RATIONALAGENT\nthing,butwhatdoesitmean?Asa\u00aerstapproximation, wewillsaythattherightactionisthe\nonethatwillcausetheagenttobemostsuccessful. Thatleavesuswiththeproblemofdeciding\nhowandwhentoevaluatetheagent'ssuccess.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.31", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1442, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "99e35303-726e-42fc-b575-4f7d4489ab6c": {"__data__": {"id_": "99e35303-726e-42fc-b575-4f7d4489ab6c", "embedding": null, "metadata": {"page_label": "2", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a032f2ea-36a8-4b14-998f-689e1ce45c2c", "node_type": "4", "metadata": {"page_label": "2", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "1defdfa88203a7412e76ebc00d07a17889007e73f4020a58cc5853a81f546e9b", "class_name": "RelatedNodeInfo"}}, "text": "32 Chapter 2.Intelligent Agents\n?\nagentperceptssensors\nactions\neffectorsenvironment\nFigure2.1Agentsinteractwithenvironments throughsensorsandeffectors.\nWeusethetermperformance measureforthehow\u00d0thecriteriathatdetermine howPERFORMANCE\nMEASURE\nsuccessful anagentis.Obviously,thereisnotone\u00aexedmeasuresuitableforallagents.We\ncouldasktheagentforasubjectiveopinionofhowhappyitiswithitsownperformance, but\nsomeagentswouldbeunabletoanswer,andotherswoulddeludethemselves.(Humanagentsin\nparticular arenotorious for\u00aasourgrapes\u00ba\u00d0saying theydidnotreallywantsomething afterthey\nareunsuccessful atgettingit.)Therefore, wewillinsistonanobjectiveperformance measure\nimposedbysomeauthority.Inotherwords,weasoutsideobserversestablishastandardofwhat\nitmeanstobesuccessful inanenvironment anduseittomeasuretheperformance ofagents.\nAsanexample,considerthecaseofanagentthatissupposed tovacuumadirty\u00afoor.A\nplausible performance measurewouldbetheamountofdirtcleanedupinasingleeight-hour shift.\nAmoresophisticated performance measurewouldfactorintheamountofelectricity consumed\nandtheamountofnoisegenerated aswell.Athirdperformance measuremightgivehighest\nmarkstoanagentthatnotonlycleansthe\u00afoorquietlyandef\u00aeciently,butalso\u00aendstimetogo\nwindsur\u00aeng attheweekend.1\nThewhenofevaluatingperformance isalsoimportant. Ifwemeasured howmuchdirtthe\nagenthadcleanedupinthe\u00aersthouroftheday,wewouldberewardingthoseagentsthatstart\nfast(eveniftheydolittleornoworklateron),andpunishing thosethatworkconsistently .Thus,\nwewanttomeasureperformance overthelongrun,beitaneight-hour shiftoralifetime.\nWeneedtobecarefultodistinguish betweenrationality andomniscience .Anomniscient OMNISCIENCE\nagentknowstheactualoutcome ofitsactions,andcanactaccordingly; butomniscience is\nimpossible inreality.Consider thefollowingexample:IamwalkingalongtheChampsElys\u00c2ees\nonedayandIseeanoldfriendacrossthestreet.Thereisnotraf\u00aecnearbyandI'mnototherwise\nengaged, so,beingrational,Istarttocrossthestreet.Meanwhile, at33,000feet,acargodoor\nfallsoffapassingairliner,2andbeforeImakeittotheothersideofthestreetIam\u00afattened. Was\nIirrational tocrossthestreet?Itisunlikelythatmyobituarywouldread\u00aaIdiotattemptstocross\n1Thereisadangerhereforthosewhoestablish performance measures: youoftengetwhatyouaskfor.Thatis,if\nyoumeasuresuccessbytheamountofdirtcleanedup,thensomecleveragentisboundtobringinaloadofdirteach\nmorning, quicklycleanitup,andgetagoodperformance score.Whatyoureallywanttomeasureishowcleanthe\u00afoor\nis,butdetermining thatismoredif\u00aecultthanjustweighing thedirtcleanedup.\n2SeeN.Henderson, \u00aaNewdoorlatchesurgedforBoeing747jumbojets,\u00baWashington Post,8/24/89.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2680, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a597c390-afb4-4a8f-ad95-d8bb8ce29e76": {"__data__": {"id_": "a597c390-afb4-4a8f-ad95-d8bb8ce29e76", "embedding": null, "metadata": {"page_label": "3", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d744111e-1d36-4033-a5ab-b694d7f347f6", "node_type": "4", "metadata": {"page_label": "3", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "d398d1c6ae4869799d0c095ea620bd83b823484bb6a05a1544cde304f70f6e27", "class_name": "RelatedNodeInfo"}}, "text": "Section2.2.HowAgentsShouldAct 33\nstreet.\u00baRather,thispointsoutthatrationality isconcerned withexpectedsuccessgivenwhathas\nbeenperceived.Crossing thestreetwasrationalbecausemostofthetimethecrossingwouldbe\nsuccessful, andtherewasnowayIcouldhaveforeseenthefallingdoor.Notethatanotheragent\nthatwasequipped withradarfordetecting fallingdoorsorasteelcagestrongenoughtorepel\nthemwouldbemoresuccessful, butitwouldnotbeanymorerational.\nInotherwords,wecannotblameanagentforfailingtotakeintoaccountsomething itcould\nnotperceive,orforfailingtotakeanaction(suchasrepelling thecargodoor)thatitisincapable\noftaking.Butrelaxingtherequirement ofperfection isnotjustaquestionofbeingfairtoagents.\nThepointisthatifwespecifythatanintelligent agentshouldalwaysdowhatisactuallytheright\nthing,itwillbeimpossible todesignanagenttoful\u00aellthisspeci\u00aecation\u00d0unless weimprovethe\nperformance ofcrystalballs.\nInsummary,whatisrationalatanygiventimedependsonfourthings:\nTheperformance measurethatde\u00aenesdegreeofsuccess.\nEverythingthattheagenthasperceivedsofar.Wewillcallthiscomplete perceptual history\ntheperceptsequence . PERCEPT SEQUENCE\nWhattheagentknowsabouttheenvironment.\nTheactionsthattheagentcanperform.\nThisleadstoade\u00aenition ofanidealrationalagent:Foreachpossibleperceptsequence, anIDEALRATIONAL\nAGENT\nidealrationalagentshoulddowhateveractionisexpectedtomaximize itsperformance measure,\nonthebasisoftheevidenceprovidedbytheperceptsequence andwhateverbuilt-inknowledge\ntheagenthas.\nWeneedtolookcarefully atthisde\u00aenition. At\u00aerstglance,itmightappeartoallowan\nagenttoindulgeinsomedecidedly underintelligent activities.Forexample,ifanagentdoesnot\nlookbothwaysbeforecrossingabusyroad,thenitsperceptsequence willnottellitthatthereis\nalargetruckapproaching athighspeed.Thede\u00aenition seemstosaythatitwouldbeOKforitto\ncrosstheroad.Infact,thisinterpretation iswrongontwocounts.First,itwouldnotberational\ntocrosstheroad:theriskofcrossingwithoutlookingistoogreat.Second,anidealrational\nagentwouldhavechosenthe\u00aalooking\u00ba actionbeforesteppingintothestreet,becauselooking\nhelpsmaximize theexpectedperformance. Doingactionsinordertoobtainusefulinformation\nisanimportant partofrationality andiscoveredindepthinChapter16.\nThenotionofanagentismeanttobeatoolforanalyzing systems, notanabsolute\ncharacterization thatdividestheworldintoagentsandnon-agents. Consider aclock.Itcanbe\nthoughtofasjustaninanimate object,oritcanbethoughtofasasimpleagent.Asanagent,\nmostclocksalwaysdotherightaction:movingtheirhands(ordisplaying digits)intheproper\nfashion.Clocksareakindofdegenerateagentinthattheirperceptsequence isempty;nomatter\nwhathappensoutside,theclock'sactionshouldbeunaffected.\nWell,thisisnotquitetrue.IftheclockanditsownertakeatripfromCalifornia toAustralia,\ntherightthingfortheclocktodowouldbetoturnitselfbacksixhours.Wedonotgetupsetat\nourclocksforfailingtodothisbecausewerealizethattheyareactingrationally ,giventheirlack\nofperceptual equipment.3\n3Oneoftheauthorsstillgetsasmallthrillwhenhiscomputer successfully resetsitselfatdaylightsavingstime.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3093, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b9af6c60-d611-4c18-a0da-ed76da139238": {"__data__": {"id_": "b9af6c60-d611-4c18-a0da-ed76da139238", "embedding": null, "metadata": {"page_label": "4", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "680171bd-ab73-451b-ae9e-bf188dd8f396", "node_type": "4", "metadata": {"page_label": "4", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "9b0c591a2bd8c253f7b2acc2ee83aa32cda9cf89ca46a2a4377134cd444db3a2", "class_name": "RelatedNodeInfo"}}, "text": "34 Chapter 2.Intelligent Agents\nTheidealmapping fromperceptsequences toactions\nOncewerealizethatanagent'sbehaviordependsonlyonitsperceptsequence todate,thenwecan\ndescribeanyparticular agentbymakingatableoftheactionittakesinresponsetoeachpossible\nperceptsequence. (Formostagents,thiswouldbeaverylonglist\u00d0in\u00aenite, infact,unlesswe\nplaceaboundonthelengthofperceptsequences wewanttoconsider.)Suchalistiscalled\namapping fromperceptsequences toactions.Wecan,inprinciple, \u00aendoutwhichmapping MAPPING\ncorrectly describes anagentbytryingoutallpossibleperceptsequences andrecording which\nactionstheagentdoesinresponse. (Iftheagentusessomerandomization initscomputations,\nthenwewouldhavetotrysomeperceptsequences severaltimestogetagoodideaoftheagent's\naveragebehavior.)Andifmappings describeagents,thenidealmappings describeidealagents. IDEALMAPPINGS\nSpecifying whichactionanagentoughttotakeinresponsetoanygivenperceptsequence provides\nadesignforanidealagent.\nThisdoesnotmean,ofcourse,thatwehavetocreateanexplicittablewithanentry\nforeverypossibleperceptsequence. Itispossibletode\u00aeneaspeci\u00aecation ofthemapping\nwithoutexhaustivelyenumerating it.Consider averysimpleagent:thesquare-root function\nonacalculator .Theperceptsequence forthisagentisasequence ofkeystrokesrepresenting a\nnumber,andtheactionistodisplayanumberonthedisplayscreen.Theidealmapping isthat\nwhentheperceptisapositivenumberx,therightactionistodisplayapositivenumberzsuch\nthatz2\nx,accurateto,say,15decimalplaces.Thisspeci\u00aecation oftheidealmapping does\nnotrequirethedesignertoactuallyconstruct atableofsquareroots.Nordoesthesquare-root\nfunctionhavetouseatabletobehavecorrectly: Figure2.2showspartoftheidealmappingand\nasimpleprogramthatimplements themappingusingNewton'smethod.\nThesquare-root exampleillustrates therelationship betweentheidealmapping andan\nidealagentdesign,foraveryrestricted task.Whereasthetableisverylarge,theagentisanice,\ncompactprogram. Itturnsoutthatitispossibletodesignnice,compactagentsthatimplement\nPerceptx Actionz\n1.0 1.000000000000000\n1.1 1.048808848170152\n1.2 1.095445115010332\n1.3 1.140175425099138\n1.4 1.183215956619923\n1.5 1.224744871391589\n1.6 1.264911064067352\n1.7 1.303840481040530\n1.8 1.341640786499874\n1.9 1.378404875209022\n......function SQRT(x)\nz\n1.0/*initialguess*/\nrepeatuntil\nz2\nx\n<10\n15\nz\nz\n(z2\nx)/(2z)\nend\nreturnz\nFigure2.2Partoftheidealmappingforthesquare-root problem(accurate to15digits),anda\ncorresponding programthatimplements theidealmapping.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2536, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "770f1749-36fc-47f6-8d68-65b60e0364bd": {"__data__": {"id_": "770f1749-36fc-47f6-8d68-65b60e0364bd", "embedding": null, "metadata": {"page_label": "5", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7a19d4f7-7aae-4520-8d99-4bea36d8fcd1", "node_type": "4", "metadata": {"page_label": "5", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "33228439e49c7f195dda4c8a78c982ca3a0a7a0968546f07d1d5b680d424326d", "class_name": "RelatedNodeInfo"}}, "text": "Section2.3.Structure ofIntelligent Agents 35\ntheidealmappingformuchmoregeneralsituations: agentsthatcansolvealimitlessvarietyof\ntasksinalimitlessvarietyofenvironments. Beforewediscusshowtodothis,weneedtolook\natonemorerequirement thatanintelligent agentoughttosatisfy.\nAutonomy\nThereisonemorethingtodealwithinthede\u00aenition ofanidealrationalagent:the\u00aabuilt-in\nknowledge\u00bapart.Iftheagent'sactionsarebasedcompletely onbuilt-inknowledge,suchthatit\nneedpaynoattention toitspercepts, thenwesaythattheagentlacksautonomy .Forexample, AUTONOMY\niftheclockmanufacturer wasprescient enoughtoknowthattheclock'sownerwouldbegoing\ntoAustralia atsomeparticular date,thenamechanism couldbebuiltintoadjustthehands\nautomatically bysixhoursatjusttherighttime.Thiswouldcertainlybesuccessful behavior,but\ntheintelligence seemstobelongtotheclock'sdesignerratherthantotheclockitself.\nAnagent'sbehaviorcanbebasedonbothitsownexperience andthebuilt-inknowledge\nusedinconstructing theagentfortheparticular environment inwhichitoperates. Asystemis\nautonomous4totheextentthatitsbehavior isdetermined byitsownexperience .Itwouldbe\ntoostringent, though,torequirecomplete autonomy fromthewordgo:whentheagenthashad\nlittleornoexperience, itwouldhavetoactrandomly unlessthedesignergavesomeassistance.\nSo,justasevolutionprovidesanimalswithenoughbuilt-inre\u00afexessothattheycansurvivelong\nenoughtolearnforthemselves,itwouldbereasonable toprovideanarti\u00aecialintelligent agent\nwithsomeinitialknowledgeaswellasanabilitytolearn.\nAutonomy notonly\u00aetsinwithourintuition, butitisanexampleofsoundengineering\npractices. Anagentthatoperatesonthebasisofbuilt-inassumptions willonlyoperatesuccess-\nfullywhenthoseassumptions hold,andthuslacks\u00afexibility.Consider,forexample,thelowly\ndungbeetle.Afterdiggingitsnestandlayingitseggs,itfetchesaballofdungfromanearbyheap\ntoplugtheentrance; iftheballofdungisremovedfromitsgraspenroute,thebeetlecontinues\nonandpantomimes plugging thenestwiththenonexistentdungball,nevernoticingthatitis\nmissing. Evolutionhasbuiltanassumption intothebeetle'sbehavior,andwhenitisviolated,\nunsuccessful behaviorresults.Atrulyautonomous intelligent agentshouldbeabletooperate\nsuccessfully inawidevarietyofenvironments, givensuf\u00aecienttimetoadapt.\n2.3STRUCTURE OFINTELLIGENT AGENTS\nSofarwehavetalkedaboutagentsbydescribing theirbehavior\u00d0theactionthatisperformed\nafteranygivensequence ofpercepts. Now,wewillhavetobitethebulletandtalkabouthow\ntheinsideswork.ThejobofAIistodesigntheagentprogram:afunctionthatimplements AGENTPROGRAM\ntheagentmapping fromperceptstoactions.Weassumethisprogramwillrunonsomesortof\ncomputing device,whichwewillcallthearchitectur e.Obviously,theprogramwechoosehas ARCHITECTURE\n4Theword\u00aaautonomous\u00ba hasalsocometomeansomething like\u00aanotundertheimmediate controlofahuman,\u00baasin\n\u00aaautonomous landvehicle.\u00baWeareusingitinastrongersense.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2904, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "064668e8-b755-4fc3-8c18-462bcad5567c": {"__data__": {"id_": "064668e8-b755-4fc3-8c18-462bcad5567c", "embedding": null, "metadata": {"page_label": "6", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9fc7c8d9-9572-4de2-b7a0-8396e1731c65", "node_type": "4", "metadata": {"page_label": "6", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "ae2b7dcdd31ab96f48c0a2b17dccf9a1e70762c6d346d43f650f6c12313aa36e", "class_name": "RelatedNodeInfo"}}, "text": "36 Chapter 2.Intelligent Agents\ntobeonethatthearchitecture willacceptandrun.Thearchitecture mightbeaplaincomputer,or\nitmightincludespecial-purpose hardware forcertaintasks,suchasprocessing cameraimagesor\n\u00aelteringaudioinput.Itmightalsoincludesoftwarethatprovidesadegreeofinsulation between\ntherawcomputer andtheagentprogram, sothatwecanprogramatahigherlevel.Ingeneral,\nthearchitecture makestheperceptsfromthesensorsavailabletotheprogram, runstheprogram,\nandfeedstheprogram'sactionchoicestotheeffectorsastheyaregenerated. Therelationship\namongagents,architectures, andprograms canbesummedupasfollows:\nagent=architecture+program\nMostofthisbookisaboutdesigning agentprograms, althoughChapters 24and25dealdirectly\nwiththearchitecture.\nBeforewedesignanagentprogram, wemusthaveaprettygoodideaofthepossible\nperceptsandactions,whatgoalsorperformance measuretheagentissupposed toachieve,and\nwhatsortofenvironment itwilloperatein.5Thesecomeinawidevariety.Figure2.3showsthe\nbasicelements foraselection ofagenttypes.\nItmaycomeasasurprisetosomereadersthatweincludeinourlistofagenttypessome\nprograms thatseemtooperateintheentirelyarti\u00aecialenvironment de\u00aenedbykeyboardinput\nandcharacter outputonascreen.\u00aaSurely,\u00baonemightsay,\u00aathisisnotarealenvironment, is\nit?\u00baInfact,whatmattersisnotthedistinction between\u00aareal\u00baand\u00aaarti\u00aecial\u00ba environments,\nbutthecomplexityoftherelationship amongthebehavioroftheagent,theperceptsequence\ngenerated bytheenvironment, andthegoalsthattheagentissupposed toachieve.Some\u00aareal\u00ba\nenvironments areactuallyquitesimple.Forexample,arobotdesigned toinspectpartsasthey\ncomebyonaconveyerbeltcanmakeuseofanumberofsimplifying assumptions: thatthe\nlightingisalwaysjustso,thattheonlythingontheconveyerbeltwillbepartsofacertainkind,\nandthatthereareonlytwoactions\u00d0accept thepartormarkitasareject.\nIncontrast,somesoftwareagents(orsoftwarerobotsorsoftbots)existinrich,unlimited SOFTWAREAGENTS\nSOFTBOTS domains. Imagineasoftbotdesigned to\u00afya\u00afightsimulator fora747.Thesimulator isa\nverydetailed,complexenvironment, andthesoftwareagentmustchoosefromawidevarietyof\nactionsinrealtime.Orimagineasoftbotdesigned toscanonlinenewssourcesandshowthe\ninteresting itemstoitscustomers. Todowell,itwillneedsomenaturallanguage processing\nabilities,itwillneedtolearnwhateachcustomer isinterested in,anditwillneedtodynamically\nchangeitsplanswhen,forexample,theconnection foronenewssourcecrashesoranewone\ncomesonline.\nSomeenvironments blurthedistinction between\u00aareal\u00baand\u00aaarti\u00aecial. \u00baIntheALIVE\nenvironment (Maesetal.,1994),softwareagentsaregivenasperceptsadigitizedcameraimage\nofaroomwhereahumanwalksabout.Theagentprocesses thecameraimageandchoosesan\naction.Theenvironment alsodisplaysthecameraimageonalargedisplayscreenthatthehuman\ncanwatch,andsuperimposes ontheimageacomputer graphicsrendering ofthesoftwareagent.\nOnesuchimageisacartoondog,whichhasbeenprogrammed tomovetowardthehuman(unless\nhepointstosendthedogaway)andtoshakehandsorjumpupeagerlywhenthehumanmakes\ncertaingestures.\n5Fortheacronymically minded,wecallthisthePAGE(Percepts, Actions,Goals,Environment) description. Notethat\nthegoalsdonotnecessarily havetoberepresented withintheagent;theysimplydescribetheperformance measureby\nwhichtheagentdesignwillbejudged.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3290, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1519e695-a2d5-4303-a1ee-1b54f85bca95": {"__data__": {"id_": "1519e695-a2d5-4303-a1ee-1b54f85bca95", "embedding": null, "metadata": {"page_label": "7", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7cf52c57-9fec-41ac-a9b3-b72dac5529e6", "node_type": "4", "metadata": {"page_label": "7", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "4f7d7e5d83994bcb066f67cdd73ad6a166098e46b5f927b63f0191d492bdd7bf", "class_name": "RelatedNodeInfo"}}, "text": "Section2.3.Structure ofIntelligent Agents 37\nAgentType Percepts Actions Goals Environment\nMedicaldiagnosis\nsystemSymptoms,\n\u00aendings,patient's\nanswersQuestions, tests,\ntreatmentsHealthypatient,\nminimize costsPatient,hospital\nSatelliteimage\nanalysissystemPixelsofvarying\nintensity,colorPrinta\ncategorization of\nsceneCorrect\ncategorizationImagesfrom\norbitingsatellite\nPart-picking robot Pixelsofvarying\nintensityPickuppartsand\nsortintobinsPlacepartsin\ncorrectbinsConveyorbelt\nwithparts\nRe\u00aenerycontroller Temperature,\npressurereadingsOpen,close\nvalves;adjust\ntemperatureMaximize purity,\nyield,safetyRe\u00aenery\nInteractiveEnglish\ntutorTypedwords Printexercises,\nsuggestions,\ncorrectionsMaximize\nstudent'sscoreon\ntestSetofstudents\nFigure2.3Examples ofagenttypesandtheirPAGEdescriptions.\nThemostfamousarti\u00aecialenvironment istheTuringTestenvironment, inwhichthewhole\npointisthatrealandarti\u00aecialagentsareonequalfooting,buttheenvironment ischallenging\nenoughthatitisverydif\u00aecultforasoftwareagenttodoaswellasahuman.Section2.4describes\ninmoredetailthefactorsthatmakesomeenvironments moredemanding thanothers.\nAgentprograms\nWewillbebuildingintelligent agentsthroughout thebook.Theywillallhavethesameskeleton,\nnamely,accepting perceptsfromanenvironment andgenerating actions.Theearlyversionsof\nagentprograms willhaveaverysimpleform(Figure2.4).Eachwillusesomeinternaldata\nstructures thatwillbeupdatedasnewperceptsarrive.Thesedatastructures areoperatedonby\ntheagent'sdecision-making procedures togenerateanactionchoice,whichisthenpassedtothe\narchitecture tobeexecuted.\nTherearetwothingstonoteaboutthisskeletonprogram. First,eventhoughwede\u00aened\ntheagentmapping asafunctionfromperceptsequences toactions,theagentprogramreceives\nonlyasingleperceptasitsinput.Itisuptotheagenttobuilduptheperceptsequence inmemory,\nifitsodesires. Insomeenvironments, itispossibletobequitesuccessful withoutstoring\ntheperceptsequence, andincomplexdomains, itisinfeasible tostorethecomplete sequence.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2049, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4b0e7fc0-dbe4-459a-8455-af398e48babf": {"__data__": {"id_": "4b0e7fc0-dbe4-459a-8455-af398e48babf", "embedding": null, "metadata": {"page_label": "8", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d6650d8e-5e58-42c2-a326-ff2918e668cf", "node_type": "4", "metadata": {"page_label": "8", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "8b2c29d6e36225933e8a51db9911b0f9c5f8bab3533101d010bc5cef4ce6c70b", "class_name": "RelatedNodeInfo"}}, "text": "38 Chapter 2.Intelligent Agents\nfunction SKELETON-AGENT(percept)returnsaction\nstatic:memory,theagent'smemoryoftheworld\nmemory\n UPDATE-MEMORY(memory,percept)\naction\n CHOOSE-BEST-ACTION(memory)\nmemory\n UPDATE-MEMORY(memory,action)\nreturnaction\nFigure2.4Askeletonagent.Oneachinvocation,theagent'smemoryisupdatedtore\u00afect\nthenewpercept,thebestactionischosen,andthefactthattheactionwastakenisalsostoredin\nmemory.Thememorypersistsfromoneinvocationtothenext.\nSecond,thegoalorperformance measureisnotpartoftheskeletonprogram. Thisisbecause\ntheperformance measureisappliedexternally tojudgethebehavioroftheagent,anditisoften\npossibletoachievehighperformance withoutexplicitknowledgeoftheperformance measure\n(see,e.g.,thesquare-root agent).\nWhynotjustlookuptheanswers?\nLetusstartwiththesimplestpossiblewaywecanthinkoftowritetheagentprogram\u00d0a lookup\ntable.Figure2.5showstheagentprogram. Itoperatesbykeepinginmemoryitsentirepercept\nsequence, andusingittoindexintotable,whichcontainstheappropriate actionforallpossible\nperceptsequences.\nItisinstructivetoconsiderwhythisproposalisdoomedtofailure:\n1.Thetableneededforsomething assimpleasanagentthatcanonlyplaychesswouldbe\nabout35100entries.\n2.Itwouldtakequitealongtimeforthedesignertobuildthetable.\n3.Theagenthasnoautonomy atall,becausethecalculation ofbestactionsisentirelybuilt-in.\nSoiftheenvironment changedinsomeunexpectedway,theagentwouldbelost.\nfunction TABLE-DRIVEN-AGENT(percept)returnsaction\nstatic:percepts,asequence, initiallyempty\ntable,atable,indexedbyperceptsequences, initiallyfullyspeci\u00aeed\nappendpercepttotheendofpercepts\naction\n LOOKUP(percepts,table)\nreturnaction\nFigure2.5Anagentbasedonaprespeci\u00aeed lookuptable.Itkeepstrackofthepercept\nsequence andjustlooksupthebestaction.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1821, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cce22b88-2af7-4b61-8f17-473d792612a9": {"__data__": {"id_": "cce22b88-2af7-4b61-8f17-473d792612a9", "embedding": null, "metadata": {"page_label": "9", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cd98c782-c829-46ac-a280-c64b09157e70", "node_type": "4", "metadata": {"page_label": "9", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "ea02e6a6600e2790f5c69159bb73f0e54a7a881978ba76a00cca2211619c30e8", "class_name": "RelatedNodeInfo"}}, "text": "Section2.3.Structure ofIntelligent Agents 39\n4.Evenifwegavetheagentalearningmechanism aswell,sothatitcouldhaveadegreeof\nautonomy, itwouldtakeforevertolearntherightvalueforallthetableentries.\nDespiteallthis,TABLE-DRIVEN-AGENTdoesdowhatwewant:itimplements thedesiredagent\nmapping. Itisnotenoughtosay,\u00aaItcan'tbeintelligent; \u00bathepointistounderstand whyanagent\nthatreasons(asopposedtolookingthingsupinatable)candoevenbetterbyavoidingthefour\ndrawbackslistedhere.\nAnexample\nAtthispoint,itwillbehelpfultoconsider aparticular environment, sothatourdiscussion\ncanbecomemoreconcrete. Mainlybecauseofitsfamiliarity ,andbecauseitinvolvesabroad\nrangeofskills,wewilllookatthejobofdesigning anautomated taxidriver.Weshouldpoint\nout,beforethereaderbecomes alarmed, thatsuchasystemiscurrently somewhatbeyondthe\ncapabilities ofexistingtechnology ,althoughmostofthecomponents areavailableinsomeform.6\nThefulldrivingtaskisextremely open-ended \u00d0thereisnolimittothenovelcombinations of\ncircumstances thatcanarise(whichisanotherreasonwhywechoseitasafocusfordiscussion).\nWemust\u00aerstthinkaboutthepercepts, actions,goalsandenvironment forthetaxi.They\naresummarized inFigure2.6anddiscussed inturn.\nAgentType Percepts Actions Goals Environment\nTaxidriver Cameras,\nspeedometer ,GPS,\nsonar,microphoneSteer,accelerate,\nbrake,talkto\npassengerSafe,fast,legal,\ncomfortable trip,\nmaximize pro\u00aetsRoads,other\ntraf\u00aec,pedestrians,\ncustomers\nFigure2.6Thetaxidriveragenttype.\nThetaxiwillneedtoknowwhereitis,whatelseisontheroad,andhowfastitisgoing.\nThisinformation canbeobtainedfromtheperceptsprovidedbyoneormorecontrollable TV\ncameras,thespeedometer ,andodometer.Tocontrolthevehicleproperly,especially oncurves,it\nshouldhaveanaccelerometer; itwillalsoneedtoknowthemechanical stateofthevehicle,soit\nwillneedtheusualarrayofengineandelectrical systemsensors.Itmighthaveinstruments that\narenotavailabletotheaveragehumandriver:asatelliteglobalpositioning system(GPS)togive\nitaccuratepositioninformation withrespecttoanelectronic map;orinfraredorsonarsensorsto\ndetectdistances toothercarsandobstacles. Finally,itwillneedamicrophone orkeyboardfor\nthepassengers totellittheirdestination.\nTheactionsavailabletoataxidriverwillbemoreorlessthesameonesavailabletoahuman\ndriver:controlovertheenginethroughthegaspedalandcontroloversteeringandbraking. In\naddition, itwillneedoutputtoascreenorvoicesynthesizer totalkbacktothepassengers, and\nperhapssomewaytocommunicate withothervehicles.\n6Seepage26foradescription ofanexistingdrivingrobot,orlookattheconference proceedings onIntelligent Vehicle\nandHighway Systems(IVHS).\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2655, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "67b0d70d-40f8-4d09-ad7c-af1225335918": {"__data__": {"id_": "67b0d70d-40f8-4d09-ad7c-af1225335918", "embedding": null, "metadata": {"page_label": "10", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "adbc09b4-b1f0-42e4-8d80-0b27ea6e6554", "node_type": "4", "metadata": {"page_label": "10", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "26279fa929e6976cae326faf000a095de1edc0328c0a3e1959d49da2380c7dc9", "class_name": "RelatedNodeInfo"}}, "text": "40 Chapter 2.Intelligent Agents\nWhatperformance measurewouldwelikeourautomated drivertoaspireto?Desirable\nqualitiesincludegettingtothecorrectdestination; minimizing fuelconsumption andwearand\ntear;minimizing thetriptimeand/orcost;minimizing violations oftraf\u00aeclawsanddisturbances\ntootherdrivers;maximizing safetyandpassenger comfort;maximizing pro\u00aets.Obviously,some\nofthesegoalscon\u00afict,sotherewillbetrade-offsinvolved.\nFinally,werethisarealproject,wewouldneedtodecidewhatkindofdrivingenvironment\nthetaxiwillface.Shoulditoperateonlocalroads,oralsoonfreeways?WillitbeinSouthern\nCalifornia, wheresnowisseldomaproblem, orinAlaska,whereitseldomisnot?Willitalways\nbedrivingontheright,ormightwewantittobe\u00afexibleenoughtodriveontheleftincasewe\nwanttooperatetaxisinBritainorJapan?Obviously,themorerestricted theenvironment, the\neasierthedesignproblem.\nNowwehavetodecidehowtobuildarealprogram toimplement themapping from\nperceptstoaction.Wewill\u00aendthatdifferentaspectsofdrivingsuggestdifferenttypesofagent\nprogram. Wewillconsiderfourtypesofagentprogram:\nSimplere\u00afexagents\nAgentsthatkeeptrackoftheworld\nGoal-based agents\nUtility-based agents\nSimplere\u00afexagents\nTheoptionofconstructing anexplicitlookuptableisoutofthequestion. Thevisualinputfrom\nasinglecameracomesinattherateof50megabytespersecond(25framespersecond,1000\n1000pixelswith8bitsofcolorand8bitsofintensityinformation). Sothelookuptableforan\nhourwouldbe260\n60\n50Mentries.\nHowever,wecansummarize portionsofthetablebynotingcertaincommonly occurring\ninput/outputassociations. Forexample,ifthecarinfrontbrakes,anditsbrakelightscomeon,\nthenthedrivershouldnoticethisandinitiatebraking.Inotherwords,someprocessing isdoneon\nthevisualinputtoestablishthecondition wecall\u00aaThecarinfrontisbraking\u00ba; thenthistriggers\nsomeestablished connection intheagentprogramtotheaction\u00aainitiatebraking\u00ba. Wecallsuch\naconnection acondition\u00b1action rule7writtenasCONDITION\u00b1A CTION\nRULE\nifcar-in-front-is-brakingtheninitiate-br aking\nHumansalsohavemanysuchconnections, someofwhicharelearnedresponses (asfordriving)\nandsomeofwhichareinnatere\u00afexes(suchasblinkingwhensomething approaches theeye).\nInthecourseofthebook,wewillseeseveraldifferentwaysinwhichsuchconnections canbe\nlearnedandimplemented.\nFigure2.7givesthestructure ofasimplere\u00afexagentinschematic form,showinghow\nthecondition\u00b1action rulesallowtheagenttomaketheconnection frompercepttoaction.(Do\nnotworryifthisseemstrivial;itgetsmoreinteresting shortly.)Weuserectangles todenote\n7Alsocalledsituation\u00b1action rules,productions ,orif\u00b1thenrules.Thelasttermisalsousedbysomeauthorsfor\nlogicalimplications, sowewillavoiditaltogether .\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2691, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7d6699c8-0462-403b-b699-d22375c15454": {"__data__": {"id_": "7d6699c8-0462-403b-b699-d22375c15454", "embedding": null, "metadata": {"page_label": "11", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d9d9245e-a063-4851-9bc5-dfcda9d16772", "node_type": "4", "metadata": {"page_label": "11", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "5ebbac9b1ea1905475fb2adcf3a694d4359306a63f33d0c9ef3f1440042a216a", "class_name": "RelatedNodeInfo"}}, "text": "Section2.3.Structure ofIntelligent Agents 41\nAgent\nEnvironment\nSensors\nEffectorsWhat the world\nis like now\nWhat action I\nshould do now\nFigure2.7Schematic diagramofasimplere\u00afexagent.\nfunction SIMPLE-REFLEX-AGENT(percept)returnsaction\nstatic:rules,asetofcondition-action rules\nstate\nINTERPRET -INPUT(percept)\nrule\nRULE-MATCH(state,rules)\naction\n RULE-ACTION[rule]\nreturnaction\nFigure2.8Asimplere\u00afexagent.Itworksby\u00aendingarulewhosecondition matchesthe\ncurrentsituation(asde\u00aenedbythepercept)andthendoingtheactionassociated withthatrule.\nthecurrentinternalstateoftheagent'sdecisionprocess,andovalstorepresent thebackground\ninformation usedintheprocess. Theagentprogram, whichisalsoverysimple,isshownin\nFigure2.8.TheINTERPRET -INPUTfunctiongenerates anabstracted description ofthecurrent\nstatefromthepercept,andtheRULE-MATCHfunctionreturnsthe\u00aerstruleinthesetofrulesthat\nmatchesthegivenstatedescription. Although suchagentscanbeimplemented veryef\u00aeciently\n(seeChapter10),theirrangeofapplicability isverynarrow,asweshallsee.\nAgentsthatkeeptrackoftheworld\nThesimplere\u00afexagentdescribed beforewillworkonlyifthecorrectdecisioncanbemade\nonthebasisofthecurrentpercept. Ifthecarinfrontisarecentmodel,andhasthecentrally\nmounted brakelightnowrequiredintheUnitedStates,thenitwillbepossibletotellifitis\nbrakingfromasingleimage.Unfortunately ,oldermodelshavedifferentcon\u00aegurations oftail\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1460, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "530042e6-5533-4b18-803e-ebcfc661ac5e": {"__data__": {"id_": "530042e6-5533-4b18-803e-ebcfc661ac5e", "embedding": null, "metadata": {"page_label": "12", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66174a56-09d6-4bbc-9668-24ecf27a5b35", "node_type": "4", "metadata": {"page_label": "12", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "cf4bcbcbbb1fac98ea410dd2b677a0baf6bc386a78ee6a96193a335ec16a30bf", "class_name": "RelatedNodeInfo"}}, "text": "42 Chapter 2.Intelligent Agents\nlights,brakelights,andturn-signal lights,anditisnotalwayspossibletotellifthecarisbraking.\nThus,evenforthesimplebrakingrule,ourdriverwillhavetomaintain somesortofinternal\nstateinordertochooseanaction.Here,theinternalstateisnottooextensive\u00d0itjustneedsthe INTERNAL STATE\npreviousframefromthecameratodetectwhentworedlightsattheedgeofthevehiclegoonor\noffsimultaneously .\nConsider thefollowingmoreobviouscase:fromtimetotime,thedriverlooksinthe\nrear-viewmirrortocheckonthelocations ofnearbyvehicles.Whenthedriverisnotlookingin\nthemirror,thevehiclesinthenextlaneareinvisible(i.e.,thestatesinwhichtheyarepresentand\nabsentareindistinguishabl e);butinordertodecideonalane-change maneuver,thedriverneeds\ntoknowwhetherornottheyarethere.\nTheproblemillustrated bythisexamplearisesbecausethesensorsdonotprovideaccessto\nthecomplete stateoftheworld.Insuchcases,theagentmayneedtomaintainsomeinternalstate\ninformation inordertodistinguish betweenworldstatesthatgeneratethesameperceptual input\nbutnonetheless aresigni\u00aecantly different.Here,\u00aasigni\u00aecantly different\u00bameansthatdifferent\nactionsareappropriate inthetwostates.\nUpdating thisinternalstateinformation astimegoesbyrequirestwokindsofknowledgeto\nbeencodedintheagentprogram. First,weneedsomeinformation abouthowtheworldevolves\nindependently oftheagent\u00d0for example,thatanovertakingcargenerally willbecloserbehind\nthanitwasamomentago.Second,weneedsomeinformation abouthowtheagent'sownactions\naffecttheworld\u00d0for example,thatwhentheagentchangeslanestotheright,thereisagap(at\nleasttemporarily) inthelaneitwasinbefore,orthatafterdrivingfor\u00aeveminutesnorthbound\nonthefreewayoneisusuallyabout\u00aevemilesnorthofwhereonewas\u00aeveminutesago.\nFigure2.9givesthestructure ofthere\u00afexagent,showinghowthecurrentperceptis\ncombined withtheoldinternalstatetogeneratetheupdateddescription ofthecurrentstate.The\nagentprogramisshowninFigure2.10.Theinteresting partisthefunctionUPDATE-STATE,which\nisresponsible forcreatingthenewinternalstatedescription. Aswellasinterpreting thenew\nperceptinthelightofexistingknowledgeaboutthestate,itusesinformation abouthowtheworld\nevolvestokeeptrackoftheunseenpartsoftheworld,andalsomustknowaboutwhattheagent's\nactionsdotothestateoftheworld.DetailedexamplesappearinChapters 7and17.\nGoal-based agents\nKnowingaboutthecurrentstateoftheenvironment isnotalwaysenoughtodecidewhattodo.\nForexample,ataroadjunction, thetaxicanturnleft,right,orgostraighton.Therightdecision\ndependsonwherethetaxiistryingtogetto.Inotherwords,aswellasacurrentstatedescription,\ntheagentneedssomesortofgoalinformation, whichdescribes situations thataredesirable\u00d0 GOAL\nforexample,beingatthepassenger' sdestination. Theagentprogramcancombine thiswith\ninformation abouttheresultsofpossibleactions(thesameinformation aswasusedtoupdate\ninternalstateinthere\u00afexagent)inordertochooseactionsthatachievethegoal.Sometimes\nthiswillbesimple,whengoalsatisfaction resultsimmediately fromasingleaction;sometimes,\nitwillbemoretricky,whentheagenthastoconsiderlongsequences oftwistsandturnsto\u00aend\nawaytoachievethegoal.Search(Chapters 3to5)andplanning (Chapters 11to13)arethe SEARCH\nPLANNING sub\u00aeelds ofAIdevotedto\u00aendingactionsequences thatdoachievetheagent'sgoals.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3278, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e014c2c5-b445-409c-9ce2-89de09007ea6": {"__data__": {"id_": "e014c2c5-b445-409c-9ce2-89de09007ea6", "embedding": null, "metadata": {"page_label": "13", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e26e0394-58f9-4610-bbe3-59562f2e907e", "node_type": "4", "metadata": {"page_label": "13", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "a0b204749881938fab53e00ce0307a5490e92c576d3b5c87f020e4e27b64ebca", "class_name": "RelatedNodeInfo"}}, "text": "Section2.3.Structure ofIntelligent Agents 43\nAgentEnvironment\nSensors\nEffectorsWhat the world\nis like now\nWhat action I\nshould do nowState\nHow the world evolves\nWhat my actions do\nFigure2.9Are\u00afexagentwithinternalstate.\nfunction REFLEX-AGENT-WITH-STATE(percept)returnsaction\nstatic:state,adescription ofthecurrentworldstate\nrules,asetofcondition-action rules\nstate\nUPDATE-STATE(state,percept)\nrule\nRULE-MATCH(state,rules)\naction\n RULE-ACTION[rule]\nstate\nUPDATE-STATE(state,action)\nreturnaction\nFigure2.10Are\u00afexagentwithinternalstate.Itworksby\u00aendingarulewhosecondition\nmatchesthecurrentsituation (asde\u00aenedbytheperceptandthestoredinternalstate)andthen\ndoingtheactionassociated withthatrule.\nNoticethatdecision\u00b1making ofthiskindisfundamentally differentfromthecondition\u00b1\nactionrulesdescribed earlier,inthatitinvolvesconsideration ofthefuture\u00d0both \u00aaWhatwill\nhappenifIdosuch-and-such?\u00ba and\u00aaWillthatmakemehappy?\u00ba Inthere\u00afexagentdesigns,\nthisinformation isnotexplicitlyused,becausethedesignerhasprecomputed thecorrectaction\nforvariouscases.There\u00afexagentbrakeswhenitseesbrakelights.Agoal-based agent,in\nprinciple, couldreasonthatifthecarinfronthasitsbrakelightson,itwillslowdown.From\nthewaytheworldusuallyevolves,theonlyactionthatwillachievethegoalofnothittingother\ncarsistobrake.Although thegoal-based agentappearslessef\u00aecient,itisfarmore\u00afexible.Ifit\nstartstorain,theagentcanupdateitsknowledgeofhoweffectivelyitsbrakeswilloperate;this\nwillautomatically causealloftherelevantbehaviorstobealteredtosuitthenewconditions. For\nthere\u00afexagent,ontheotherhand,wewouldhavetorewritealargenumberofcondition\u00b1action\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1688, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fd79c5f1-57e1-4d2f-9021-5c4ca6d1f4b0": {"__data__": {"id_": "fd79c5f1-57e1-4d2f-9021-5c4ca6d1f4b0", "embedding": null, "metadata": {"page_label": "14", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d277a37b-cfb5-4ba3-90c3-acb2518d9d61", "node_type": "4", "metadata": {"page_label": "14", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "82a39de91934eedd6c71e1c3cfac3811c4519c162dc43c6a49e8f46c917928bb", "class_name": "RelatedNodeInfo"}}, "text": "44 Chapter 2.Intelligent Agents\nrules.Ofcourse,thegoal-based agentisalsomore\u00afexiblewithrespecttoreaching different\ndestinations. Simplybyspecifying anewdestination, wecangetthegoal-based agenttocome\nupwithanewbehavior.There\u00afexagent'srulesforwhentoturnandwhentogostraightwill\nonlyworkforasingledestination; theymustallbereplacedtogosomewherenew.\nFigure2.11showsthegoal-based agent'sstructure. Chapter13containsdetailedagent\nprograms forgoal-based agents.\nAgentEnvironment\nSensors\nEffectorsWhat it will be like\n  if I do action AWhat the world\nis like now\nWhat action I\nshould do nowState\nHow the world evolves\nWhat my actions do\nGoals\nFigure2.11Anagentwithexplicitgoals.\nUtility-based agents\nGoalsalonearenotreallyenoughtogeneratehigh-quality behavior.Forexample,therearemany\nactionsequences thatwillgetthetaxitoitsdestination, therebyachievingthegoal,butsome\narequicker,safer,morereliable,orcheaperthanothers.Goalsjustprovideacrudedistinction\nbetween\u00aahappy\u00baand\u00aaunhappy\u00ba states,whereasamoregeneralperformance measureshould\nallowacomparison ofdifferentworldstates(orsequences ofstates)according toexactlyhow\nhappytheywouldmaketheagentiftheycouldbeachieved.Because\u00aahappy\u00badoesnotsound\nveryscienti\u00aec, thecustomary terminology istosaythatifoneworldstateispreferred toanother,\nthenithashigherutilityfortheagent.8UTILITY\nUtilityistherefore afunctionthatmapsastate9ontoarealnumber,whichdescribes the\nassociated degreeofhappiness. Acomplete speci\u00aecation oftheutilityfunctionallowsrational\ndecisions intwokindsofcaseswheregoalshavetrouble.First,whentherearecon\u00aficting goals,\nonlysomeofwhichcanbeachieved(forexample,speedandsafety),theutilityfunctionspeci\u00aees\ntheappropriate trade-off.Second,whenthereareseveralgoalsthattheagentcanaimfor,none\n8Theword\u00aautility\u00bahererefersto\u00aathequalityofbeinguseful,\u00banottotheelectriccompany orwaterworks.\n9Orsequence ofstates,ifwearemeasuring theutilityofanagentoverthelongrun.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1990, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "62050fa0-7614-4fc2-bab3-0495e8debafe": {"__data__": {"id_": "62050fa0-7614-4fc2-bab3-0495e8debafe", "embedding": null, "metadata": {"page_label": "15", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aa0c5184-7568-40af-9ee6-45dc83180ac4", "node_type": "4", "metadata": {"page_label": "15", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "2285b68919d5f1c0f29e65b1fac8b4fe69162bf8896dceae5a23f1c7174b8096", "class_name": "RelatedNodeInfo"}}, "text": "Section2.4.Environments 45\nofwhichcanbeachievedwithcertainty,utilityprovidesawayinwhichthelikelihood ofsuccess\ncanbeweighedupagainsttheimportance ofthegoals.\nInChapter16,weshowthatanyrationalagentcanbedescribed aspossessing autility\nfunction. Anagentthatpossesses anexplicitutilityfunctionthereforecanmakerationaldecisions,\nbutmayhavetocomparetheutilitiesachievedbydifferentcoursesofactions.Goals,although\ncruder,enabletheagenttopickanactionrightawayifitsatis\u00aeesthegoal.Insomecases,\nmoreover,autilityfunctioncanbetranslated intoasetofgoals,suchthatthedecisions madeby\nagoal-based agentusingthosegoalsareidenticaltothosemadebytheutility-basedagent.\nTheoverallutility-based agentstructureappearsinFigure2.12.Actualutility-basedagent\nprograms appearinChapter5,whereweexaminegame-playing programs thatmustmake\u00aene\ndistinctions amongvariousboardpositions; andinChapter17,wherewetacklethegeneral\nproblemofdesigning decision-making agents.\nAgentEnvironment\nSensors\nEffectorsWhat it will be like\n  if I do action AWhat the world\nis like now\nHow happy I will be\n   in such a state\nWhat action I\nshould do nowState\nHow the world evolves\nWhat my actions do\nUtility\nFigure2.12Acomplete utility-based agent.\n2.4ENVIRONMENTS\nInthissectionandintheexercisesattheendofthechapter,youwillseehowtocoupleanagent\ntoanenvironment. Section2.3introduced severaldifferentkindsofagentsandenvironments.\nInallcases,however,thenatureoftheconnection betweenthemisthesame:actionsaredone\nbytheagentontheenvironment, whichinturnprovidesperceptstotheagent.First,wewill\ndescribethedifferenttypesofenvironments andhowtheyaffectthedesignofagents.Thenwe\nwilldescribeenvironment programs thatcanbeusedastestbedsforagentprograms.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1782, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "51be24d0-344b-4780-b040-07b86e38944d": {"__data__": {"id_": "51be24d0-344b-4780-b040-07b86e38944d", "embedding": null, "metadata": {"page_label": "16", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1fe55689-be5f-4c9a-9e6d-f5a05376119a", "node_type": "4", "metadata": {"page_label": "16", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "2bcf60ccb528c59e0d064a8524ecc1bd9317c1e481ab039ed9dc601f0b2e320d", "class_name": "RelatedNodeInfo"}}, "text": "46 Chapter 2.Intelligent Agents\nPropertiesofenvironments\nEnvironments comeinseveral\u00afavors.Theprincipal distinctions tobemadeareasfollows:\nAccessible vs.inaccessible . ACCESSIBLE\nIfanagent'ssensoryapparatus givesitaccesstothecomplete stateoftheenvironment,\nthenwesaythattheenvironment isaccessible tothatagent.Anenvironment iseffectively\naccessible ifthesensorsdetectallaspectsthatarerelevanttothechoiceofaction.An\naccessible environment isconvenientbecausetheagentneednotmaintainanyinternalstate\ntokeeptrackoftheworld.\nDeterministic vs.nondeterministic . DETERMINISTIC\nIfthenextstateoftheenvironment iscompletely determined bythecurrentstateandthe\nactionsselectedbytheagents,thenwesaytheenvironment isdeterministic. Inprinciple,\nanagentneednotworryaboutuncertainty inanaccessible, deterministic environment. If\ntheenvironment isinaccessible, however,thenitmayappeartobenondeterministic. This\nisparticularly trueiftheenvironment iscomplex,makingithardtokeeptrackofallthe\ninaccessible aspects.Thus,itisoftenbettertothinkofanenvironment asdeterministic or\nnondeterministic fromthepointofviewoftheagent.\nEpisodic vs.nonepisodic . EPISODIC\nInanepisodicenvironment, theagent'sexperience isdividedinto\u00aaepisodes. \u00baEachepisode\nconsistsoftheagentperceivingandthenacting.Thequalityofitsactiondependsjuston\ntheepisodeitself,becausesubsequent episodes donotdependonwhatactionsoccurin\npreviousepisodes. Episodic environments aremuchsimplerbecausetheagentdoesnot\nneedtothinkahead.\nStaticvs.dynamic. STATIC\nIftheenvironment canchangewhileanagentisdeliberating, thenwesaytheenvironment\nisdynamicforthatagent;otherwise itisstatic.Staticenvironments areeasytodealwith\nbecausetheagentneednotkeeplookingattheworldwhileitisdeciding onanaction,\nnorneeditworryaboutthepassageoftime.Iftheenvironment doesnotchangewiththe\npassageoftimebuttheagent'sperformance scoredoes,thenwesaytheenvironment is\nsemidynamic . SEMIDYNAMIC\nDiscretevs.continuous . DISCRETE\nIftherearealimitednumberofdistinct,clearlyde\u00aenedperceptsandactionswesaythat\ntheenvironment isdiscrete.Chessisdiscrete\u00d0there area\u00aexednumberofpossiblemoves\noneachturn.Taxidrivingiscontinuous\u00d0the speedandlocationofthetaxiandtheother\nvehiclessweepthrougharangeofcontinuous values.10\nWewillseethatdifferentenvironment typesrequiresomewhatdifferentagentprograms todeal\nwiththemeffectively.Itwillturnout,asyoumightexpect,thatthehardestcaseisinaccessible ,\nnonepisodic ,dynamic,andcontinuous .Italsoturnsoutthatmostrealsituations aresocomplex\nthatwhethertheyarereallydeterministic isamootpoint;forpracticalpurposes, theymustbe\ntreatedasnondeterministic.\n10Ata\u00aeneenoughlevelofgranularity ,eventhetaxidrivingenvironment isdiscrete,becausethecameraimageis\ndigitizedtoyielddiscretepixelvalues.Butanysensibleagentprogramwouldhavetoabstractabovethislevel,uptoa\nlevelofgranularity thatiscontinuous.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2908, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2ea49615-0a27-4115-8948-70cd6ff1f821": {"__data__": {"id_": "2ea49615-0a27-4115-8948-70cd6ff1f821", "embedding": null, "metadata": {"page_label": "17", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0bd4140-19fe-4feb-a329-26d4cad626b9", "node_type": "4", "metadata": {"page_label": "17", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "52c0174106a6c6035903c2a75c49f622c0155bcfb5016025919a4ab50ec9a61c", "class_name": "RelatedNodeInfo"}}, "text": "Section2.4.Environments 47\nFigure2.13liststheproperties ofanumberoffamiliarenvironments. Notethattheanswers\ncanchangedepending onhowyouconceptualize theenvironments andagents.Forexample,\npokerisdeterministic iftheagentcankeeptrackoftheorderofcardsinthedeck,butitis\nnondeterministic ifitcannot.Also,manyenvironments areepisodicathigherlevelsthanthe\nagent'sindividualactions.Forexample,achesstournament consistsofasequence ofgames;\neachgameisanepisode,because(byandlarge)thecontributionofthemovesinonegametothe\nagent'soverallperformance isnotaffectedbythemovesinitsnextgame.Ontheotherhand,\nmoveswithinasinglegamecertainlyinteract,sotheagentneedstolookaheadseveralmoves.\nEnvironment Accessible Deterministic Episodic StaticDiscrete\nChesswithaclock Yes Yes No Semi Yes\nChesswithoutaclock Yes Yes No YesYes\nPoker No No No YesYes\nBackgammon Yes No No YesYes\nTaxidriving No No No No No\nMedicaldiagnosis system No No No No No\nImage-analysis system Yes Yes YesSemi No\nPart-picking robot No No Yes No No\nRe\u00aenerycontroller No No No No No\nInteractiveEnglishtutor No No No No Yes\nFigure2.13Examples ofenvironments andtheircharacteristics.\nEnvironmentprograms\nThegenericenvironment programinFigure2.14illustrates thebasicrelationship betweenagents\nandenvironments. Inthisbook,wewill\u00aenditconvenientformanyoftheexamplesandexercises\ntouseanenvironment simulator thatfollowsthisprogramstructure. Thesimulator takesoneor\nmoreagentsasinputandarrangestorepeatedly giveeachagenttherightperceptsandreceiveback\nanaction.Thesimulator thenupdatestheenvironment basedontheactions,andpossiblyother\ndynamicprocesses intheenvironment thatarenotconsidered tobeagents(rain,forexample).\nTheenvironment istherefore de\u00aenedbytheinitialstateandtheupdatefunction. Ofcourse,an\nagentthatworksinasimulator oughtalsotoworkinarealenvironment thatprovidesthesame\nkindsofperceptsandacceptsthesamekindsofactions.\nTheRUN-ENVIRONMENTprocedure correctly exercisestheagentsinanenvironment. For\nsomekindsofagents,suchasthosethatengageinnaturallanguage dialogue, itmaybesuf\u00aecient\nsimplytoobservetheirbehavior.Togetmoredetailedinformation aboutagentperformance, we\ninsertsomeperformance measurement code.ThefunctionRUN-EVAL-ENVIRONMENT,shownin\nFigure2.15,doesthis;itappliesaperformance measuretoeachagentandreturnsalistofthe\nresultingscores.Thescoresvariablekeepstrackofeachagent'sscore.\nIngeneral,theperformance measurecandependontheentiresequence ofenvironment\nstatesgenerated duringtheoperation oftheprogram. Usually,however,theperformance measure\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2592, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6dcef79c-a195-4be6-a641-6a284dd0f9d2": {"__data__": {"id_": "6dcef79c-a195-4be6-a641-6a284dd0f9d2", "embedding": null, "metadata": {"page_label": "18", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bea429f6-6da7-4d9f-8f3d-e396df0fcbe6", "node_type": "4", "metadata": {"page_label": "18", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "c9791e6d099d7d60285e8ec2e2041488930ae506f15a7bded2b2c4404534c873", "class_name": "RelatedNodeInfo"}}, "text": "48 Chapter 2.Intelligent Agents\nprocedureRUN-ENVIRONMENT(state,UPDATE-FN,agents,termination )\ninputs:state,theinitialstateoftheenvironment\nUPDATE-FN,functiontomodifytheenvironment\nagents,asetofagents\ntermination ,apredicate totestwhenwearedone\nrepeat\nforeachagentinagentsdo\nPERCEPT[agent]\nGET-PERCEPT(agent,state)\nend\nforeachagentinagentsdo\nACTION[agent]\nPROGRAM[agent](PERCEPT[agent])\nend\nstate\nUPDATE-FN(actions,agents,state)\nuntiltermination (state)\nFigure2.14Thebasicenvironment simulator program. Itgiveseachagentitspercept,getsan\nactionfromeachagent,andthenupdatestheenvironment.\nfunction RUN-EVAL-ENVIRONMENT(state,UPDATE-FN,agents,\ntermination, PERFORMANCE -FN)returnsscores\nlocalvariables :scores,avectorthesamesizeasagents,all0\nrepeat\nforeachagentinagentsdo\nPERCEPT[agent]\nGET-PERCEPT(agent,state)\nend\nforeachagentinagentsdo\nACTION[agent]\nPROGRAM[agent](PERCEPT[agent])\nend\nstate\nUPDATE-FN(actions,agents,state)\nscores\nPERFORMANCE -FN(scores,agents,state)\nuntiltermination (state)\nreturnscores /*change*/\nFigure2.15Anenvironment simulator programthatkeepstrackoftheperformance measure\nforeachagent.\nworksbyasimpleaccumulation usingeithersummation, averaging,ortakingamaximum. For\nexample,iftheperformance measureforavacuum-cleaning agentisthetotalamountofdirt\ncleanedinashift,scoreswilljustkeeptrackofhowmuchdirthasbeencleanedupsofar.\nRUN-EVAL-ENVIRONMENTreturnstheperformance measureforaasingleenvironment,\nde\u00aenedbyasingleinitialstateandaparticular updatefunction. Usually,anagentisdesigned to\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1599, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f1f1a985-33e9-4553-b3ad-81c4bde250f5": {"__data__": {"id_": "f1f1a985-33e9-4553-b3ad-81c4bde250f5", "embedding": null, "metadata": {"page_label": "19", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4664bd02-ec62-4a83-ac5b-505e8d3a4dab", "node_type": "4", "metadata": {"page_label": "19", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "911a1c63f4cfc25da1f093e7fd004378c1babaed880eb16880a46a8b77d34b3d", "class_name": "RelatedNodeInfo"}}, "text": "Section2.5.Summary 49\nworkinanenvironmentclass,awholesetofdifferentenvironments. Forexample,wedesignENVIRONMENT\nCLASS\nachessprogramtoplayagainstanyofawidecollection ofhumanandmachineopponents. If\nwedesigned itforasingleopponent, wemightbeabletotakeadvantageofspeci\u00aecweaknesses\ninthatopponent, butthatwouldnotgiveusagoodprogramforgeneralplay.Strictlyspeaking,\ninordertomeasuretheperformance ofanagent,weneedtohaveanenvironment generator\nthatselectsparticular environments (withcertainlikelihoods) inwhichtoruntheagent.Weare\ntheninterested intheagent'saverageperformance overtheenvironment class.Thisisfairly\nstraightforward toimplement forasimulated environment, andExercises2.5to2.11takeyou\nthroughtheentiredevelopment ofanenvironment andtheassociated measurement process.\nApossibleconfusion arisesbetweenthestatevariableintheenvironment simulator and\nthestatevariableintheagentitself(seeREFLEX-AGENT-WITH-STATE).Asaprogrammer imple-\nmentingboththeenvironment simulator andtheagent,itistempting toallowtheagenttopeek\nattheenvironment simulator' sstatevariable.Thistemptation mustberesistedatallcosts!The\nagent'sversionofthestatemustbeconstructed fromitsperceptsalone,withoutaccesstothe\ncomplete stateinformation.\n2.5SUMMAR Y\nThischapterhasbeensomething ofawhirlwind tourofAI,whichwehaveconceivedofasthe\nscienceofagentdesign.Themajorpointstorecallareasfollows:\nAnagentissomething thatperceivesandactsinanenvironment. Wesplitanagentinto\nanarchitecture andanagentprogram.\nAnidealagentisonethatalwaystakestheactionthatisexpectedtomaximize itsperfor-\nmancemeasure, giventheperceptsequence ithasseensofar.\nAnagentisautonomous totheextentthatitsactionchoicesdependonitsownexperience,\nratherthanonknowledgeoftheenvironment thathasbeenbuilt-inbythedesigner.\nAnagentprogrammapsfromapercepttoanaction,whileupdatinganinternalstate.\nThereexistsavarietyofbasicagentprogramdesigns,depending onthekindofinformation\nmadeexplicitandusedinthedecisionprocess.Thedesignsvaryinef\u00aeciency,compactness,\nand\u00afexibility.Theappropriate designoftheagentprogram dependsonthepercepts,\nactions,goals,andenvironment.\nRe\u00afexagentsrespondimmediately topercepts, goal-based agentsactsothattheywill\nachievetheirgoal(s),andutility-based agentstrytomaximize theirown\u00aahappiness. \u00ba\nTheprocessofmakingdecisions byreasoning withknowledgeiscentraltoAIandto\nsuccessful agentdesign.Thismeansthatrepresenting knowledgeisimportant.\nSomeenvironments aremoredemanding thanothers.Environments thatareinaccessible,\nnondeterministic, nonepisodic, dynamic, andcontinuous arethemostchallenging.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2632, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20b4de67-52e0-409f-9f9d-6ce0f3b1d5ff": {"__data__": {"id_": "20b4de67-52e0-409f-9f9d-6ce0f3b1d5ff", "embedding": null, "metadata": {"page_label": "20", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7b8e5d0-292a-49db-849e-983eb8354dbc", "node_type": "4", "metadata": {"page_label": "20", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "f1f9f1c9653e9ce238612a9d3da0eabefd4ec1e5ae16ce650915407d5ec00346", "class_name": "RelatedNodeInfo"}}, "text": "50 Chapter 2.Intelligent Agents\nBIBLIOGRAPHICAL ANDHISTORICALNOTES\nTheanalysisofrationalagencyasamappingfromperceptsequences toactionsprobably stems\nultimately fromtheefforttoidentifyrationalbehaviorintherealmofeconomics andotherforms\nofreasoning underuncertainty (coveredinlaterchapters) andfromtheeffortsofpsychological\nbehavioristssuchasSkinner(1953)toreducethepsychology oforganismsstrictlytoinput/output\norstimulus/response mappings. Theadvancefrombehaviorismtofunctionalism inpsychology ,\nwhichwasatleastpartlydrivenbytheapplication ofthecomputer metaphor toagents(Putnam,\n1960;Lewis,1966),introduced theinternalstateoftheagentintothepicture.Thephilosopher\nDanielDennett(1969;1978b)helpedtosynthesize theseviewpointsintoacoherent\u00aaintentional\nstance\u00batowardagents.Ahigh-level,abstractperspectiveonagencyisalsotakenwithintheworld\nofAIin(McCarthy andHayes,1969).JonDoyle(1983)proposed thatrationalagentdesignis\nthecoreofAI,andwouldremainasitsmissionwhileothertopicsinAIwouldspinofftoform\nnewdisciplines. Horvitzetal.(1988)speci\u00aecally suggesttheuseofrationality conceivedasthe\nmaximization ofexpectedutilityasabasisforAI.\nTheAIresearcher andNobel-prize-winning economist HerbSimondrewacleardistinction\nbetweenrationality underresourcelimitations (procedural rationality) andrationality asmaking\ntheobjectivelyrationalchoice(substanti verationality) (Simon,1958).Cherniak (1986)explores\ntheminimallevelofrationality neededtoqualifyanentityasanagent.RussellandWefald(1991)\ndealexplicitlywiththepossibility ofusingavarietyofagentarchitectures. DungBeetleEcol-\nogy(HanskiandCambefort, 1991)providesawealthofinteresting information onthebehavior\nofdungbeetles.\nEXERCISES\n2.1Whatisthedifferencebetweenaperformance measureandautilityfunction?\n2.2Foreachoftheenvironments inFigure2.3,determine whattypeofagentarchitecture is\nmostappropriate (tablelookup,simplere\u00afex,goal-based orutility-based).\n2.3Chooseadomainthatyouarefamiliarwith,andwriteaPAGEdescription ofanagent\nfortheenvironment. Characterize theenvironment asbeingaccessible, deterministic, episodic,\nstatic,andcontinuous ornot.Whatagentarchitecture isbestforthisdomain?\n2.4Whiledriving,whichisthebestpolicy?\na.Alwaysputyourdirectional blinkeronbeforeturning,\nb.Neveruseyourblinker,\nc.Lookinyourmirrorsanduseyourblinkeronlyifyouobserveacarthatcanobserveyou?\nWhatkindofreasoning didyouneedtodotoarriveatthispolicy(logical,goal-based, orutility-\nbased)?Whatkindofagentdesignisnecessary tocarryoutthepolicy(re\u00afex,goal-based, or\nutility-based)?\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2587, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b649889-e07a-46ed-bb02-a64accae7a00": {"__data__": {"id_": "0b649889-e07a-46ed-bb02-a64accae7a00", "embedding": null, "metadata": {"page_label": "21", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e32c141a-8ed3-4645-8cd2-a1bf91813a56", "node_type": "4", "metadata": {"page_label": "21", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "b20df348b10227a870b0214e5a569110e8fb16f4d1c71b54b1f20f5020a3770e", "class_name": "RelatedNodeInfo"}}, "text": "Section2.5.Summary 51\nThefollowingexercisesallconcerntheimplementation ofanenvironment andsetofagentsin\nthevacuum-cleaner world.\n2.5Implement aperformance-measuring environment simulator forthevacuum-cleaner world.\nThisworldcanbedescribed asfollows:\nPercepts:Eachvacuum-cleaner agentgetsathree-element perceptvectoroneachturn.\nThe\u00aerstelement,atouchsensor,shouldbea1ifthemachinehasbumpedintosomething\nanda0otherwise. Thesecondcomesfromaphotosensor underthemachine, whichemits\na1ifthereisdirtthereanda0otherwise. Thethirdcomesfromaninfraredsensor,which\nemitsa1whentheagentisinitshomelocation,anda0otherwise.\nActions:Thereare\u00aeveactionsavailable:goforward,turnrightby90\n,turnleftby90\n,\nsuckupdirt,andturnoff.\nGoals:Thegoalforeachagentistocleanupandgohome.Tobeprecise,theperformance\nmeasurewillbe100pointsforeachpieceofdirtvacuumed up,minus1pointforeach\nactiontaken,andminus1000pointsifitisnotinthehomelocationwhenitturnsitselfoff.\nEnvironment:Theenvironment consistsofagridofsquares. Somesquarescontain\nobstacles (wallsandfurniture) andothersquaresareopenspace.Someoftheopensquares\ncontaindirt.Each\u00aagoforward\u00ba actionmovesonesquareunlessthereisanobstacleinthat\nsquare,inwhichcasetheagentstayswhereitis,butthetouchsensorgoeson.A\u00aasuckup\ndirt\u00baactionalwayscleansupthedirt.A\u00aaturnoff\u00bacommand endsthesimulation.\nWecanvarythecomplexityoftheenvironment alongthreedimensions:\nRoomshape:Inthesimplestcase,theroomisann\nnsquare,forsome\u00aexedn.Wecan\nmakeitmoredif\u00aecultbychanging toarectangular ,L-shaped, orirregularlyshapedroom,\noraseriesofroomsconnected bycorridors.\nFurniture:Placingfurnitureintheroommakesitmorecomplexthananemptyroom.To\nthevacuum-cleaning agent,apieceoffurniture cannotbedistinguished fromawallby\nperception; bothappearasa1onthetouchsensor.\nDirtplacement :Inthesimplestcase,dirtisdistributeduniformly aroundtheroom.But\nitismorerealisticforthedirttopredominate incertainlocations, suchasalongaheavily\ntravelledpathtothenextroom,orinfrontofthecouch.\n2.6Implement atable-lookup agentforthespecialcaseofthevacuum-cleaner worldconsisting\nofa2\n2gridofopensquares,inwhichatmosttwosquareswillcontaindirt.Theagentstarts\nintheupperleftcorner,facingtotheright.Recallthatatable-lookup agentconsistsofatableof\nactionsindexedbyaperceptsequence. Inthisenvironment, theagentcanalwayscomplete its\ntaskinnineorfeweractions(fourmoves,threeturns,andtwosuck-ups), sothetableonlyneeds\nentriesforperceptsequences uptolengthnine.Ateachturn,thereareeightpossiblepercept\nvectors,sothetablewillbeofsize9\ni=18i=153,391,688.Fortunately ,wecancutthisdown\nbyrealizingthatthetouchsensorandhomesensorinputsarenotneeded;wecanarrangesothat\ntheagentneverbumpsintoawallandknowswhenithasreturnedhome.Thenthereareonly\ntworelevantperceptvectors,?0?and?1?,andthesizeofthetableisatmost9\ni=12i=1022.\nRuntheenvironment simulator onthetable-lookup agentinallpossibleworlds(howmanyare\nthere?).Recorditsperformance scoreforeachworldanditsoverallaveragescore.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3006, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a17a7e6c-9476-4fea-9e33-e6083bd481d4": {"__data__": {"id_": "a17a7e6c-9476-4fea-9e33-e6083bd481d4", "embedding": null, "metadata": {"page_label": "22", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dc35c2fe-c9d0-45ad-9e27-00c16449e401", "node_type": "4", "metadata": {"page_label": "22", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "4a3e60a7b72060edb9067ebaff47b3f9c977777b6fa71c54fc4fccaefdee1a66", "class_name": "RelatedNodeInfo"}}, "text": "52 Chapter 2.Intelligent Agents\n2.7Implement anenvironment foran\nmrectangular room,whereeachsquarehasa5%chance\nofcontaining dirt,andnandmarechosenatrandomfromtherange8to15,inclusive.\n2.8Designandimplement apurere\u00afexagentfortheenvironment ofExercise2.7,ignoring\ntherequirement ofreturning home,andmeasureitsperformance. Explainwhyitisimpossible\ntohaveare\u00afexagentthatreturnshomeandshutsitselfoff.Speculate onwhatthebestpossible\nre\u00afexagentcoulddo.Whatpreventsare\u00afexagentfromdoingverywell?\n2.9Designandimplement severalagentswithinternalstate.Measuretheirperformance. How\nclosedotheycometotheidealagentforthisenvironment?\n2.10Calculate thesizeofthetableforatable-lookup agentinthedomainofExercise2.7.\nExplainyourcalculation. Youneednot\u00aellintheentriesforthetable.\n2.11Experiment withchanging theshapeanddirtplacement oftheroom,andwithadding\nfurniture. Measure youragentsinthesenewenvironments. Discusshowtheirperformance\nmightbeimprovedtohandlemorecomplexgeographies.\nArti\u00aecial Intelligence: AModernApproachbyStuartRussellandPeterNorvig,c\n1995Prentice-Hall, Inc.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1057, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7451ace7-13c0-4188-9939-c90839303fc9": {"__data__": {"id_": "7451ace7-13c0-4188-9939-c90839303fc9", "embedding": null, "metadata": {"page_label": "0", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fba910c9-2447-4cae-a7a5-10478968f8ba", "node_type": "4", "metadata": {"page_label": "0", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "2675200431a97e11d55b3224598bc522565863b6f555c2097ce8c26d4b29033e", "class_name": "RelatedNodeInfo"}}, "text": "Intelligent Agents\nPhilipp Koehn\n8 February 2024\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 121, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6c63e7f6-0512-42ef-af6a-8b6a643d0734": {"__data__": {"id_": "6c63e7f6-0512-42ef-af6a-8b6a643d0734", "embedding": null, "metadata": {"page_label": "1", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "64a39386-e028-413e-83ea-5dbf4249dd51", "node_type": "4", "metadata": {"page_label": "1", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "1bcabf8a9793c48be92faa8adac24f1b046c179bf21b472dee29f5fe5e403576", "class_name": "RelatedNodeInfo"}}, "text": "1\n Agents and Environments\n\u2022Agents include humans, robots, softbots, thermostats, etc.\n\u2022The agent function maps from percept histories to actions:\nf:P\u2217\u2192A\n\u2022The agent program runs on the physical architecture to produce f\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 292, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6532479a-2ae2-4da8-895a-6aaac805c853": {"__data__": {"id_": "6532479a-2ae2-4da8-895a-6aaac805c853", "embedding": null, "metadata": {"page_label": "2", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "013e5318-ca62-4631-b99e-b8548829c417", "node_type": "4", "metadata": {"page_label": "2", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "15963c7fedb27973ebc887d6a26d5074f17cb8fee494fd99dbe427cba9d52bcc", "class_name": "RelatedNodeInfo"}}, "text": "2\n Vacuum Cleaner World\n\u2022Percepts: location and contents, e.g., [A, Dirty ]\n\u2022Actions: Left ,Right ,Suck ,NoOp\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 182, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "61e35dda-fc65-4473-af29-60b1f020f95b": {"__data__": {"id_": "61e35dda-fc65-4473-af29-60b1f020f95b", "embedding": null, "metadata": {"page_label": "3", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0f91f725-1b13-42a4-a393-1710258fb210", "node_type": "4", "metadata": {"page_label": "3", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "b1409efcd670df1a9c2dbb08d8e40487ca08fa38c334aa005e0881de4822539a", "class_name": "RelatedNodeInfo"}}, "text": "3\n Vacuum Cleaner Agent\nTable Function\nPercept sequence Action\n[A, Clean ] Right\n[A, Dirty ] Suck\n[B, Clean ] Left\n[B, Dirty ] Suck\n[A, Clean ],[A, Clean ]Right\n[A, Clean ],[A, Dirty ]Suck\n......Input: location, status\nOutput: action\n1:ifstatus = Dirty then\n2: return Suck\n3:end if\n4:iflocation = A then\n5: return Right\n6:end if\n7:iflocation = B then\n8: return Left\n9:end if\n\u2022What is the right function?\n\u2022Can it be implemented in a small agent program?\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 525, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5b93da12-5b91-4b42-8f3a-d2ee4b477bd7": {"__data__": {"id_": "5b93da12-5b91-4b42-8f3a-d2ee4b477bd7", "embedding": null, "metadata": {"page_label": "4", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "13cd80da-57a3-4441-a645-ff3ae27711fe", "node_type": "4", "metadata": {"page_label": "4", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "661c13ef50ba753612e3025ad6069e6aa5bcb4605e3e43f80c93703ceb47b752", "class_name": "RelatedNodeInfo"}}, "text": "4\n Rationality\n\u2022Fixed performance measure evaluates the environment sequence\n\u2013one point per square cleaned up in time T?\n\u2013one point per clean square per time step, minus one per move?\n\u2013penalize for > kdirty squares?\n\u2022A rational agent chooses whichever action maximizes the expected value of the\nperformance measure given the percept sequence to date\n\u2022Rational\u0338=omniscient\n\u2192percepts may not supply all relevant information\n\u2022Rational\u0338=clairvoyant\n\u2192action outcomes may not be as expected\n\u2022Hence, rational\u0338=successful\n\u2022Rational =\u21d2exploration, learning, autonomy\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 630, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b1d6fcd2-ab70-466c-9839-8436a04de818": {"__data__": {"id_": "b1d6fcd2-ab70-466c-9839-8436a04de818", "embedding": null, "metadata": {"page_label": "5", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6bdefd75-a243-4222-b725-de3966d7e61a", "node_type": "4", "metadata": {"page_label": "5", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "b059b80780191b1ea2aa6b99274cdd256da239ce143a8ebc1627abd0e1c83bb5", "class_name": "RelatedNodeInfo"}}, "text": "5\nintelligent agent\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 92, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f6a3ee55-c401-42ee-a896-7dbcb950a25b": {"__data__": {"id_": "f6a3ee55-c401-42ee-a896-7dbcb950a25b", "embedding": null, "metadata": {"page_label": "6", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "542f6490-7535-41aa-ab5a-29ff279ec7bd", "node_type": "4", "metadata": {"page_label": "6", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "6b2990bfd44d6b6acbb560db7b43813967de22d0aa79a021543d1ead1f87718f", "class_name": "RelatedNodeInfo"}}, "text": "6\n Intelligent Agent\n\u2022De\ufb01nition:\nAn intelligent agent perceives its environment via sensors and acts rationally\nupon that environment with its effectors.\n\u2022Adiscrete agent receives percepts one at a time, and maps this percept sequence\nto a sequence of discrete actions.\n\u2022Properties\n\u2013autonomous\n\u2013reactive to the environment\n\u2013pro-active (goal-directed)\n\u2013interacts with other agents via the environment\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 472, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8ca54719-b2bc-4289-9d2f-593101e317c6": {"__data__": {"id_": "8ca54719-b2bc-4289-9d2f-593101e317c6", "embedding": null, "metadata": {"page_label": "7", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "376c995c-9fb1-42a1-8e8f-ff50d17f3aa4", "node_type": "4", "metadata": {"page_label": "7", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "5f14d62ae5a1e23500c002797dc714bce83a12a65b03ab521484a7707fd61632", "class_name": "RelatedNodeInfo"}}, "text": "7\n Sensors/Percepts and Effectors/Actions\n\u2022For example: humans\n\u2013 Sensors: Eyes (vision), ears (hearing), skin (touch), tongue (gustation), nose\n(olfaction), neuromuscular system (proprioception)\n\u2013 Percepts:\n\u2217At the lowest level: electrical signals from these sensors\n\u2217After preprocessing: objects in the visual \ufb01eld (location, textures, colors, ...),\nauditory streams (pitch, loudness, direction), ...\n\u2013 Effectors: limbs, digits, eyes, tongue, ...\n\u2013 Actions: lift a \ufb01nger, turn left, walk, run, carry an object, ...\n\u2022Percepts and actions need to be carefully de\ufb01ned,\npossibly at different levels of abstraction\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 683, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7bb5f7e0-432e-4b02-89b6-a4e20cb8c45d": {"__data__": {"id_": "7bb5f7e0-432e-4b02-89b6-a4e20cb8c45d", "embedding": null, "metadata": {"page_label": "8", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d101e4db-7f79-4bc4-b9ab-c82118d9b3d2", "node_type": "4", "metadata": {"page_label": "8", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "5e7894061202dfb7a97b662b5adb4098423c4f6532ea874ea7cf4d8d317ad6db", "class_name": "RelatedNodeInfo"}}, "text": "8\n Example: Self-Driving Car\n\u2022Percepts: Video, sonar, speedometer, odometer, engine sensors, keyboard input,\nmicrophone, GPS, ...\n\u2022Actions: Steer, accelerate, brake, horn, speak/display, ...\n\u2022Goals: Maintain safety, reach destination, maximize pro\ufb01ts (fuel, tire wear),\nobey laws, provide passenger comfort, ...\n\u2022Environment : U.S. urban streets, freeways, traf\ufb01c, pedestrians, weather,\ncustomers, ...\n\u2022Different aspects of driving may require different types of agent programs\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 550, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7017e94d-b4c2-4496-8165-e0c9f894ea42": {"__data__": {"id_": "7017e94d-b4c2-4496-8165-e0c9f894ea42", "embedding": null, "metadata": {"page_label": "9", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c5a18516-2801-4419-a264-a0b664c0aa2c", "node_type": "4", "metadata": {"page_label": "9", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "2257c41255d37565b778234edd0abc15d91f3f56527e088c0c6b25dea3a75c76", "class_name": "RelatedNodeInfo"}}, "text": "9\n Rationality\n\u2022An ideal rational agent should, for each possible percept sequence, do whatever\nactions will maximize its expected performance measure based on\n\u2013percept sequence\n\u2013built-in and acquired knowledge\n\u2022Rationality includes information gathering, not \u201drational ignorance\u201d\n(If you don\u2019t know something, \ufb01nd out!)\n\u2022Need a performance measure to say how well a task has been achieved\n\u2022Types of performance measures\n\u2013false alarm (false positive) rate\n\u2013false dismissal (false negative) rate\n\u2013speed\n\u2013resources required\n\u2013impact on environment\n\u2013etc.\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 623, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "73b912b6-e215-4b8b-ab02-9d9723d42fd2": {"__data__": {"id_": "73b912b6-e215-4b8b-ab02-9d9723d42fd2", "embedding": null, "metadata": {"page_label": "10", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4817c0d7-352a-470c-bdee-e82540661cba", "node_type": "4", "metadata": {"page_label": "10", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "1df0879ba20247a486a3e5a6d67960119b67f4055b67e3b7cf601ebc16a62a6d", "class_name": "RelatedNodeInfo"}}, "text": "10\n Autonomy\n\u2022A system is autonomous to the extent that its own behavior is determined by its\nown experience\n\u2022Therefore, a system is not autonomous if it is guided by its designer according to\na priori decisions\n\u2022To survive, agents must have\n\u2013enough built-in knowledge to survive\n\u2013ability to learn\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 370, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cf457bff-5399-414b-95a8-751f6b9731b3": {"__data__": {"id_": "cf457bff-5399-414b-95a8-751f6b9731b3", "embedding": null, "metadata": {"page_label": "11", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fc85c902-b5d3-4e57-a74f-616278e0c9ba", "node_type": "4", "metadata": {"page_label": "11", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "fe5d2d91143e803c51c2e04313593555a162fba3f8529a94f2ef2a7ffbb64900", "class_name": "RelatedNodeInfo"}}, "text": "11\nagent types\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 87, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3104168-6eea-4667-9de5-a108f7d04034": {"__data__": {"id_": "f3104168-6eea-4667-9de5-a108f7d04034", "embedding": null, "metadata": {"page_label": "12", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d83cf4d5-a13c-4274-9ac0-1b8bfdac4589", "node_type": "4", "metadata": {"page_label": "12", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "080b0a77c7fff6f05020bb983e876fc2c04bb88a9a94c3f09b17a3f4afda221c", "class_name": "RelatedNodeInfo"}}, "text": "12\n Agent Types\n\u2022Table-driven agents\nuse a percept sequence/action table in memory to \ufb01nd the next action. They are\nimplemented by a (large) lookup table.\n\u2022Simple re\ufb02ex agents\nare based on condition-action rules, implemented with an appropriate\nproduction system. They are stateless devices which do not have memory of\npast world states.\n\u2022Agents with memory\nhave internal state, which is used to keep track of past states of the world.\n\u2022Agents with goals\nare agents that, in addition to state information, have goal information that\ndescribes desirable situations. Agents of this kind take future events into\nconsideration.\n\u2022Utility-based agents\nbase their decisions on classic axiomatic utility theory in order to act rationally.\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 803, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "85915591-dcea-402b-b0f9-85ddcc65d954": {"__data__": {"id_": "85915591-dcea-402b-b0f9-85ddcc65d954", "embedding": null, "metadata": {"page_label": "13", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0869e2b9-a31d-4352-9feb-86ca72cb2324", "node_type": "4", "metadata": {"page_label": "13", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "67db632a67ff00eef630b7cd95c3ec29831c46569b28f08076fc882ccb49f0c1", "class_name": "RelatedNodeInfo"}}, "text": "13\n Architecture of Table-Driven/Re\ufb02ex Agent\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 117, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d1483a82-fc60-469a-ac55-5a0ed0ca0ee6": {"__data__": {"id_": "d1483a82-fc60-469a-ac55-5a0ed0ca0ee6", "embedding": null, "metadata": {"page_label": "14", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f86b3111-01c1-4e53-83df-f92ff9be0aee", "node_type": "4", "metadata": {"page_label": "14", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "1d9193745887eae11d9a6f3f6bfc16f9f82ccc361c33545e3bb583821ad2195f", "class_name": "RelatedNodeInfo"}}, "text": "14\n Table-Driven Agents\n\u2022Table lookup of percept-action pairs mapping from every possible perceived\nstate to the optimal action for that state\n\u2022Problems\n\u2013too big to generate and to store (Chess has about 10120states, for example)\n\u2013no knowledge of non-perceptual parts of the current state\n\u2013not adaptive to changes in the environment; requires entire table to be updated\nif changes occur\n\u2013looping: can\u2019t make actions conditional on previous actions/states\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 527, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0f5252b4-c88a-4758-8b80-838436ed2149": {"__data__": {"id_": "0f5252b4-c88a-4758-8b80-838436ed2149", "embedding": null, "metadata": {"page_label": "15", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d4373eb7-929c-45bf-b748-acbd4054a3b9", "node_type": "4", "metadata": {"page_label": "15", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "81b8dc30e2c5ed8d1e504ea6f2e76b3133ebec91984771475f5edce3d7f2eeb0", "class_name": "RelatedNodeInfo"}}, "text": "15\n Simple Re\ufb02ex Agents\n\u2022Rule-based reasoning to map from percepts to optimal action;\neach rule handles a collection of perceived states\n\u2022Problems\n\u2013still usually too big to generate and to store\n\u2013still no knowledge of non-perceptual parts of state\n\u2013still not adaptive to changes in the environment;\nrequires collection of rules to be updated if changes occur\n\u2013still can\u2019t make actions conditional on previous state\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 487, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "660ce218-39ef-48af-aa84-ea9dce37d998": {"__data__": {"id_": "660ce218-39ef-48af-aa84-ea9dce37d998", "embedding": null, "metadata": {"page_label": "16", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3654828c-6c7d-4bf9-b2cd-ce8435291660", "node_type": "4", "metadata": {"page_label": "16", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "944b43fdc7027133669614046e49ad941e23480313f9cf75cf83c2b501785daa", "class_name": "RelatedNodeInfo"}}, "text": "16\n Architecture of Agent with Memory\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 110, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5430a335-490f-4e1a-bbde-f0a39eec7665": {"__data__": {"id_": "5430a335-490f-4e1a-bbde-f0a39eec7665", "embedding": null, "metadata": {"page_label": "17", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "50034a92-37b6-4d7f-a9f0-09cf98806c36", "node_type": "4", "metadata": {"page_label": "17", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "09220da7d3b36b6c271bd68ec6d6e37e51c69a976357f4802461f3fecf032fc9", "class_name": "RelatedNodeInfo"}}, "text": "17\n Agents with Memory\n\u2022Encode \u201dinternal state\u201d of world to remember past contained in earlier percepts\n\u2022Needed because sensors do not usually give the entire state of the world at each\ninput, so perception of the environment is captured over time.\n\u2022\u201dState\u201d is used to encode different \u201dworld states\u201d that generate the same\nimmediate percept\n\u2022Requires ability to represent change in the world; one possibility is to represent\njust the latest state, but then can\u2019t reason about hypothetical courses of action\n\u2022Example: Rodney Brooks\u2019s Subsumption Architecture\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 631, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "903659d8-a415-4264-98ed-675fb565c677": {"__data__": {"id_": "903659d8-a415-4264-98ed-675fb565c677", "embedding": null, "metadata": {"page_label": "18", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "84d83c1b-13c9-4df4-883a-da2192351114", "node_type": "4", "metadata": {"page_label": "18", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "eaec82de6bb9935128731ce6fc961fd477bb21a815669d6de1ee7abc432ea3fd", "class_name": "RelatedNodeInfo"}}, "text": "18\n Brooks\u2019 Subsumption Architecture\n\u2022Main idea: build complex, intelligent robots by decomposing behaviors into a\nhierarchy of skills, each completely de\ufb01ning a complete percept-action cycle for\none very speci\ufb01c task\n\u2022Examples:\n\u2013avoiding contact\n\u2013wandering\n\u2013exploring\n\u2013recognizing doorways\n\u2022Each behavior is modeled by a \ufb01nite-state machine with a few states\n\u2022Behaviors are loosely coupled, asynchronous interactions\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 490, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0457fdea-0c13-4688-a54e-fd71dfe377a4": {"__data__": {"id_": "0457fdea-0c13-4688-a54e-fd71dfe377a4", "embedding": null, "metadata": {"page_label": "19", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ce61545-6112-4b61-b2f1-3d3cc2b1eccc", "node_type": "4", "metadata": {"page_label": "19", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "5cd7070b17ebae3e7ab241b7f62a16f1e1f870aac8cf822b733d56310e93adc4", "class_name": "RelatedNodeInfo"}}, "text": "19\n Architecture of Goal-Based Agent\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 109, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4b257a6e-94a5-4788-b70a-0504a93078f6": {"__data__": {"id_": "4b257a6e-94a5-4788-b70a-0504a93078f6", "embedding": null, "metadata": {"page_label": "20", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "37eb8154-56d4-418a-811c-ee1267b5c996", "node_type": "4", "metadata": {"page_label": "20", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "70e6198a4e75898a3861ac9f500b395cc3ca8fb960343ee4e3cc6a2627202ea0", "class_name": "RelatedNodeInfo"}}, "text": "20\n Goal-Based Agent\n\u2022Choose actions so as to achieve a (given or computed) goal.\n\u2022A goal is a description of a desirable situation.\n\u2022Keeping track of the current state is often not enough:\nneed to add goals to decide which situations are good\n\u2022Deliberative instead of reactive.\n\u2022May have to consider long sequences of possible actions before deciding if goal\nis achieved\n(involves consideration of the future, \u201dwhat will happen if I do...?\u201d )\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 516, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c443db44-6e60-4414-b692-c67badf89cf0": {"__data__": {"id_": "c443db44-6e60-4414-b692-c67badf89cf0", "embedding": null, "metadata": {"page_label": "21", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9535911d-33e2-49c3-b623-c79315e1fe79", "node_type": "4", "metadata": {"page_label": "21", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "102946d3c2f1babd4f1d3d686e8e2435520f68ce10ba5c249a2309602493377d", "class_name": "RelatedNodeInfo"}}, "text": "21\n Architecture of Utility-Based Agent\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 112, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7df068a-d095-444e-b683-d349abdae08b": {"__data__": {"id_": "b7df068a-d095-444e-b683-d349abdae08b", "embedding": null, "metadata": {"page_label": "22", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2990df88-ca4a-4cbe-a8a1-749be92c2ee7", "node_type": "4", "metadata": {"page_label": "22", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "f166739740f2e0b5df17253adf81df5f41a507ef129d538662cd50f570926677", "class_name": "RelatedNodeInfo"}}, "text": "22\n Utility-Based Agent\n\u2022When there are multiple possible alternatives, how to decide which one is best?\n\u2022A goal speci\ufb01es a crude distinction between a happy and unhappy state, but\noften need a more general performance measure that describes \u201ddegree of\nhappiness.\u201d\n\u2022Utility function\nU: State\u2192Real Numbers\nindicating a measure of success or happiness when at a given state.\n\u2022Allows decisions comparing choice between con\ufb02icting goals, and choice\nbetween likelihood of success and importance of goal (if achievement is\nuncertain).\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 601, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e47d43f3-91b4-44d6-9e5f-dd85e0cf4fba": {"__data__": {"id_": "e47d43f3-91b4-44d6-9e5f-dd85e0cf4fba", "embedding": null, "metadata": {"page_label": "23", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e09f8ec4-7ea1-4f55-ae7d-97f528e03bcd", "node_type": "4", "metadata": {"page_label": "23", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "f7b8976c5dac53b525f67f32a7512041a397c316dcd1f604f5a771a587ab3967", "class_name": "RelatedNodeInfo"}}, "text": "23\nenvironment\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 87, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "82597407-bbd3-4e54-8b17-b7f2856a7e9d": {"__data__": {"id_": "82597407-bbd3-4e54-8b17-b7f2856a7e9d", "embedding": null, "metadata": {"page_label": "24", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "972dc4ab-fc85-4816-bafe-f236034ae90b", "node_type": "4", "metadata": {"page_label": "24", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "3665f184f99d335c44b8262870c7916611fe72178bc8aea09723200bbedea29c", "class_name": "RelatedNodeInfo"}}, "text": "24\n Properties of Environments\n\u2022Accessible/Inaccessible.\n\u2013if an agent\u2019s sensors give it access to the complete state of the environment\nneeded to choose an action, the environment is accessible.\n\u2013such environments are convenient, since the agent is freed from the task of\nkeeping track of the changes in the environment.\n\u2022Deterministic/Nondeterministic\n\u2013an environment is deterministic if the next state of the environment is\ncompletely determined by the current state of the environment and the action\nof the agent.\n\u2013in an accessible and deterministic environment, the agent need not deal with\nuncertainty.\n\u2022Episodic/Sequential\n\u2013an episodic environment means that subsequent episodes do not depend on\nwhat actions occurred in previous episodes.\n\u2013such environments do not require the agent to plan ahead.\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 877, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2d445638-89e9-4f1e-8af9-f8f445ca439e": {"__data__": {"id_": "2d445638-89e9-4f1e-8af9-f8f445ca439e", "embedding": null, "metadata": {"page_label": "25", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e4f359e7-990a-48b6-b23b-e7116d2f7f41", "node_type": "4", "metadata": {"page_label": "25", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "3a6e2b893984ae9ff2b1a5bf931ed22f5caa6f7cc0896394a1cbac7710734ccf", "class_name": "RelatedNodeInfo"}}, "text": "25\n Properties of Environments\n\u2022Static/Dynamic\n\u2013a static environment does not change while the agent is thinking.\n\u2013the passage of time as an agent deliberates is irrelevant.\n\u2013the agent doesn\u2019t need to observe the world during deliberation.\n\u2022Discrete/Continuous\n\u2013if the number of distinct percepts and actions is limited, the environment is\ndiscrete, otherwise it is continuous.\n\u2022With/Without intelligent adversaries\n\u2013if the environment contains intelligent, adversarial agents, the agent needs to\nbe concerned about strategic, game-theoretic aspects of the environment\n\u2013most engineering environments don\u2019t have rational adversaries, whereas most\nsocial and economic systems get their complexity from the interactions of\n(more or less) rational agents.\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5669d62-ae64-496d-9be1-b0a0aec6dd86": {"__data__": {"id_": "b5669d62-ae64-496d-9be1-b0a0aec6dd86", "embedding": null, "metadata": {"page_label": "26", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "329538b3-b96c-42ad-80ca-bab4f96305e1", "node_type": "4", "metadata": {"page_label": "26", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "1576260d4857f7f2fa2be4f64e0dbcfd0544528eb16cf23888dd4e695a1ad609", "class_name": "RelatedNodeInfo"}}, "text": "26\n Properties of Environments\nAccessible Deterministic Episodic Static Discrete\nImage Classi\ufb01cation\nSolitaire\nBackgammon\nTaxi driving\nInternet shopping\nMedical diagnosis\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 243, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ad6fcc2-192b-4771-b997-0d99481044c4": {"__data__": {"id_": "0ad6fcc2-192b-4771-b997-0d99481044c4", "embedding": null, "metadata": {"page_label": "27", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "77809ebb-d8a8-4c58-a5ad-b6a11b4637e7", "node_type": "4", "metadata": {"page_label": "27", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "42d92892947d21aedae728822de3ae0044c96cbd171185ea521fcbdc1cdef907", "class_name": "RelatedNodeInfo"}}, "text": "27\n Properties of Environments\nAccessible Deterministic Episodic Static Discrete\nImage Classi\ufb01cation yes yes yes yes no\nSolitaire\nBackgammon\nTaxi driving\nInternet shopping\nMedical diagnosis\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 262, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6c20d800-f06b-4ae4-8ad6-538bc5da1d70": {"__data__": {"id_": "6c20d800-f06b-4ae4-8ad6-538bc5da1d70", "embedding": null, "metadata": {"page_label": "28", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "976c795b-f5d5-4f1c-946c-c0e788e4be41", "node_type": "4", "metadata": {"page_label": "28", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "2fb19826024461f05c34c1e561ec9905ffe157cb5b41a3878fef9a6a0fb15d26", "class_name": "RelatedNodeInfo"}}, "text": "28\n Properties of Environments\nAccessible Deterministic Episodic Static Discrete\nImage Classi\ufb01cation yes yes yes yes no\nSolitaire no yes no yes yes\nBackgammon\nTaxi driving\nInternet shopping\nMedical diagnosis\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 280, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b4a2397c-cdf8-4537-9ffd-07f8df360085": {"__data__": {"id_": "b4a2397c-cdf8-4537-9ffd-07f8df360085", "embedding": null, "metadata": {"page_label": "29", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2f3716f3-7ea7-4055-b8e4-950bc62a3b47", "node_type": "4", "metadata": {"page_label": "29", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "c42c70316dcba5418011a7d78653199a93d32f5750f9d8f414ff3a9750f3cf70", "class_name": "RelatedNodeInfo"}}, "text": "29\n Properties of Environments\nAccessible Deterministic Episodic Static Discrete\nImage Classi\ufb01cation yes yes yes yes no\nSolitaire no yes no yes yes\nBackgammon yes no no yes yes\nTaxi driving\nInternet shopping\nMedical diagnosis\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 298, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9cef2c25-8b41-485b-b165-04ca52887e30": {"__data__": {"id_": "9cef2c25-8b41-485b-b165-04ca52887e30", "embedding": null, "metadata": {"page_label": "30", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "262425e9-1a30-405e-a513-891a87598fbf", "node_type": "4", "metadata": {"page_label": "30", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "9a24e45c02551e84ebe044981caf549ea9fc4965f8b9a53d239deb8bede54b70", "class_name": "RelatedNodeInfo"}}, "text": "30\n Properties of Environments\nAccessible Deterministic Episodic Static Discrete\nImage Classi\ufb01cation yes yes yes yes no\nSolitaire no yes no yes yes\nBackgammon yes no no yes yes\nTaxi driving no no no no no\nInternet shopping\nMedical diagnosis\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 313, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a2f1ac0f-7856-42ed-a918-c4b7471b203d": {"__data__": {"id_": "a2f1ac0f-7856-42ed-a918-c4b7471b203d", "embedding": null, "metadata": {"page_label": "31", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e9c57312-ca85-4dbc-b7b3-36df08853db9", "node_type": "4", "metadata": {"page_label": "31", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "0b76caa9abc8448fb5ce1e016bcd0babcebaf2756bbee7968d74cafd2fb6f56a", "class_name": "RelatedNodeInfo"}}, "text": "31\n Properties of Environments\nAccessible Deterministic Episodic Static Discrete\nImage Classi\ufb01cation yes yes yes yes no\nSolitaire no yes no yes yes\nBackgammon yes no no yes yes\nTaxi driving no no no no no\nInternet shopping no no no no no\nMedical diagnosis\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 328, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c29910c3-9eb0-4e5f-be54-c692fe0b1f6c": {"__data__": {"id_": "c29910c3-9eb0-4e5f-be54-c692fe0b1f6c", "embedding": null, "metadata": {"page_label": "32", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "918d6eab-0844-4917-809d-68b6818d454e", "node_type": "4", "metadata": {"page_label": "32", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "f53b373874733329bc2f7d2a0cb80be244100a9013d53c8de4807cf8357c5fa3", "class_name": "RelatedNodeInfo"}}, "text": "32\n Properties of Environments\nAccessible Deterministic Episodic Static Discrete\nImage Classi\ufb01cation yes yes yes yes no\nSolitaire no yes no yes yes\nBackgammon yes no no yes yes\nTaxi driving no no no no no\nInternet shopping no no no no no\nMedical diagnosis no no no no no\n\u21d2lots of real-world domains fall into the hardest case\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 398, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1e0eb29d-d183-4209-a012-902e092e4601": {"__data__": {"id_": "1e0eb29d-d183-4209-a012-902e092e4601", "embedding": null, "metadata": {"page_label": "33", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "221d27b2-441c-4dd8-a014-c2d7407961a1", "node_type": "4", "metadata": {"page_label": "33", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "24c1a5ecb9ac0887e452be6dec0f1a451ec26030b6c8e3e508989cb1d7621435", "class_name": "RelatedNodeInfo"}}, "text": "33\nsummary\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 83, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c8a37f28-9e56-4d87-bc25-4ad9b39bdba3": {"__data__": {"id_": "c8a37f28-9e56-4d87-bc25-4ad9b39bdba3", "embedding": null, "metadata": {"page_label": "34", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0b620ab8-48d8-4e0d-a64f-cccb33254bdb", "node_type": "4", "metadata": {"page_label": "34", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}, "hash": "1ec25a8e1190f641db27a0b34cf7dd596a80e8724e7dd81426224596270db54e", "class_name": "RelatedNodeInfo"}}, "text": "34\n Summary\n\u2022Anagent perceives and acts in an environment, has an architecture, and is\nimplemented by an agent program.\n\u2022Anideal agent always chooses the action which maximizes its expected\nperformance, given its percept sequence so far.\n\u2022Anautonomous agent uses its own experience rather than built-in knowledge\nof the environment by the designer.\n\u2022Anagent program maps from percept to action and updates its internal state.\n\u2013 re\ufb02ex agent responds immediately to percepts.\n\u2013 goal-based agent acts in order to achieve their goal(s).\n\u2013 utility-based agent maximizes their own utility function.\n\u2022Representing knowledge is important for successful agent design.\n\u2022Most challenging environments are inaccessible, nondeterministic, nonepisodic,\ndynamic, and continuous, and contain intelligent adversaries.\nPhilipp Koehn Arti\ufb01cial Intelligence: Intelligent Agents 8 February 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 873, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"d4d7bc7c-7e32-453e-8af6-51f0177a7fec": {"node_ids": ["a0bea8eb-a6d9-4d70-88e1-960d0f9c2624", "5b7cb5fd-5092-4d2a-9cda-c1cc7bedf724"], "metadata": {"page_label": "1", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "a7f759f7-53ba-405f-95aa-e857207648a9": {"node_ids": ["7f51159f-bedb-454b-8660-c708b6f4cfd3", "8b404941-c86e-441a-8386-322f01604985"], "metadata": {"page_label": "2", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "843edcee-ff4d-4ea1-a259-ca5a30230a95": {"node_ids": ["52b70eec-4bbf-4808-9f3d-846741182718", "5b5077b9-38da-4c25-ade2-27760f6ac782"], "metadata": {"page_label": "3", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "15025bec-e1d7-44d2-bf61-e5c8889d7989": {"node_ids": ["bf16bae2-7474-4276-af73-3b05272afb9a", "373b31a5-6106-4f6b-bc14-29d11081ed1a"], "metadata": {"page_label": "4", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "d128bc4c-f689-413d-bc9c-211e33e45f6d": {"node_ids": ["b68fae12-9a8e-408f-a503-d7bf7e9d4b00", "734cd577-5821-4faf-b9f0-a6e729f369aa"], "metadata": {"page_label": "5", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "c15b00da-3e3b-4f33-9f9a-a7968d7510d6": {"node_ids": ["6cb33439-2d56-4640-9022-86fe9e6637be", "2ca6880e-0b18-41cd-aef3-617f3214d411"], "metadata": {"page_label": "6", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "604d5b76-c572-4673-b2ec-3e8adea2b617": {"node_ids": ["c27d9cfa-3b4a-4853-ae17-554eb3e4f3e2", "962b04be-8f2a-4d63-9432-8b9a5520d3a2", "93cedf8a-c8a6-40f0-b8df-c8e5128a6dbf", "16d20fd5-f436-4401-bd65-5f9811920361", "2a1166b5-5963-4208-9081-740b8c1d1e77"], "metadata": {"page_label": "7", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "cfc5774c-dc55-4dbc-84c2-de2425f6b1b3": {"node_ids": ["2547fd93-0bc3-4d4d-9be4-c89cbba0b856"], "metadata": {"page_label": "8", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "4cb244ef-d23a-4606-9cad-18afdc0ad3f9": {"node_ids": ["f941853b-1b1e-4a48-abc3-9dbfd2911beb", "248ecc26-f16e-4113-9488-3f432d6c5aac", "8fcc9c46-6e03-435c-97e7-97a3638694a8", "591c6e7e-fb52-49ea-9859-8b25f6932b1b"], "metadata": {"page_label": "9", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "27943491-696e-4730-8d93-3628598abe87": {"node_ids": ["3673bf07-6eb5-4f21-a899-825c209f56dd"], "metadata": {"page_label": "10", "file_name": "1506.02640v5.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/1506.02640v5.pdf", "file_type": "application/pdf", "file_size": 5296750, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "25aa5ef8-56c2-479d-bbb5-daba49730b80": {"node_ids": ["0b6f9597-8a81-457a-b1ab-26e8b37dac9a"], "metadata": {"page_label": "1", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "4062379e-10b9-4136-b572-f189250c3e7d": {"node_ids": ["174bc864-365a-4e3d-b898-528fc170542e"], "metadata": {"page_label": "2", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "a5f20a51-bedd-4a9c-9085-139446353f1e": {"node_ids": ["b0e7ec7b-ac2b-4944-ab73-9e95e66a6b31"], "metadata": {"page_label": "3", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "de5353d8-49ce-45cd-b973-34c7eb4d78b1": {"node_ids": ["063cb970-a394-4c2e-9db9-8a5e99b557d1"], "metadata": {"page_label": "4", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "5fa2eff2-1d87-4e2d-8988-f8fe17f40185": {"node_ids": ["51cd4906-09a7-48c8-a66d-9a42d60b5764"], "metadata": {"page_label": "5", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "263f4cb5-bead-4a6b-8984-20e99553c3ca": {"node_ids": ["b0e2a428-1265-44d9-b5b0-4f2ebf5cb572"], "metadata": {"page_label": "6", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d8d897c2-a40f-46c2-9f4f-40c7ca3f2c6e": {"node_ids": ["61909d8b-fe51-4401-bb85-eb3c6e189724", "03d5f84c-4969-4564-b2e9-705d3bb1ec99"], "metadata": {"page_label": "7", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "0caa366f-8138-418c-b552-104a339c11cd": {"node_ids": ["3be2bb7d-2174-4e69-ae06-820b8bd9592a"], "metadata": {"page_label": "8", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "a8ca7892-bfd8-4117-aa5e-3d15152072f0": {"node_ids": ["d0eb1202-335f-4d83-802d-5ddc851fb7d9"], "metadata": {"page_label": "9", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "93b400e2-5ea7-4af3-8ab1-e188d9a1c9fd": {"node_ids": ["f524492e-3799-470d-9137-4db6a4d82997"], "metadata": {"page_label": "10", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "4d47e6f7-5bc0-4bb9-809e-b21c7eb79c0a": {"node_ids": ["0d1aec07-9348-4529-975d-7d8b4d6d9ffa"], "metadata": {"page_label": "11", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "9e06595d-c402-4bf7-be8f-20b852150113": {"node_ids": ["195c5082-2566-45ec-b115-cd9f6d01aa1f"], "metadata": {"page_label": "12", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "b7cc01e2-f0e6-457d-9575-374ec5406f04": {"node_ids": ["eebba14d-6257-4a18-943d-11c3f1f245f1"], "metadata": {"page_label": "13", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "81e1c260-96e9-44ed-934c-fee55d39ca24": {"node_ids": ["2d1040fd-0b44-408d-aa70-cb01de009e5f"], "metadata": {"page_label": "14", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "515c186e-752d-434c-a38a-9078e7733eb3": {"node_ids": ["9672404b-d5a4-4cd5-bb4f-1c139ac10205"], "metadata": {"page_label": "15", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "0ced88fc-9fd3-428d-837a-5e3c241aabdc": {"node_ids": ["9e72d9a4-1cee-4795-bc24-2aeef0e8b5ad"], "metadata": {"page_label": "16", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "0670389a-f799-43e0-9a56-827672784b53": {"node_ids": ["0583d04f-0507-4834-9af7-cf3f338d82e3"], "metadata": {"page_label": "17", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "e3afcbf0-afa3-4b1f-ba0e-b2f3afddb625": {"node_ids": ["898b37bf-cead-4d38-bc79-862ff358c7eb"], "metadata": {"page_label": "18", "file_name": "Intelligent Agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/Intelligent Agents.pdf", "file_type": "application/pdf", "file_size": 273098, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "aa15153c-21e2-4bc4-981a-4427eb5389be": {"node_ids": ["7ea8d8a6-05c7-4c65-b391-494e8a807c0b"], "metadata": {"page_label": "1", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "b20afe2f-20ec-4c27-87c5-b7557a65be3a": {"node_ids": ["0ee870fb-8e5c-438b-853b-19450f45b881"], "metadata": {"page_label": "2", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "271abb5d-413f-451e-8ae8-0b745abdc3a0": {"node_ids": ["288fe6f5-c570-4f45-a2f6-1fe0827cd32c"], "metadata": {"page_label": "3", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "eab98aab-d194-4483-8763-c6adb9876aa4": {"node_ids": ["457473bb-f17c-4a26-a4f7-473ee6f5813d"], "metadata": {"page_label": "4", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "3be8cd1b-645e-4c2c-b429-8d910b985aa7": {"node_ids": ["bafd021b-e57b-4be0-b250-6d72223a8c81"], "metadata": {"page_label": "5", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "5b37a0d6-dbc7-4b1a-85f9-0ff44ee3cbea": {"node_ids": ["e1a85400-fcd8-4b6c-a72e-c24f572c110b"], "metadata": {"page_label": "6", "file_name": "ML.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/ML.pdf", "file_type": "application/pdf", "file_size": 38172, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "88a81797-7850-4cdb-bcc5-c52855615dd9": {"node_ids": ["657b08ba-ab79-450f-ae8e-e234aa283a7b", "7c70da1d-5015-4ac4-9430-ac0d26fca148", "f62b83b7-c650-4dc4-b699-8e29fe4a3ffd", "af11eeed-7f6f-48f7-9cad-5d7b91750f40", "a1b490d9-b503-484c-a83d-c90dc324ec9a", "ecb12fa0-dbab-4376-8c85-ac0e7a80f3f7", "3f356fa0-6086-40e7-908d-36ade5c79691", "ab5c7922-dedc-4671-b320-e7b76491f2b8", "95e80773-b27e-41fb-af86-6d8474f7d9d0"], "metadata": {"file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/MLDOC.txt", "file_name": "MLDOC.txt", "file_type": "text/plain", "file_size": 21968, "creation_date": "2024-08-07", "last_modified_date": "2024-08-07"}}, "c8236ec3-79c5-466c-af80-25d0effa6b1c": {"node_ids": ["e8773c7d-5006-44dc-a9e9-d08a61ca5693"], "metadata": {"page_label": "1", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "b8cb43a8-4726-41c7-ba46-c19dfaec4c3e": {"node_ids": ["49d151ed-8df9-473f-a589-586a0191b2ba"], "metadata": {"page_label": "2", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "081ddf92-852f-40bb-b588-538c9fd45e34": {"node_ids": ["73cd50da-1aa5-417d-8563-a5ecdc657fb2"], "metadata": {"page_label": "3", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "3dfd3637-fe04-425a-832e-319e6865f996": {"node_ids": ["26ee755e-a30b-4074-9e1f-52c00759ef12"], "metadata": {"page_label": "4", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "1045d45d-e50c-4c65-950c-87e76a697c6e": {"node_ids": ["e1dae1df-ac3c-4f8b-98dc-ff8753ac0fee"], "metadata": {"page_label": "5", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "982fa401-3dfb-4937-8004-738030d53def": {"node_ids": ["4ae355d4-ce1f-4f1a-996e-a969ba3de09e"], "metadata": {"page_label": "6", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "8d4f18be-6679-4f6e-bc83-e33fef9e8653": {"node_ids": ["e80c9e12-0e3a-4c30-b442-a2cca3ccc153"], "metadata": {"page_label": "7", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "3ac9b8bd-feba-4a5f-a387-71180d079a1e": {"node_ids": ["08616f41-959d-402c-9460-8ae5181025e3"], "metadata": {"page_label": "8", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "8370cd5e-ef89-4abf-ba32-ecf770c2b4f4": {"node_ids": ["59125d5c-dc15-4241-bb7e-fc40e86fbe73"], "metadata": {"page_label": "9", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "6640a5ed-a358-4e2b-91e6-536a4936d4e5": {"node_ids": ["7b21c50e-be6d-4f0f-9f69-38c6ee3d1426", "a6f19505-fbb4-4b67-b9cb-ecad0ddcc2bd"], "metadata": {"page_label": "10", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "0a07be52-f662-4822-b001-331d0ac88dff": {"node_ids": ["d6151167-3060-4503-8afd-5f375e9dbeff"], "metadata": {"page_label": "11", "file_name": "NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/NIPS-2017-attention-is-all-you-need-Paper.pdf", "file_type": "application/pdf", "file_size": 569417, "creation_date": "2024-08-08", "last_modified_date": "2024-08-07"}}, "cff25309-ccf5-4af2-872d-4776bec5d113": {"node_ids": ["7c98b49f-46eb-4a77-a842-4e1be44e99db"], "metadata": {"page_label": "1", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "a032f2ea-36a8-4b14-998f-689e1ce45c2c": {"node_ids": ["99e35303-726e-42fc-b575-4f7d4489ab6c"], "metadata": {"page_label": "2", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d744111e-1d36-4033-a5ab-b694d7f347f6": {"node_ids": ["a597c390-afb4-4a8f-ad95-d8bb8ce29e76"], "metadata": {"page_label": "3", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "680171bd-ab73-451b-ae9e-bf188dd8f396": {"node_ids": ["b9af6c60-d611-4c18-a0da-ed76da139238"], "metadata": {"page_label": "4", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "7a19d4f7-7aae-4520-8d99-4bea36d8fcd1": {"node_ids": ["770f1749-36fc-47f6-8d68-65b60e0364bd"], "metadata": {"page_label": "5", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "9fc7c8d9-9572-4de2-b7a0-8396e1731c65": {"node_ids": ["064668e8-b755-4fc3-8c18-462bcad5567c"], "metadata": {"page_label": "6", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "7cf52c57-9fec-41ac-a9b3-b72dac5529e6": {"node_ids": ["1519e695-a2d5-4303-a1ee-1b54f85bca95"], "metadata": {"page_label": "7", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d6650d8e-5e58-42c2-a326-ff2918e668cf": {"node_ids": ["4b0e7fc0-dbe4-459a-8455-af398e48babf"], "metadata": {"page_label": "8", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "cd98c782-c829-46ac-a280-c64b09157e70": {"node_ids": ["cce22b88-2af7-4b61-8f17-473d792612a9"], "metadata": {"page_label": "9", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "adbc09b4-b1f0-42e4-8d80-0b27ea6e6554": {"node_ids": ["67b0d70d-40f8-4d09-ad7c-af1225335918"], "metadata": {"page_label": "10", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d9d9245e-a063-4851-9bc5-dfcda9d16772": {"node_ids": ["7d6699c8-0462-403b-b699-d22375c15454"], "metadata": {"page_label": "11", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "66174a56-09d6-4bbc-9668-24ecf27a5b35": {"node_ids": ["530042e6-5533-4b18-803e-ebcfc661ac5e"], "metadata": {"page_label": "12", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "e26e0394-58f9-4610-bbe3-59562f2e907e": {"node_ids": ["e014c2c5-b445-409c-9ce2-89de09007ea6"], "metadata": {"page_label": "13", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d277a37b-cfb5-4ba3-90c3-acb2518d9d61": {"node_ids": ["fd79c5f1-57e1-4d2f-9021-5c4ca6d1f4b0"], "metadata": {"page_label": "14", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "aa0c5184-7568-40af-9ee6-45dc83180ac4": {"node_ids": ["62050fa0-7614-4fc2-bab3-0495e8debafe"], "metadata": {"page_label": "15", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "1fe55689-be5f-4c9a-9e6d-f5a05376119a": {"node_ids": ["51be24d0-344b-4780-b040-07b86e38944d"], "metadata": {"page_label": "16", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "b0bd4140-19fe-4feb-a329-26d4cad626b9": {"node_ids": ["2ea49615-0a27-4115-8948-70cd6ff1f821"], "metadata": {"page_label": "17", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "bea429f6-6da7-4d9f-8f3d-e396df0fcbe6": {"node_ids": ["6dcef79c-a195-4be6-a641-6a284dd0f9d2"], "metadata": {"page_label": "18", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "4664bd02-ec62-4a83-ac5b-505e8d3a4dab": {"node_ids": ["f1f1a985-33e9-4553-b3ad-81c4bde250f5"], "metadata": {"page_label": "19", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d7b8e5d0-292a-49db-849e-983eb8354dbc": {"node_ids": ["20b4de67-52e0-409f-9f9d-6ce0f3b1d5ff"], "metadata": {"page_label": "20", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "e32c141a-8ed3-4645-8cd2-a1bf91813a56": {"node_ids": ["0b649889-e07a-46ed-bb02-a64accae7a00"], "metadata": {"page_label": "21", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "dc35c2fe-c9d0-45ad-9e27-00c16449e401": {"node_ids": ["a17a7e6c-9476-4fea-9e33-e6083bd481d4"], "metadata": {"page_label": "22", "file_name": "chapter02.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/chapter02.pdf", "file_type": "application/pdf", "file_size": 610518, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "fba910c9-2447-4cae-a7a5-10478968f8ba": {"node_ids": ["7451ace7-13c0-4188-9939-c90839303fc9"], "metadata": {"page_label": "0", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "64a39386-e028-413e-83ea-5dbf4249dd51": {"node_ids": ["6c63e7f6-0512-42ef-af6a-8b6a643d0734"], "metadata": {"page_label": "1", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "013e5318-ca62-4631-b99e-b8548829c417": {"node_ids": ["6532479a-2ae2-4da8-895a-6aaac805c853"], "metadata": {"page_label": "2", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "0f91f725-1b13-42a4-a393-1710258fb210": {"node_ids": ["61e35dda-fc65-4473-af29-60b1f020f95b"], "metadata": {"page_label": "3", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "13cd80da-57a3-4441-a645-ff3ae27711fe": {"node_ids": ["5b93da12-5b91-4b42-8f3a-d2ee4b477bd7"], "metadata": {"page_label": "4", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "6bdefd75-a243-4222-b725-de3966d7e61a": {"node_ids": ["b1d6fcd2-ab70-466c-9839-8436a04de818"], "metadata": {"page_label": "5", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "542f6490-7535-41aa-ab5a-29ff279ec7bd": {"node_ids": ["f6a3ee55-c401-42ee-a896-7dbcb950a25b"], "metadata": {"page_label": "6", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "376c995c-9fb1-42a1-8e8f-ff50d17f3aa4": {"node_ids": ["8ca54719-b2bc-4289-9d2f-593101e317c6"], "metadata": {"page_label": "7", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d101e4db-7f79-4bc4-b9ab-c82118d9b3d2": {"node_ids": ["7bb5f7e0-432e-4b02-89b6-a4e20cb8c45d"], "metadata": {"page_label": "8", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "c5a18516-2801-4419-a264-a0b664c0aa2c": {"node_ids": ["7017e94d-b4c2-4496-8165-e0c9f894ea42"], "metadata": {"page_label": "9", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "4817c0d7-352a-470c-bdee-e82540661cba": {"node_ids": ["73b912b6-e215-4b8b-ab02-9d9723d42fd2"], "metadata": {"page_label": "10", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "fc85c902-b5d3-4e57-a74f-616278e0c9ba": {"node_ids": ["cf457bff-5399-414b-95a8-751f6b9731b3"], "metadata": {"page_label": "11", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d83cf4d5-a13c-4274-9ac0-1b8bfdac4589": {"node_ids": ["f3104168-6eea-4667-9de5-a108f7d04034"], "metadata": {"page_label": "12", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "0869e2b9-a31d-4352-9feb-86ca72cb2324": {"node_ids": ["85915591-dcea-402b-b0f9-85ddcc65d954"], "metadata": {"page_label": "13", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "f86b3111-01c1-4e53-83df-f92ff9be0aee": {"node_ids": ["d1483a82-fc60-469a-ac55-5a0ed0ca0ee6"], "metadata": {"page_label": "14", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "d4373eb7-929c-45bf-b748-acbd4054a3b9": {"node_ids": ["0f5252b4-c88a-4758-8b80-838436ed2149"], "metadata": {"page_label": "15", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "3654828c-6c7d-4bf9-b2cd-ce8435291660": {"node_ids": ["660ce218-39ef-48af-aa84-ea9dce37d998"], "metadata": {"page_label": "16", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "50034a92-37b6-4d7f-a9f0-09cf98806c36": {"node_ids": ["5430a335-490f-4e1a-bbde-f0a39eec7665"], "metadata": {"page_label": "17", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "84d83c1b-13c9-4df4-883a-da2192351114": {"node_ids": ["903659d8-a415-4264-98ed-675fb565c677"], "metadata": {"page_label": "18", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "6ce61545-6112-4b61-b2f1-3d3cc2b1eccc": {"node_ids": ["0457fdea-0c13-4688-a54e-fd71dfe377a4"], "metadata": {"page_label": "19", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "37eb8154-56d4-418a-811c-ee1267b5c996": {"node_ids": ["4b257a6e-94a5-4788-b70a-0504a93078f6"], "metadata": {"page_label": "20", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "9535911d-33e2-49c3-b623-c79315e1fe79": {"node_ids": ["c443db44-6e60-4414-b692-c67badf89cf0"], "metadata": {"page_label": "21", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "2990df88-ca4a-4cbe-a8a1-749be92c2ee7": {"node_ids": ["b7df068a-d095-444e-b683-d349abdae08b"], "metadata": {"page_label": "22", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "e09f8ec4-7ea1-4f55-ae7d-97f528e03bcd": {"node_ids": ["e47d43f3-91b4-44d6-9e5f-dd85e0cf4fba"], "metadata": {"page_label": "23", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "972dc4ab-fc85-4816-bafe-f236034ae90b": {"node_ids": ["82597407-bbd3-4e54-8b17-b7f2856a7e9d"], "metadata": {"page_label": "24", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "e4f359e7-990a-48b6-b23b-e7116d2f7f41": {"node_ids": ["2d445638-89e9-4f1e-8af9-f8f445ca439e"], "metadata": {"page_label": "25", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "329538b3-b96c-42ad-80ca-bab4f96305e1": {"node_ids": ["b5669d62-ae64-496d-9be1-b0a0aec6dd86"], "metadata": {"page_label": "26", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "77809ebb-d8a8-4c58-a5ad-b6a11b4637e7": {"node_ids": ["0ad6fcc2-192b-4771-b997-0d99481044c4"], "metadata": {"page_label": "27", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "976c795b-f5d5-4f1c-946c-c0e788e4be41": {"node_ids": ["6c20d800-f06b-4ae4-8ad6-538bc5da1d70"], "metadata": {"page_label": "28", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "2f3716f3-7ea7-4055-b8e4-950bc62a3b47": {"node_ids": ["b4a2397c-cdf8-4537-9ffd-07f8df360085"], "metadata": {"page_label": "29", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "262425e9-1a30-405e-a513-891a87598fbf": {"node_ids": ["9cef2c25-8b41-485b-b165-04ca52887e30"], "metadata": {"page_label": "30", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "e9c57312-ca85-4dbc-b7b3-36df08853db9": {"node_ids": ["a2f1ac0f-7856-42ed-a918-c4b7471b203d"], "metadata": {"page_label": "31", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "918d6eab-0844-4917-809d-68b6818d454e": {"node_ids": ["c29910c3-9eb0-4e5f-be54-c692fe0b1f6c"], "metadata": {"page_label": "32", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "221d27b2-441c-4dd8-a014-c2d7407961a1": {"node_ids": ["1e0eb29d-d183-4209-a012-902e092e4601"], "metadata": {"page_label": "33", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}, "0b620ab8-48d8-4e0d-a64f-cccb33254bdb": {"node_ids": ["c8a37f28-9e56-4d87-bc25-4ad9b39bdba3"], "metadata": {"page_label": "34", "file_name": "lecture-intelligent-agents.pdf", "file_path": "/Users/pavankumar/Projects/Llama-index-Agent/Data/lecture-intelligent-agents.pdf", "file_type": "application/pdf", "file_size": 456703, "creation_date": "2024-08-08", "last_modified_date": "2024-08-08"}}}}